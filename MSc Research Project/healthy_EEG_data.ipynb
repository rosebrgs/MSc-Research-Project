{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73885fa5-bc98-44fb-9852-40b14ff93ba0",
   "metadata": {},
   "source": [
    "The cells that need to be run in order for all functions to work start with * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c803aa02-9122-4024-905f-25f2279d879f",
   "metadata": {},
   "source": [
    "## *Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f484fc5a-d71b-4827-b1f5-e22dec4a7be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvista\n",
    "import ipywidgets\n",
    "import ipyevents\n",
    "import pyvistaqt\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import hilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "282b8921-aab1-4a37-b447-c3ef9c8b7ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# to make plots interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5001cf-6cf3-43b0-b5b2-9dd60460563a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### don't need to run but could be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1915f29d-2342-4d4f-be53-beb65bf1771f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print(python_version())\n",
    "#pip list\n",
    "#pip list | findstr numpy\n",
    "#pip list | findstr pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553aa05e-2a2a-4004-abdf-878bab5ff21f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a770e54-59f5-47e3-8c48-021a1212893f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "conda install --name=base nb_conda_kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63345b99-a4a3-445a-8560-eb105bad75c8",
   "metadata": {},
   "source": [
    "## *Labelled data: Onset times NREM stages 2 and 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b24000-3d26-402b-9075-74323acc8a37",
   "metadata": {},
   "source": [
    "### *Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1851b849-e9bc-45aa-9d69-ecd2193ed823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "file_path = r\"C:\\EEG DATA\\FL_label_data.pickle\"\n",
    "# added r in front of file path to make it a raw string, to make sure that \\ is not interpreted as a newline character\n",
    "\n",
    "# open the pickle file\n",
    "with open(file_path, \"rb\") as file:\n",
    "    label_data = pickle.load(file)\n",
    "\n",
    "# show the label_data type\n",
    "print(type(label_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a45b659-5bca-4596-91ce-e3a56ef326b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Printing the label_dataset (dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5d6052-355a-4eac-a2c6-5af5d3d98fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the keys and values of the labelled label_dataset\n",
    "\n",
    "print(\"Keys and Values:\")\n",
    "for key, value in zip(label_data.keys(), label_data.values()):\n",
    "\tprint(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795d3474-d508-4872-93c3-d0b097f42890",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Exploring the label_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaf3cee-b061-4fe3-aa5b-bd2b9acd8ea3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"keys:\", label_data.keys())\n",
    "print(\"keys_length:\", len(label_data.keys()))\n",
    "print(\"values_length:\", len(label_data.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc2301b-4de0-4bd8-846e-92d63b0289c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data['087'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b4f09-65e4-466e-b439-ba45cd5ab2ef",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "label_data['087'].values()\n",
    "# essentially same as above but without the 'label' and 'onset' and starts with dict_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f782a2-7803-4007-8e12-7ac0f56866cd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "label_data['087']['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cdd2e4-6b7b-4717-bcbb-0a4afdee3b98",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "label_data['085'].keys()\n",
    "# not all the participants have the same order for the keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74018ab1-caf6-4480-ab9e-3bcfb084160e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "label_087 = label_data['087']['label']\n",
    "print(label_087)\n",
    "\n",
    "onset_087 = label_data['087']['onset']\n",
    "print(onset_087)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312f4f0f-2524-4625-8c92-57b486d1a9fd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(len(label_087))\n",
    "print(len(onset_087))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ae6dab-76f2-433b-b981-c8a5e5e4b059",
   "metadata": {},
   "source": [
    "### *Printing the values for NREM stages 2 and 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db033ff-0275-4d62-a3cd-ef282f8ec177",
   "metadata": {},
   "source": [
    "#### *New dictionary with only NREM stages 2 and 3 onset times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "903aac65-0bc4-4e66-a9d4-75d07dd26937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: 083, Warning: The indices do not match\n",
      "Key: 084, Warning: The indices do not match\n",
      "Key: 086, Warning: The indices do not match\n",
      "Key: 038, Warning: The indices do not match\n",
      "Key: 040, Warning: The indices do not match\n",
      "Key: 043, Warning: The indices do not match\n",
      "Key: 045, Warning: The indices do not match\n",
      "Key: 062, Warning: The indices do not match\n",
      "Key: 065, Warning: The indices do not match\n",
      "Key: 069, Warning: The indices do not match\n",
      "Key: 073, Warning: The indices do not match\n",
      "Key: 085, Warning: The indices do not match\n",
      "Key: 091, Warning: The indices do not match\n"
     ]
    }
   ],
   "source": [
    "# to return all the results\n",
    "# returns a dict so should have commas between values\n",
    "\n",
    "def extract_onsets(label_data):\n",
    "    onset_dict = {}\n",
    "    for key, value in label_data.items():\n",
    "        labels = np.atleast_1d(value['label'])\n",
    "        onsets = np.atleast_1d(value['onset'])\n",
    "        # to ensure that labels and onsets are treated as array\n",
    "        # because subsequently using np.where\n",
    "        indices = np.where((labels == 1) | (labels == 2))[0]\n",
    "        # returns indices where the label is 1 (N2) or 2 (N3)\n",
    "        if indices.size > 0 and np.all(indices < len(onsets)):\n",
    "            # to ensure that no out-of-bounds error\n",
    "            selected_onsets = onsets[indices]\n",
    "            # retrieve onset value corresponding to label 1 or 2\n",
    "            onset_dict[key] = selected_onsets\n",
    "            # save extracted onset under correct key in dict\n",
    "            #print(f\"Key: {key}, Onset values for labels 1 (N2) and 2 (N3): {', '.join(map(str, selected_onsets))}\")\n",
    "        else:\n",
    "            print(f\"Key: {key}, Warning: The indices do not match\")\n",
    "    return onset_dict\n",
    "    # returning the onset_dict and what you're printing\n",
    "    # should I be only returning what is supposed to be printed? or maybe only the dict, since already has commas?\n",
    "\n",
    "label_data_onsets = extract_onsets(label_data)\n",
    "# this code also shows participants with mismatch in length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0638aad4-a7d0-4a19-b986-d9f3a18883d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data['046']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11860882-968d-4cfe-ad78-6f08f5b9ccd4",
   "metadata": {},
   "source": [
    "#### *Function for creating sublists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b324b2ee-19eb-4922-8923-1c2b03cc6a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting onset values corresponding to labels 1 and 2 (assuming you have a list of labels)\n",
    "# onset_values_013 contains the relevant onset values\n",
    "\n",
    "# Function 1: to split the onset values into sublists where the difference between two values is always 30. otherwise starts a new sublist.\n",
    "\n",
    "def group_by_increment(onset_values, increment=30):\n",
    "    groups = []\n",
    "    # will be a list of lists\n",
    "    current_group = [float(onset_values[0])]\n",
    "    # initializes this list with the first value from onset_values (the input)\n",
    "    \n",
    "    for i in range(1, len(onset_values)):\n",
    "        # loops through all the onset values\n",
    "        if onset_values[i] - onset_values[i - 1] == increment:\n",
    "            # if i = 1, if onset_values[1] - onset_values[0] == 30\n",
    "            current_group.append(float(onset_values[i]))\n",
    "            # add the value at current index\n",
    "        else:\n",
    "            # if not a difference of 30\n",
    "            # means you've reached the end of that sublist\n",
    "            if len(current_group) >= 1:\n",
    "                # if there is at least a value in that group\n",
    "                groups.append(current_group)\n",
    "                # add the sublist to the big list\n",
    "            current_group = [float(onset_values[i])]\n",
    "            # starts a new current group with the new value at the current index\n",
    "    \n",
    "    if len(current_group) >= 1:\n",
    "        groups.append(current_group)\n",
    "    # once you exit the group, if the last current_group contains more than one value\n",
    "    # then you can add it to group\n",
    "    # to make sure that last sequence is not left out\n",
    "    \n",
    "    return groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25159202-ed5f-4dd7-b439-27b6c9bedfb9",
   "metadata": {},
   "source": [
    "#### *Extract raw segments (correct function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28a55681-d3e7-4f2d-9ba3-14ee8ff88435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_segments(raw, groups):\n",
    "    raw_segments = []\n",
    "    # empty list to store the extracted EEG segments\n",
    "    #max_time = raw.times[-1]\n",
    "    \n",
    "    for group in groups:\n",
    "        start = group[0]\n",
    "        # start = first value in group\n",
    "        #stop = min(group[-1], max_time) \n",
    "        stop = group[-1]\n",
    "        # stop = last value in group\n",
    "\n",
    "        #if start >= max_time:\n",
    "            #continue\n",
    "        # takes the smaller of the two values\n",
    "        segment = raw.copy().crop(tmin=start, tmax=stop)\n",
    "        raw_segments.append(segment)\n",
    "    \n",
    "    return raw_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99836357-0d51-46e0-86a4-6b76ccdb53b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Plot segments (will concatenate them later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9abf214-bc24-4a68-b606-9385dbdf44c9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Loop through each group and call participant_013_raw.plot\n",
    "\n",
    "# Assuming participant_013_raw is already loaded\n",
    "# participant_013_raw = mne.io.read_raw_fif(\"path_to_raw_file.fif\", preload=True)\n",
    "\n",
    "def plot_segments(raw, groups, n_channels=64):\n",
    "    for group in groups:\n",
    "        start = group[0]\n",
    "        duration = group[-1] - group[0]\n",
    "        # group[-1]: last value in the group\n",
    "        raw.plot(duration=duration, start=start, n_channels=n_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd587596-a3fe-4ce4-9f34-1874b47d34d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Errors in data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eb42c3-b01b-4b12-a159-c8727ff739f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Examples of participants which show mismatch in length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbe3824-3976-4a3e-9349-2f408dd1ea97",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"length of labels for 083:\", len(label_data['083']['label']))\n",
    "print(\"length of onsets for 083:\", len(label_data['083']['onset']))\n",
    "\n",
    "print(\"\\nlength of labels for 084:\", len(label_data['084']['label']))\n",
    "print(\"length of onsets for 084:\", len(label_data['084']['onset']))\n",
    "\n",
    "print(\"\\nlength of labels for 086:\", len(label_data['086']['label']))\n",
    "print(\"length of onsets for 086:\", len(label_data['086']['onset']))\n",
    "\n",
    "print(\"\\nlength of labels for 038:\", len(label_data['038']['label']))\n",
    "print(\"length of onsets for 038:\", len(label_data['038']['onset']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce9d5a2-1034-45b5-a730-3f7f0107e29c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "label_data['083']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dadc98-745a-4702-831a-b9f78b954680",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### attempt at putting results as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51f7766-cc6d-4b02-a3ea-98544938e14e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# attempt at putting results as a dictionary\n",
    "result_dict = {}\n",
    "for idx in indices:\n",
    "    key = keys[idx]  # Get the corresponding key\n",
    "    if key not in result_dict:\n",
    "        result_dict[key] = []\n",
    "    result_dict[key].append(idx)\n",
    "\n",
    "# Example: Retrieve values for key '087'\n",
    "print(result_dict.get('087', []))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff30faa0-ce7c-49a7-8bd5-bc01b750859a",
   "metadata": {},
   "source": [
    "## *Slow oscillation detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e868b9-08d5-473b-9546-b0b571535a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_slow_oscillations_times(combined_raw):\n",
    "\n",
    "    # according to methods from Klinzing et al.(2016)\n",
    "\n",
    "    \n",
    "    # 1. filter between 0.16 and 1.25 Hz\n",
    "    filtered_data = combined_raw.copy().filter(l_freq=0.16, h_freq=1.25, fir_design='firwin', verbose=False)\n",
    "\n",
    "    # 2. downsample to 100 Hz\n",
    "    #filtered_data.resample(100)\n",
    "    sfreq = filtered_data.info['sfreq']\n",
    "    current_data = filtered_data.get_data(picks=\"Fz\")[0]\n",
    "    # only keep channel \"Fz\"\n",
    "\n",
    "    \n",
    "    # 3. find all positive-to-negative zero-crossings\n",
    "    \n",
    "    # zero_crossings = np.where( S!= 0)[0]\n",
    "    # can also save this somewhere for further detection of spindles\n",
    "    \n",
    "    S = np.diff(np.sign(current_data))\n",
    "    # np.sign returns an array with 1 (positive), 0 (zero), -1 (negative)\n",
    "    # np.diff calculates the difference between consecutive elements in an array\n",
    "    # positive value: transition from negative to positive\n",
    "    # negative value: transition from positive to negative\n",
    "    # when it's a zero, means that value stayed the same\n",
    "    zero_crossings = np.where(S < 0)[0]\n",
    "    # -2 is when a positive-to-negative zero-crossing occurs\n",
    "    # goes from 1 to -1 \n",
    "    # -1 - 1 = -2\n",
    "    # [0] extracts the actual array\n",
    "    # extracts the indices of interest from current_data (not S)\n",
    "    #signs = np.sign(current_data)\n",
    "    #pos_to_neg = np.where((signs[:-1] > 0) & (signs[1:] < 0))[0]\n",
    "    # detect +1 to -1\n",
    "    #neg_to_pos = np.where((signs[:-1] <  0) & (signs[1:] > 0))[0]\n",
    "    # detect -1 to +1\n",
    "\n",
    "    # 4. Detect peak potentials in each pair\n",
    "    slow_oscillations = []\n",
    "    negative_peaks = []\n",
    "    positive_peaks = []\n",
    "    peak_to_peak_amplitudes = []\n",
    "    candidate_indices = []\n",
    "\n",
    "    # for loop for each pair\n",
    "    # to collect all the negative and positive peaks\n",
    "    # to further apply criteria\n",
    "    count = 0\n",
    "    for i in range(0, len(zero_crossings)-1, 1):\n",
    "        # loop through all the zero_crossings\n",
    "        # step of 1 (with step of 2, miss some zero_crossings)\n",
    "        start_idx = zero_crossings[i] + 1\n",
    "        # assigns index of zero-crossing (representing start of potential SO)\n",
    "        # to start_idx\n",
    "        end_idx = zero_crossings[i + 1] + 1\n",
    "        # assigns index of next zero-crossing (representing end of potential SO)\n",
    "        # to end_idx\n",
    "\n",
    "        # find the negative to positive crossing in between\n",
    "        #mid_crossings = neg_to_pos[(neg_to_pos > start_idx) & (neg_to_pos < end_idx)]\n",
    "\n",
    "        #if len(mid_crossings) != 1:\n",
    "            #continue\n",
    "\n",
    "        #mid_idx = mid_crossings [0]\n",
    "\n",
    "        #duration = (end_idx - start_idx) / sfreq\n",
    "        #if not (0.8 <= duration <= 2.0):\n",
    "  \n",
    "        \n",
    "        segment_length = (end_idx - start_idx) / sfreq\n",
    "\n",
    "        # need to add +1 because of way extract segment later\n",
    "\n",
    "        # have identified index for the pair\n",
    "        \n",
    "        # extract data segment between crossings\n",
    "        \n",
    "        # find peaks\n",
    "        if 0.8 <= segment_length <= 2.0:\n",
    "            count += 1\n",
    "            segment = current_data[start_idx:end_idx]\n",
    "            positive_peak = np.max(segment)\n",
    "            negative_peak = np.min(segment)\n",
    "            peak_to_peak_amplitude = positive_peak - negative_peak\n",
    "\n",
    "        # store values\n",
    "            candidate_indices.append((start_idx, end_idx))\n",
    "            positive_peaks.append(positive_peak)\n",
    "            negative_peaks.append(negative_peak)\n",
    "            peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "\n",
    "    # calculate mean values for comparison\n",
    "    #mean_negative_peak = np.mean(negative_peaks)\n",
    "    # mean_negative_peak = np.mean(negative_peaks) if negative_peaks else 0\n",
    "    #mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes)\n",
    "    # mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes) if peak_to_peak_amplitudes else 0\n",
    "\n",
    "    negative_peak_threshold = np.percentile(negative_peaks, 25)\n",
    "    # keep lowest negative peaks (under the 25th percentile)\n",
    "    peak_to_peak_amplitude_threshold = np.percentile(peak_to_peak_amplitudes, 75)\n",
    "    # keep largest peak-to-peak amplitude (over 75th percentile)\n",
    "\n",
    "    for (start_idx, end_idx), negative_peak, peak_to_peak_amplitude in zip(candidate_indices, negative_peaks, peak_to_peak_amplitudes):\n",
    "        if peak_to_peak_amplitude >= peak_to_peak_amplitude_threshold and negative_peak <= negative_peak_threshold:\n",
    "            slow_oscillations.append((start_idx / sfreq, end_idx / sfreq))\n",
    "            \n",
    "    return slow_oscillations\n",
    "    # returns a list of tuples, in which each tuple represents the start and end times of\n",
    "    # a detected slow oscillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b797375-483c-41c9-9987-d4a0f96eadbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_slow_oscillations_peaks(combined_raw):\n",
    "\n",
    "    # according to methods from Klinzing et al.(2016)\n",
    "\n",
    "    \n",
    "    # 1. filter between 0.16 and 1.25 Hz\n",
    "    filtered_data = combined_raw.copy().filter(l_freq=0.16, h_freq=1.25, fir_design='firwin', verbose=False)\n",
    "\n",
    "    # 2. downsample to 100 Hz\n",
    "    #filtered_data.resample(100)\n",
    "    sfreq = filtered_data.info['sfreq']\n",
    "    current_data = filtered_data.get_data(picks=\"Fz\")[0]\n",
    "    # only keep channel \"Fz\"\n",
    "\n",
    "    \n",
    "    # 3. find all positive-to-negative zero-crossings\n",
    "    \n",
    "    # zero_crossings = np.where( S!= 0)[0]\n",
    "    # can also save this somewhere for further detection of spindles\n",
    "    \n",
    "    S = np.diff(np.sign(current_data))\n",
    "    # np.sign returns an array with 1 (positive), 0 (zero), -1 (negative)\n",
    "    # np.diff calculates the difference between consecutive elements in an array\n",
    "    # positive value: transition from negative to positive\n",
    "    # negative value: transition from positive to negative\n",
    "    # when it's a zero, means that value stayed the same\n",
    "    zero_crossings = np.where(S < 0)[0]\n",
    "    # -2 is when a positive-to-negative zero-crossing occurs\n",
    "    # goes from 1 to -1 \n",
    "    # -1 - 1 = -2\n",
    "    # [0] extracts the actual array\n",
    "    # extracts the indices of interest from current_data (not S)\n",
    "\n",
    "\n",
    "    # 4. Detect peak potentials in each pair\n",
    "    slow_oscillations = []\n",
    "    slow_oscillations_peaks = []\n",
    "    negative_peaks = []\n",
    "    positive_peaks = []\n",
    "    peak_to_peak_amplitudes = []\n",
    "    candidate_indices =  []\n",
    "\n",
    "    # for loop for each pair\n",
    "    # to collect all the negative and positive peaks\n",
    "    # to further apply criteria\n",
    "    count = 0\n",
    "    for i in range(0, len(zero_crossings) - 1, 1):\n",
    "        # loop through all the zero_crossings\n",
    "        # step of 1 (with step of 2, miss some zero_crossings)\n",
    "        start_idx = zero_crossings[i] + 1\n",
    "        # assigns index of zero-crossing (representing start of potential SO)\n",
    "        # to start_idx\n",
    "        end_idx = zero_crossings[i + 1] + 1\n",
    "        # assigns index of next zero-crossing (representing end of potential SO)\n",
    "        # to end_idx\n",
    "        segment_length = (end_idx - start_idx) / sfreq\n",
    "\n",
    "        # need to add +1 because of way extract segment later\n",
    "\n",
    "        # have identified index for the pair\n",
    "        \n",
    "        # extract data segment between crossings\n",
    "        \n",
    "        # find peaks\n",
    "        if 0.8 <= segment_length <= 2.0:\n",
    "            count += 1\n",
    "            segment = current_data[start_idx:end_idx]\n",
    "            positive_peak = np.max(segment)\n",
    "            negative_peak = np.min(segment)\n",
    "            peak_to_peak_amplitude = positive_peak - negative_peak\n",
    "\n",
    "        # store values\n",
    "            candidate_indices.append((start_idx, end_idx))\n",
    "            positive_peaks.append(positive_peak)\n",
    "            negative_peaks.append(negative_peak)\n",
    "            peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "\n",
    "    # calculate mean values for comparison\n",
    "    #mean_negative_peak = np.mean(negative_peaks)\n",
    "    # mean_negative_peak = np.mean(negative_peaks) if negative_peaks else 0\n",
    "    #mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes)\n",
    "    # mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes) if peak_to_peak_amplitudes else 0\n",
    "\n",
    "    negative_peak_threshold = np.percentile(negative_peaks, 25)\n",
    "    peak_to_peak_amplitude_threshold = np.percentile(peak_to_peak_amplitudes, 75)\n",
    "\n",
    "    for (start_idx, end_idx), negative_peak, peak_to_peak_amplitude in zip(candidate_indices, negative_peaks, peak_to_peak_amplitudes):\n",
    "        if peak_to_peak_amplitude >= peak_to_peak_amplitude_threshold and negative_peak <= negative_peak_threshold:\n",
    "            slow_oscillations.append((start_idx / sfreq, end_idx / sfreq))\n",
    "            slow_oscillations_peaks.append((negative_peak, positive_peak))\n",
    "\n",
    "            \n",
    "    return slow_oscillations\n",
    "    # returns a list of tuples, in which each tuple represents the start and end times of\n",
    "    # a detected slow oscillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0187238d-d3e5-45d9-81f0-e4fab6c25895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now want to visualise slow oscillations\n",
    "# find peak and trough for each of them, and then stack them all together to visualise\n",
    "\n",
    "# this function aligns detected slow oscillations at their trough\n",
    "# creates an average SO waveform\n",
    "\n",
    "def visualize_and_stack_slow_oscillations_trough(combined_raw, slow_oscillations, plot_name):\n",
    "\n",
    "    # Apply band-pass filter between 0.3 and 1.25 Hz\n",
    "    filtered_data = combined_raw.copy().filter(l_freq=0.16, h_freq=1.25)\n",
    "    # downsampling to 100 Hz\n",
    "    #filtered_data.resample(100)\n",
    "    filtered_channel_data = filtered_data.get_data(picks=\"Fz\")[0]\n",
    "    \n",
    "    sfreq = filtered_data.info['sfreq']\n",
    "    \n",
    "    stacked_data = []\n",
    "    # loop through each slow oscillation\n",
    "    for start_time, end_time in slow_oscillations:\n",
    "        # to convert start and end times to sample indices\n",
    "        start_idx = int(start_time * sfreq)\n",
    "        end_idx = int(end_time * sfreq)\n",
    "\n",
    "        # extract the slow oscillation segment\n",
    "        segment = filtered_channel_data[start_idx:end_idx]\n",
    "\n",
    "        global_trough_idx = np.argmin(filtered_channel_data[start_idx:end_idx]) + start_idx\n",
    "         # argmin finds the index of the min value\n",
    "        # min finds the min value itself\n",
    "        \n",
    "        # calculate indices for 1.5 seconds before and after trough\n",
    "        before_trough_idx = max(0, global_trough_idx - int(1.5 * sfreq))\n",
    "        # substracts 1.5 seconds from the trough index\n",
    "        # max as a safety check, to make sure that before_trough_index never negative\n",
    "        # to prevent accessing data points before the beginning of the segment\n",
    "        after_trough_idx = min(len(filtered_channel_data), global_trough_idx + int(1.5 * sfreq))\n",
    "        # adds 1.5 seconds to the trough index\n",
    "        # min is another safety check\n",
    "        \n",
    "        # extract the segment around the trough\n",
    "        aligned_segment = filtered_channel_data[before_trough_idx:after_trough_idx]\n",
    "\n",
    "        # append the aligned segment to the stacked data\n",
    "        stacked_data.append(aligned_segment)\n",
    "\n",
    "    # Find the maximum length of the segments\n",
    "    max_len = max(len(segment) for segment in stacked_data)\n",
    "\n",
    "    # Pad shorter segments with np.nan\n",
    "    padded_stacked_data = []\n",
    "    for segment in stacked_data:\n",
    "        pad_len = max_len - len(segment)\n",
    "        # how much padding is needed\n",
    "        pad_before = pad_len // 2\n",
    "        pad_after = pad_len - pad_before\n",
    "        padded_segment = np.pad(segment, (pad_before, pad_after), 'constant', constant_values=np.nan)\n",
    "        # distribute the padding before and after the segment\n",
    "        # use NaNs instead of zeros to avoid bias\n",
    "        padded_stacked_data.append(padded_segment)\n",
    "\n",
    "    # calculate the average stacked slow oscillation\n",
    "    average_padded_stacked_data = np.nanmean(padded_stacked_data, axis=0)\n",
    "    # compute average waveform by ignoring NaNs\n",
    "\n",
    "    # visualize the average stacked slow oscillation\n",
    "    time_axis = np.linspace(-1.5, 1.5, len(average_padded_stacked_data))\n",
    "    # this is to create the time axis\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(time_axis, average_padded_stacked_data, color=\"blue\", label=\"Mean SO\")\n",
    "    plt.axvline(0, color=\"red\", linestyle=\"--\", label=\"Trough (0s)\")\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude (µV)')\n",
    "    plt.title(plot_name)\n",
    "    plt.legend()\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d635b5b4-2c5e-4f32-9aba-2d2a6e1e1334",
   "metadata": {},
   "source": [
    "## *Spindle detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d92f5b3-3988-4e8f-a1b4-040400a6bf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import scipy.signal as signal\n",
    "#from scipy.signal import find_peaks\n",
    "\n",
    "def detect_spindles_times(eeg_raw):\n",
    "    # Parameters\n",
    "    #channel = 'Fz'\n",
    "    \n",
    "    # 1. Filter between 12 and 16 Hz\n",
    "    \n",
    "    filtered_data = eeg_raw.copy().pick_channels(['Fz'])\n",
    "    filtered_data.filter(l_freq=12, h_freq=16)\n",
    "    \n",
    "    # 2. Downsample at 100 Hz (100 samples per second)\n",
    "    \n",
    "    #filtered_data.resample(100)\n",
    "    sfreq = filtered_data.info['sfreq']  \n",
    "    # update to new sampling frequency\n",
    "    # because used later in the code\n",
    "    channel_data = filtered_data.get_data()[0]\n",
    "    # extract the filtered data\n",
    "    \n",
    "    \n",
    "    # 3: Calculate amplitude by applying Hilbert transformation\n",
    "\n",
    "    hilbert_signal = hilbert(channel_data)\n",
    "    # apply hilbert transformation to bandpassed data\n",
    "    # gives analytic signal with amplitude and phase information\n",
    "    envelope = np.abs(hilbert_signal)\n",
    "    # take the absolute part of the hilbert signal\n",
    "    # also the instantaneous power of the signal\n",
    "    # gives the envelope: amplitude modulation\n",
    "    # how strength of oscillations change over time\n",
    "    # size of sliding window\n",
    "    \n",
    "    # 4: Perform smoothing with a sliding window of 0.2 seconds\n",
    "    # this removes high-frequency noise\n",
    "    \n",
    "    sliding_window = int(0.2 * sfreq)\n",
    "    smoothed_envelope = np.convolve(envelope, np.ones(sliding_window) / sliding_window, mode='same')\n",
    "    # convolving envelope with a uniform filter over the sliding window\n",
    "    # convolution takes rolling average of 20 samples at a time\n",
    "    # smooth the signal with the average of values in the window\n",
    "    # in the smoothed envelope, can detect regions with higher amplitude \n",
    "    # which is when a spindle event occurs\n",
    "    # np.ones: creates a filter kernel\n",
    "    # have a filter where the sum of all elements equals 1\n",
    "    # this filter is replaced by the average of the 20 surrounding samples\n",
    "    # convolution between envelope and averaging filter\n",
    "    # mode = 'same': so that output of convolution has same length as original envelope\n",
    "\n",
    "    # 5. Define spindle detection threshold\n",
    "\n",
    "    threshold = np.percentile(smoothed_envelope, 75)\n",
    "    spindle_threshold = smoothed_envelope > threshold\n",
    "    #threshold = np.mean(smoothed_envelope) + 1.5 * np.std(smoothed_envelope)\n",
    "    #spindle_threshold = smoothed_envelope > threshold\n",
    "    # threshold is 75th percentile of the smoothed envelope\n",
    "    # will look at the duration later\n",
    "    \n",
    "    # 6. Detect spindles and define peaks and troughs for visualisation\n",
    "    \n",
    "    spindles = []\n",
    "    # initialize list with spindles\n",
    "    above_threshold = np.where(spindle_threshold)[0]\n",
    "    # returns indices where signal above the threshold\n",
    "    stacked_spindles = []\n",
    "    # initialize list for stacking the spindles for the visualisation\n",
    "    # contains aligned spindles at peak\n",
    "    \n",
    "    if len(above_threshold) > 0:\n",
    "        # checking it's not empty\n",
    "        start_idx = above_threshold[0]\n",
    "        # would be the start of a potential spindle\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] > above_threshold[i - 1] + 1:  \n",
    "                # if above threshold[1] > above_threshold[0] + 1\n",
    "                # because all indices should be separated by 1\n",
    "                # so here detects gaps\n",
    "                # so starting from the second index\n",
    "                # and comparing each index to the one before\n",
    "                end_idx = above_threshold[i - 1]\n",
    "                # so if above condition is true, this is the end of the spindle\n",
    "                duration = (end_idx - start_idx) / sfreq\n",
    "                if 0.5 <= duration <= 3:\n",
    "                    # only keep spindles lasting 0.5 to 3 seconds\n",
    "                    segment = channel_data[start_idx:end_idx]\n",
    "                    # extract EEG segment corresponding to detected spindle\n",
    "                    peak_idx = start_idx + np.argmax(segment) \n",
    "                    # extract the peak of the spindle\n",
    "                    # this will be useful for later\n",
    "                    spindles.append((start_idx / sfreq, end_idx / sfreq))\n",
    "                    # all the spindles are stored in spindles\n",
    "                    \n",
    "                    # Aligning spindles at peak for visualization\n",
    "                    before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "                    # still in the for loop, so this is the peak index of individual peak\n",
    "                    after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "                    # extracting 1.5 seconds before and after peak\n",
    "                    # max and min are used for out of bounds situations at the start and end of EEG data\n",
    "                    aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "                    stacked_spindles.append(aligned_segment)\n",
    "                    # the aligned segment is saved in stacked spindles\n",
    "                \n",
    "                start_idx = above_threshold[i]\n",
    "                # update the start index for the for loop\n",
    "\n",
    "        # then need to process the final spindle\n",
    "        end_idx = above_threshold[-1]\n",
    "        duration = (end_idx - start_idx) / sfreq\n",
    "        if 0.5 <= duration <= 3:\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            peak_idx = start_idx + np.argmax(segment)\n",
    "            spindles.append((start_idx / sfreq, end_idx / sfreq))\n",
    "\n",
    "            before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "            after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "            aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "            stacked_spindles.append(aligned_segment)\n",
    "    \n",
    "    return spindles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d4264fd-5035-4209-a592-dbd4aff76829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as signal\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def detect_spindles_peaks(eeg_raw):\n",
    "    # Parameters\n",
    "    #channel = 'Fz'\n",
    "    \n",
    "    # 1. Filter between 12 and 16 Hz\n",
    "    \n",
    "    filtered_data = eeg_raw.copy().pick_channels(['Fz'])\n",
    "    filtered_data.filter(l_freq=12, h_freq=16)\n",
    "    \n",
    "    # 2. Downsample at 100 Hz (100 samples per second)\n",
    "    \n",
    "    #filtered_data.resample(100)\n",
    "    sfreq = filtered_data.info['sfreq']  \n",
    "    # update to new sampling frequency\n",
    "    # because used later in the code\n",
    "    channel_data = filtered_data.get_data()[0]\n",
    "    # extract the filtered data\n",
    "    \n",
    "    # 3: Calculate amplitude by applying Hilbert transformation\n",
    "\n",
    "    hilbert_signal = hilbert(channel_data)\n",
    "    # apply hilbert transformation to bandpassed data\n",
    "    # gives analytic signal with amplitude and phase information\n",
    "    envelope = np.abs(hilbert_signal)\n",
    "    # take the absolute part of the hilbert signal\n",
    "    # also the instantaneous power of the signal\n",
    "    # gives the envelope: amplitude modulation\n",
    "    # how strength of oscillations change over time\n",
    "    # size of sliding window\n",
    "    \n",
    "    # 4: Perform smoothing with a sliding window of 0.2 seconds\n",
    "    # this removes high-frequency noise\n",
    "    \n",
    "    sliding_window = int(0.2 * sfreq)\n",
    "    smoothed_envelope = np.convolve(envelope, np.ones(sliding_window) / sliding_window, mode='same')\n",
    "    # convolving envelope with a uniform filter over the sliding window\n",
    "    # convolution takes rolling average of 20 samples at a time\n",
    "    # smooth the signal with the average of values in the window\n",
    "    # in the smoothed envelope, can detect regions with higher amplitude \n",
    "    # which is when a spindle event occurs\n",
    "    # np.ones: creates a filter kernel\n",
    "    # have a filter where the sum of all elements equals 1\n",
    "    # this filter is replaced by the average of the 20 surrounding samples\n",
    "    # convolution between envelope and averaging filter\n",
    "    # mode = 'same': so that output of convolution has same length as original envelope\n",
    "\n",
    "    # 5. Define spindle detection threshold\n",
    "\n",
    "    threshold = np.percentile(smoothed_envelope, 75)\n",
    "    spindle_threshold = smoothed_envelope > threshold\n",
    "    # 75th percentile as criteria\n",
    "\n",
    "    #threshold = np.mean(smoothed_envelope) + 1.5 * np.std(smoothed_envelope)\n",
    "    #spindle_threshold = smoothed_envelope > threshold\n",
    "    \n",
    "    # 6. Detect spindles and define peaks and troughs for visualisation\n",
    "    \n",
    "    spindles = []\n",
    "    # initialize list with spindles\n",
    "    above_threshold = np.where(spindle_threshold)[0]\n",
    "    # returns indices where signal above the threshold\n",
    "    stacked_spindles = []\n",
    "    # initialize list for stacking the spindles for the visualisation\n",
    "    # contains aligned spindles at peak\n",
    "    \n",
    "    if len(above_threshold) > 0:\n",
    "        # checking it's not empty\n",
    "        start_idx = above_threshold[0]\n",
    "        # would be the start of a potential spindle\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] > above_threshold[i - 1] + 1:  \n",
    "                # if above threshold[1] > above_threshold[0] + 1\n",
    "                # because all indices should be separated by 1\n",
    "                # so here detects gaps\n",
    "                end_idx = above_threshold[i - 1]\n",
    "                # so if above condition is true, this is the end of the spindle\n",
    "                duration = (end_idx - start_idx) / sfreq\n",
    "                if 0.5 <= duration <= 3:\n",
    "                    # only keep spindles lasting 0.5 to 3 seconds\n",
    "                    segment = channel_data[start_idx:end_idx]\n",
    "                    # extract EEG segment corresponding to detected spindle\n",
    "                    peak_idx = start_idx + np.argmax(segment) \n",
    "                    # extract the peak of the spindle\n",
    "                    # this will be useful for later\n",
    "                    #spindles.append(f\"Spindle detected from {start_idx / sfreq:.2f}s to {end_idx / sfreq:.2f}s, peak at {peak_idx / sfreq:.2f}s\")\n",
    "                    spindles.append((peak_idx / sfreq))\n",
    "                    # all the spindles are stored in spindles\n",
    "                    \n",
    "                    # Aligning spindles at peak for visualization\n",
    "                    before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "                    # still in the for loop, so this is the peak index of individual peak\n",
    "                    after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "                    # extracting 1.5 seconds before and after peak\n",
    "                    # max and min are used for out of bounds situations at the start and end of EEG data\n",
    "                    aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "                    stacked_spindles.append(aligned_segment)\n",
    "                    # the aligned segment is saved in stacked spindles\n",
    "                \n",
    "                start_idx = above_threshold[i]\n",
    "                # update the start index for the for loop\n",
    "\n",
    "        # then need to process the final spindle\n",
    "        end_idx = above_threshold[-1]\n",
    "        duration = (end_idx - start_idx) / sfreq\n",
    "        if 0.5 <= duration <= 3:\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            peak_idx = start_idx + np.argmax(segment)\n",
    "            spindles.append((peak_idx / sfreq))\n",
    "\n",
    "            before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "            after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "            aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "            stacked_spindles.append(aligned_segment)\n",
    "\n",
    "    \n",
    "    return spindles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cf62aa2-2f73-468a-b2ab-2801ff3e4388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_spindles(eeg_raw, plot_name):\n",
    "\n",
    "\n",
    "    # copy previous function\n",
    "    filtered_data = eeg_raw.copy().pick_channels(['Fz'])\n",
    "    filtered_data.filter(l_freq=None, h_freq=35)\n",
    "    #filtered_data.resample(100)\n",
    "    sfreq = filtered_data.info['sfreq']  \n",
    "    channel_data = filtered_data.get_data(picks='Fz')[0]\n",
    "    \n",
    "    bandpassed_data = mne.filter.filter_data(channel_data, sfreq, l_freq=12, h_freq=16, l_trans_bandwidth=1.5, h_trans_bandwidth=1.5)\n",
    "    hilbert_signal = signal.hilbert(bandpassed_data)\n",
    "    envelope = np.abs(hilbert_signal)\n",
    "    \n",
    "    sliding_window = int(0.2 * sfreq)\n",
    "    smoothed_envelope = np.convolve(envelope, np.ones(sliding_window) / sliding_window, mode='same')\n",
    "\n",
    "    \n",
    "    threshold = np.percentile(smoothed_envelope, 75)\n",
    "    spindle_threshold = smoothed_envelope > threshold\n",
    "    #threshold = np.mean(smoothed_envelope) + 1.5 * np.std(smoothed_envelope)\n",
    "    #spindle_threshold = smoothed_envelope > threshold\n",
    "    \n",
    "    spindles = []\n",
    "    stacked_spindles = []\n",
    "    above_threshold = np.where(spindle_threshold)[0]\n",
    "    \n",
    "    if len(above_threshold) > 0:\n",
    "        start_idx = above_threshold[0]\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] > above_threshold[i - 1] + 1:\n",
    "                end_idx = above_threshold[i - 1]\n",
    "                duration = (end_idx - start_idx) / sfreq\n",
    "                if 0.5 <= duration <= 3:\n",
    "                    segment = bandpassed_data[start_idx:end_idx]\n",
    "                    peak_idx = start_idx + np.argmax(segment)\n",
    "                    \n",
    "                    before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "                    after_peak_idx = min(len(bandpassed_data), peak_idx + int(1.5 * sfreq))\n",
    "                    aligned_segment = bandpassed_data[before_peak_idx:after_peak_idx]\n",
    "                    stacked_spindles.append(aligned_segment)\n",
    "                \n",
    "                start_idx = above_threshold[i]\n",
    "    \n",
    "    # code for visualization\n",
    "    max_len = max(len(seg) for seg in stacked_spindles)\n",
    "    padded_stacked_spindles = [np.pad(seg, (0, max_len - len(seg)), constant_values=np.nan) for seg in stacked_spindles]\n",
    "    avg_spindle_waveform = np.nanmean(padded_stacked_spindles, axis=0)\n",
    "    time_axis = np.linspace(-1.5, 1.5, len(avg_spindle_waveform))\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(time_axis, avg_spindle_waveform, color=\"blue\", label=\"Mean Spindle\")\n",
    "    plt.axvline(0, color=\"red\", linestyle=\"--\", label=\"Peak (0s)\")\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude (µV)')\n",
    "    plt.title(plot_name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98ab508-f88f-4fd0-b36e-f97466a11d89",
   "metadata": {},
   "source": [
    "## *Slow-oscillation and spindle coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1eedac25-64f3-406a-9a00-7b78923c7424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_slow_oscillations_spindles_coupling_peaks(combined_raw):\n",
    "    slow_oscillations_peaks = detect_slow_oscillations_peaks(combined_raw)\n",
    "    slow_oscillations_times = detect_slow_oscillations_times(combined_raw)\n",
    "    spindles_peaks = detect_spindles_peaks(combined_raw)\n",
    "\n",
    "    coupling_times = []\n",
    "\n",
    "    for (start_time, end_time), (negative_peak, positive_peak) in zip(slow_oscillations_times, slow_oscillations_peaks):\n",
    "        for peak in spindles_peaks:\n",
    "            if negative_peak < peak < end_time:\n",
    "                coupling_times.append(peak)\n",
    "                # if the peak of the spindle is between the negative and positive trough\n",
    "                # add it to list coupling times\n",
    "\n",
    "    return coupling_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e0cb26-cf8a-43e4-ba61-f818b001730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_slow_oscillations_spindles_coupling_so_times(combined_raw):\n",
    "    slow_oscillations_peaks = detect_slow_oscillations_peaks(combined_raw)\n",
    "    slow_oscillations_times = detect_slow_oscillations_times(combined_raw)\n",
    "    spindles_peaks = detect_spindles_peaks(combined_raw)\n",
    "\n",
    "    coupling_times = []\n",
    "    coupling_times_so = []\n",
    "\n",
    "    # first detect the coupling events\n",
    "    for (start_time, end_time), (negative_peak, positive_peak) in zip(slow_oscillations_times, slow_oscillations_peaks):\n",
    "        for peak in spindles_peaks:\n",
    "            if negative_peak < peak < end_time:\n",
    "                coupling_times.append(peak)\n",
    "                # if the peak of the spindle is between the negative and positive trough\n",
    "                # add it to list coupling times\n",
    "\n",
    "    # then calculate the slow oscillation length\n",
    "    for start_time, end_time in slow_oscillations_times:\n",
    "        current_start_time = start_time\n",
    "        current_end_time = end_time\n",
    "        for coupling_peak in coupling_times:\n",
    "            if current_start_time < coupling_peak < current_end_time:\n",
    "                coupling_times_so.append((current_start_time, current_end_time))\n",
    "\n",
    "    return coupling_times_so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff78bb4-a566-4cf6-97c6-261bf54bf88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_slow_oscillations_spindles_coupling_spindles_times(combined_raw):\n",
    "    slow_oscillations_peaks = detect_slow_oscillations_peaks(combined_raw)\n",
    "    slow_oscillations_times = detect_slow_oscillations_times(combined_raw)\n",
    "    spindles_peaks = detect_spindles_peaks(combined_raw)\n",
    "    spindles_times = detect_spindles_times(combined_raw)\n",
    "\n",
    "    coupling_times = []\n",
    "    coupling_times_spindles = []\n",
    "\n",
    "    # first detect the coupling events\n",
    "    for (start_time, end_time), (negative_peak, positive_peak) in zip(slow_oscillations_times, slow_oscillations_peaks):\n",
    "        for peak in spindles_peaks:\n",
    "            if negative_peak < peak < end_time:\n",
    "                coupling_times.append(peak)\n",
    "                # if the peak of the spindle is between the negative and positive trough\n",
    "                # add it to list coupling times\n",
    "\n",
    "    for start_time, end_time in spindles_times:\n",
    "        current_start_time = start_time\n",
    "        current_end_time = end_time\n",
    "        for coupling_peak in coupling_times:\n",
    "            if current_start_time < coupling_peak < current_end_time:\n",
    "                coupling_times_spindles.append((current_start_time, current_end_time))\n",
    "\n",
    "    return coupling_times_spindles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757581be-5688-4067-aa4a-ade5190988de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_slow_oscillations_spindles_coupling_precise(combined_raw):\n",
    "    slow_oscillations_peaks = detect_slow_oscillations_peaks(combined_raw)\n",
    "    spindles_peaks = detect_spindles_peaks(combined_raw)\n",
    "    slow_oscillations_times = detect_slow_oscillations_times(combined_raw)\n",
    "\n",
    "    coupling_times = []\n",
    "\n",
    "    for negative_peak, positive_peak in slow_oscillations_peaks:\n",
    "        current_negative_peak = negative_peak\n",
    "        current_positive_peak  = positive_peak\n",
    "        current_middle = (current_positive_peak + current_negative_peak) // 2\n",
    "        for peak in spindles_peaks:\n",
    "            if peak == current_middle:\n",
    "                coupling_times.append(peak)\n",
    "\n",
    "    return coupling_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce906fc0-1f17-431a-93d6-2340df18d3e5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# *Raw EEG Data Participant 020 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8170d3-0300-4fb2-8511-918d7918d51e",
   "metadata": {},
   "source": [
    "### *Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575d3982-f5d8-4d7c-9df4-9e8029d59d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_020_file = r\"C:\\EEG DATA\\020\\eeg\\TMR.vhdr\"\n",
    "\n",
    "participant_020_raw = mne.io.read_raw_brainvision(vhdr_fname=participant_020_file, preload=True)\n",
    "\n",
    "# added preload=True here to import the whole dataset at once?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682aa0a4-5662-42e7-afb2-34224126fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(participant_020_raw)\n",
    "print(participant_020_raw.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ecd062-bb97-4952-a8ff-c6fceb43dff0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Plot with different duration times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed0b1b5-3d01-45d8-b0f9-76c6aad21fb3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# with no duration\n",
    "#mne.viz.set_3d_backend(\"notebook\")\n",
    "\n",
    "participant_020_raw.copy().compute_psd(fmax=250.0).plot(picks=\"data\", exclude=\"bads\", amplitude=False)\n",
    "# use 250.0 because have to use 1/4 of 1000.0 ?\n",
    "# to compute power spectral density\n",
    "participant_020_raw.copy().plot(n_channels=64)\n",
    "# default duration time in MNE is 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddda945-c5ef-445a-9164-cbf31214530f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# with duration = 5\n",
    "# data looks cleaner \n",
    "# more zoomed in view\n",
    "\n",
    "participant_020_raw.copy().compute_psd(fmax=250.0).plot(picks=\"data\", exclude=\"bads\", amplitude=False)\n",
    "# use 250.0 because have to use 1/4 of 1000.0 ?\n",
    "# to compute power spectral density\n",
    "participant_020_raw.copy().plot(duration=5, n_channels=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121fe9ba-126d-4b51-b5e9-8361127d333f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### bandpass filtering between 0.1 and 40 Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c0676a-ad63-4daf-941b-2538a4f9e71a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### attempt at using a filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2689e13f-a172-4276-b100-58a1124c045b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "filter_params = mne.filter.create_filter(participant_020_raw.get_data(), participant_020_raw.info[\"sfreq\"], l_freq=0.1, h_freq=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e70fa7-29ac-487d-a895-0e0e17d3017d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "mne.viz.plot_filter(filter_params, participant_020_raw.info[\"sfreq\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceeb582-4d7f-41ac-8c6e-8798f700f0b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Using a plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db2107c-6ad1-4e85-b661-10b0eac5abaa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# using plot function should work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f4444c-f9aa-48cc-a518-aecd2b6ef552",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "participant_020_raw.copy().pick([\"Fz\"]).plot(lowpass=0.1, highpass=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b601f1af-b14a-4a3b-b4ea-153035599956",
   "metadata": {},
   "source": [
    "### *Onset times for participant 020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683991a4-0ee4-4962-af2e-fac87a585d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data_onsets_020 = label_data_onsets['020']\n",
    "#label_data_onsets_020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5936e0a-3a5f-4456-9dd4-2a79635fdf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_020 = group_by_increment(label_data_onsets_020, increment=30)\n",
    "groups_020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e25076-5bc6-4cd4-94ec-bd5cd045dcc0",
   "metadata": {},
   "source": [
    "### *Plot Raw Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ec9ebc-7713-405b-bb73-cc2208681ffe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### With previous filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31750e9-df38-405f-90aa-f492e5daba3b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Extract segments\n",
    "segments = extract_segments(participant_020_raw, groups_020)\n",
    "\n",
    "if segments:\n",
    "    # if the segments do exist\n",
    "    combined_raw = mne.concatenate_raws(segments)\n",
    "    combined_raw.pick([\"Fz\"]).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331b2a9a-1c9f-49f6-b136-fc9275217aaa",
   "metadata": {},
   "source": [
    "#### *Combine raws + pick channel and filter directly in plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec00656-88d6-411e-bb59-45ee5729769c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check that EEG data looks correct\n",
    "\n",
    "# Extract segments\n",
    "segments_020 = extract_segments(participant_020_raw, groups_020)\n",
    "\n",
    "if segments_020:\n",
    "    combined_raw_020 = mne.concatenate_raws(segments_020)\n",
    "    combined_raw_020.set_eeg_reference(ref_channels = ['M1', 'M2'])\n",
    "    combined_raw_020.apply_function(lambda x: x * 1e6, picks='eeg')\n",
    "    # concatenates raw segments as if they were continuous\n",
    "    # boundaries of the raw files are annotated bad\n",
    "    combined_raw_020.pick([\"Fz\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3326e4-e84f-474b-b464-c2440e7b5830",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_raw_020.times[-1])\n",
    "print(participant_020_raw.times[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739dff08-1d16-434a-bc31-1e095e960b7f",
   "metadata": {},
   "source": [
    "### *Slow oscillation detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14612afc-1f23-4aa9-b1ba-c0d9db60ab25",
   "metadata": {},
   "source": [
    "##### *Function for slow oscillation detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1c6f3-e809-472f-a911-e2ede32a1a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without filter 0.16 - 1.25 Hz\n",
    "\n",
    "def detect_slow_oscillations_times_old(combined_raw):\n",
    "\n",
    "    # according to methods from Klinzing et al.(2016)\n",
    "\n",
    "    \n",
    "    # 1. low-pass filter of 3.5 Hz\n",
    "    \n",
    "    filtered_data = combined_raw.copy().filter(l_freq=None, h_freq=3.5)\n",
    "\n",
    "    # 2. downsample to 100 Hz\n",
    "    filtered_data.copy().resample(100)\n",
    "    sfreq = filtered_data.info['sfreq']\n",
    "    current_data = filtered_data.get_data(picks=\"Fz\")[0]\n",
    "    # only keep channel \"Fz\"\n",
    "\n",
    "    \n",
    "    # 3. find all positive-to-negative zero-crossings\n",
    "    \n",
    "    # zero_crossings = np.where( S!= 0)[0]\n",
    "    # can also save this somewhere for further detection of spindles\n",
    "    \n",
    "    S = np.diff(np.sign(current_data))\n",
    "    # np.sign returns an array with 1 (positive), 0 (zero), -1 (negative)\n",
    "    # np.diff calculates the difference between consecutive elements in an array\n",
    "    # positive value: transition from negative to positive\n",
    "    # negative value: transition from positive to negative\n",
    "    # when it's a zero, means that value stayed the same\n",
    "    zero_crossings = np.where(S == -2)[0]\n",
    "    # -2 is when a positive-to-negative zero-crossing occurs\n",
    "    # goes from 1 to -1 \n",
    "    # -1 - 1 = -2\n",
    "    # [0] extracts the actual array\n",
    "    # extracts the indices of interest from current_data (not S)\n",
    "\n",
    "\n",
    "    # 4. Detect peak potentials in each pair\n",
    "    slow_oscillations = []\n",
    "    negative_peaks = []\n",
    "    positive_peaks = []\n",
    "    peak_to_peak_amplitudes = []\n",
    "\n",
    "    # for loop for each pair\n",
    "    # to collect all the negative and positive peaks\n",
    "    # to further apply criteria\n",
    "    for i in range(0, len(zero_crossings) - 1, 2):\n",
    "        # loop through all the zero_crossings\n",
    "        # step of 2\n",
    "        start_idx = zero_crossings[i]\n",
    "        # assigns index of zero-crossing (representing start of potential SO)\n",
    "        # to start_idx\n",
    "        end_idx = zero_crossings[i + 1]\n",
    "        # assigns index of next zero-crossing (representing end of potential SO)\n",
    "        # to end_idx\n",
    "\n",
    "        # have identified index for the pair\n",
    "        \n",
    "        # extract data segment between crossings\n",
    "        segment_between_crossings = current_data[start_idx:end_idx]\n",
    "\n",
    "        # find peaks\n",
    "        positive_peak = np.max(segment_between_crossings)\n",
    "        negative_peak = np.min(segment_between_crossings)\n",
    "        peak_to_peak_amplitude = positive_peak - negative_peak\n",
    "\n",
    "        # store values\n",
    "        positive_peaks.append(positive_peak)\n",
    "        negative_peaks.append(negative_peak)\n",
    "        peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "\n",
    "    # calculate mean values for comparison\n",
    "    mean_negative_peak = np.mean(negative_peaks)\n",
    "    # mean_negative_peak = np.mean(negative_peaks) if negative_peaks else 0\n",
    "    mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes)\n",
    "    # mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes) if peak_to_peak_amplitudes else 0\n",
    "\n",
    "    # for loop\n",
    "    # to apply criteria\n",
    "    for i in range(0, len(zero_crossings) - 1, 2):\n",
    "\n",
    "        start_idx = zero_crossings[i]\n",
    "        end_idx = zero_crossings[i + 1]\n",
    "        \n",
    "        # extract data segment between crossings\n",
    "        segment_between_crossings = current_data[start_idx:end_idx]\n",
    "\n",
    "        # find positive and negative peaks\n",
    "        positive_peak = np.max(segment_between_crossings)\n",
    "        negative_peak = np.min(segment_between_crossings)\n",
    "        \n",
    "        # calculate peak-to-peak amplitude\n",
    "        peak_to_peak_amplitude = positive_peak - negative_peak\n",
    "\n",
    "        # calculate length of segment in seconds\n",
    "        segment_length = (end_idx - start_idx) / filtered_data.info['sfreq']\n",
    "\n",
    "        # apply criteria for slow oscillation detection\n",
    "        if (negative_peak <= 1.25 * mean_negative_peak and\n",
    "            # np.mean(current_data[current_data < 0])\n",
    "            # looks at the mean of all negative values in the data\n",
    "            # but should be looking at the mean of all negative peak amplitudes\n",
    "            \n",
    "            peak_to_peak_amplitude >= 1.25 * mean_peak_to_peak_amplitude and\n",
    "            0.8 <= segment_length <= 2):\n",
    "            # np.mean(np.ptp(current_data[zero_crossings[:-1:2]], axis=0))\n",
    "            # zero_crossings[:-1:2] selects every other zero-crossing index, except the last one\n",
    "            # np.ptp = peak to peak\n",
    "            # calculates ptp along the specified axis within the zero-crossing segments\n",
    "                slow_oscillations.append((start_idx / filtered_data.info['sfreq'], end_idx / filtered_data.info['sfreq']))\n",
    "\n",
    "    return slow_oscillations\n",
    "    # returns a list of tuples, in which each tuple represents the start and end times of\n",
    "    # a detected slow oscillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf519bad-fa41-41f8-91fc-ce4b72b68dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_slow_oscillations_peaks_old(combined_raw):\n",
    "\n",
    "    # according to methods from Klinzing et al.(2016)\n",
    "    \n",
    "    # 1. low-pass filter of 3.5 Hz\n",
    "    \n",
    "    filtered_data = combined_raw.copy().filter(l_freq=None, h_freq=3.5)\n",
    "\n",
    "    # 2. downsample to 100 Hz\n",
    "    filtered_data.copy().resample(100)\n",
    "    sfreq = filtered_data.info['sfreq']\n",
    "    current_data = filtered_data.get_data(picks=\"Fz\")[0]\n",
    "    # only keep channel \"Fz\"\n",
    "    \n",
    "    # 3. find all positive-to-negative zero-crossings\n",
    "    \n",
    "    # zero_crossings = np.where( S!= 0)[0]\n",
    "    # can also save this somewhere for further detection of spindles\n",
    "    \n",
    "    S = np.diff(np.sign(current_data))\n",
    "    # np.sign returns an array with 1 (positive), 0 (zero), -1 (negative)\n",
    "    # np.diff calculates the difference between consecutive elements in an array\n",
    "    # positive value: transition from negative to positive\n",
    "    # negative value: transition from positive to negative\n",
    "    # when it's a zero, means that value stayed the same\n",
    "    zero_crossings = np.where(S == -2)[0]\n",
    "    # -2 is when a positive-to-negative zero-crossing occurs\n",
    "    # goes from 1 to -1 \n",
    "    # -1 - 1 = -2\n",
    "    # [0] extracts the actual array\n",
    "    # extracts the indices of interest from current_data (not S)\n",
    "\n",
    "    # wouldn't we want to only look at negative values?\n",
    "\n",
    "    # 4. Detect peak potentials in each pair\n",
    "    slow_oscillations = []\n",
    "    negative_peaks = []\n",
    "    positive_peaks = []\n",
    "    peak_to_peak_amplitudes = []\n",
    "    slow_oscillations_peaks = []\n",
    "\n",
    "    # for loop for each pair\n",
    "    # to collect all the negative and positive peaks\n",
    "    # to further apply criteria\n",
    "    for i in range(0, len(zero_crossings) - 1, 2):\n",
    "        # loop through all the zero_crossings\n",
    "        # step of 2\n",
    "        start_idx = zero_crossings[i]\n",
    "        # assigns index of zero-crossing (representing start of potential SO)\n",
    "        # to start_idx\n",
    "        end_idx = zero_crossings[i + 1]\n",
    "        # assigns index of next zero-crossing (representing end of potential SO)\n",
    "        # to end_idx\n",
    "\n",
    "        # have identified index for the pair\n",
    "        \n",
    "        # extract data segment between crossings\n",
    "        segment_between_crossings = current_data[start_idx:end_idx]\n",
    "\n",
    "        # find peaks\n",
    "        positive_peak = np.max(segment_between_crossings)\n",
    "        negative_peak = np.min(segment_between_crossings)\n",
    "        peak_to_peak_amplitude = positive_peak - negative_peak\n",
    "\n",
    "        # store values\n",
    "        positive_peaks.append(positive_peak)\n",
    "        negative_peaks.append(negative_peak)\n",
    "        peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "\n",
    "    # calculate mean values for comparison\n",
    "    mean_negative_peak = np.mean(negative_peaks)\n",
    "    # mean_negative_peak = np.mean(negative_peaks) if negative_peaks else 0\n",
    "    mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes)\n",
    "    # mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes) if peak_to_peak_amplitudes else 0\n",
    "\n",
    "    # for loop\n",
    "    # to apply criteria\n",
    "    for i in range(0, len(zero_crossings) - 1, 2):\n",
    "\n",
    "        start_idx = zero_crossings[i]\n",
    "        end_idx = zero_crossings[i + 1]\n",
    "        \n",
    "        # extract data segment between crossings\n",
    "        segment_between_crossings = current_data[start_idx:end_idx]\n",
    "\n",
    "        # find positive and negative peaks\n",
    "        positive_peak = np.max(segment_between_crossings)\n",
    "        negative_peak = np.min(segment_between_crossings)\n",
    "        \n",
    "        # calculate peak-to-peak amplitude\n",
    "        peak_to_peak_amplitude = positive_peak - negative_peak\n",
    "\n",
    "        # calculate length of segment in seconds\n",
    "        segment_length = (end_idx - start_idx) / filtered_data.info['sfreq']\n",
    "\n",
    "        # find times of positive and negative peaks\n",
    "        segment_positive_peak_index = np.argmax(segment_between_crossings)\n",
    "        segment_negative_peak_index = np.argmin(segment_between_crossings)\n",
    "        # this is the index in the segment\n",
    "\n",
    "        positive_peak_index = start_idx + segment_positive_peak_index\n",
    "        negative_peak_index = start_idx + segment_negative_peak_index\n",
    "\n",
    "        # apply criteria for slow oscillation detection\n",
    "        if (negative_peak <= 1.25 * mean_negative_peak and\n",
    "            # np.mean(current_data[current_data < 0])\n",
    "            # looks at the mean of all negative values in the data\n",
    "            # but should be looking at the mean of all negative peak amplitudes\n",
    "            \n",
    "            peak_to_peak_amplitude >= 1.25 * mean_peak_to_peak_amplitude and\n",
    "            0.8 <= segment_length <= 2):\n",
    "            # np.mean(np.ptp(current_data[zero_crossings[:-1:2]], axis=0))\n",
    "            # zero_crossings[:-1:2] selects every other zero-crossing index, except the last one\n",
    "            # np.ptp = peak to peak\n",
    "            # calculates ptp along the specified axis within the zero-crossing segments\n",
    "                slow_oscillations.append((start_idx / filtered_data.info['sfreq'], end_idx / filtered_data.info['sfreq']))\n",
    "                slow_oscillations_peaks.append((negative_peak_index / filtered_data.info['sfreq'], positive_peak_index /  filtered_data.info['sfreq']))\n",
    "\n",
    "    return slow_oscillations_peaks\n",
    "    # returns a list of tuples, in which each tuple represents the start and end times of\n",
    "    # a detected slow oscillation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b098754-af40-4cf1-a19e-99fc18a8981e",
   "metadata": {},
   "source": [
    "##### *slow_oscillations_020_times: slow oscillations times returned as a list of np.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e947de-8473-4d51-a6ac-88fe16b03092",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_oscillations_020_times = detect_slow_oscillations_times(combined_raw_020)\n",
    "#slow_oscillations_020_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5e4d16-97eb-4eaa-93a0-0bef9f56f098",
   "metadata": {},
   "source": [
    "##### *slow_oscillations_020_peaks: slow oscillations peaks returned as a list of np.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2baf584-ac51-4b55-99b0-03d7cd3be36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_oscillations_020_peaks = detect_slow_oscillations_peaks(combined_raw_020)\n",
    "#slow_oscillations_020_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5085db-3d9c-4f52-b433-d4017deebd95",
   "metadata": {},
   "source": [
    "##### *sanity check of length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc97ac8a-e8b2-42ae-ba75-25ac96b2c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(slow_oscillations_020_times))\n",
    "print(len((slow_oscillations_020_peaks)))\n",
    "# both are the same length so functions should be working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fb72bb-e05f-4b4e-a1d5-0dd7dfbbc772",
   "metadata": {},
   "source": [
    "##### *Average slow oscillation visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12f4e49-1241-4bf1-aa60-a97a6af277ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_and_stack_slow_oscillations_trough(combined_raw_020, slow_oscillations_020_times, 'Average Slow Oscillation (Trough-centered) for Participant 020 (0.16-1.25 Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a679f55e-5e7f-42c2-9d6b-909dc759c7b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Visualize individual slow oscillations (first 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ea0727-cf03-421e-9a1b-328e6613ef9c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# function to visualise all slow oscillations\n",
    "# here only look at 10 slow_oscillations\n",
    "\n",
    "def visualize_slow_oscillations(raw_data, slow_oscillations, channel_name, num_oscillations=10):\n",
    "\n",
    "    # Get the EEG data for the channel of interest\n",
    "    channel_data = raw_data.get_data(picks=channel_name)[0]\n",
    "    sfreq = raw_data.info['sfreq']\n",
    "\n",
    "    # Filter the data to keep only frequencies between 0.1 and 1.25 Hz\n",
    "    filtered_data = raw_data.copy().filter(l_freq=0.1, h_freq=1.25)\n",
    "    filtered_channel_data = filtered_data.get_data(picks=channel_name)[0]\n",
    "    \n",
    "\n",
    "    # Loop through the first ten slow oscillations\n",
    "    for i, (start_time, end_time) in enumerate(slow_oscillations[:num_oscillations]):\n",
    "        # Convert start and end times to sample indices\n",
    "        start_idx = int(start_time * sfreq)\n",
    "        end_idx = int(end_time * sfreq)\n",
    "\n",
    "        # Extract the slow oscillation segment\n",
    "        segment = filtered_channel_data[start_idx:end_idx]  # Use filtered data here\n",
    "        # to get duration of a segment in seconds\n",
    "        # divide number of samples in the segment\n",
    "        # by number of samples taken per second (sampling frequency)\n",
    "\n",
    "        # Find peak and trough indices\n",
    "        peak_idx = np.argmax(segment)\n",
    "        trough_idx = np.argmin(segment)\n",
    "\n",
    "        # Visualize the individual slow oscillation with peak and trough marked\n",
    "        time_axis = np.arange(0, len(segment)) / sfreq  \n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(time_axis, segment)\n",
    "        plt.plot(time_axis[peak_idx], segment[peak_idx], \"x\", color='red', label='peak')\n",
    "        plt.plot(time_axis[trough_idx], segment[trough_idx], \"x\", color='blue', label='trough')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude (µV)')\n",
    "        plt.title(f'Slow Oscillation {i + 1} from {start_time:.2f}s to {end_time:.2f}s (0.1-1.25 Hz)')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage:\n",
    "visualize_slow_oscillations(combined_raw_020, slow_oscillations_020_times, 'Fz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7052b19-b80a-4b97-9af7-1b23661dfa46",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "combined_raw_020.compute_psd(fmax=30,average=None).plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd32e01c-7ab8-4da7-a4cb-52b2433c7991",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Spindle detection with peak frequency (Klinzing et al., 2016) with visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b963a8-d2b1-4c00-a1e5-7c219e9d8908",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import scipy.signal as signal\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def detect_spindles_peak_frequency(eeg_raw):\n",
    "    # Parameters\n",
    "    #channel = 'Fz'\n",
    "    \n",
    "    # 1. Low-pass filter of 35 Hz\n",
    "    \n",
    "    filtered_data = eeg_raw.copy().pick_channels(['Fz'])\n",
    "    filtered_data.filter(l_freq=None, h_freq=35)\n",
    "    \n",
    "    # 2. Downsample at 100 Hz (100 samples per second)\n",
    "    \n",
    "    filtered_data.resample(100)\n",
    "    sfreq = filtered_data.info['sfreq']  \n",
    "    # update to new sampling frequency\n",
    "    # because used later in the code\n",
    "    channel_data = filtered_data.get_data(picks='Fz')[0]\n",
    "    # extract the filtered data\n",
    "    \n",
    "    # 3. Identify individual peak frequencies in sleep power spectra for fast spindles\n",
    "    # and detect peak frequency\n",
    "\n",
    "    \n",
    "    #freqs, psd = signal.welch(channel_data, fs=sfreq, nperseg=int(sfreq * 2))\n",
    "    # to obtain power spectral density\n",
    "    # using Welch's method\n",
    "    # using 2 seconds of data per segment\n",
    "\n",
    "    # first compute the power spectral density\n",
    "    psd_raw = filtered_data.compute_psd(method='welch')\n",
    "    # use Welch's method (commonly used)\n",
    "    # average consecutive FFTs of small windows of the signal\n",
    "    freqs = psd_raw.freqs\n",
    "    psd = psd_raw.get_data(picks='Fz')[0]\n",
    "\n",
    "    # then select the spindle range\n",
    "    spindle_range = (freqs >= 12) & (freqs <= 15)\n",
    "    spindle_range_freqs = freqs[spindle_range]\n",
    "    spindle_psd = psd[spindle_range]\n",
    "    # selecting PSD values within spindle range (12-15 Hz)\n",
    "\n",
    "    # identify all the peaks\n",
    "    peaks, _ = find_peaks(spindle_psd)\n",
    "    # this gives indices\n",
    "    # method from scipy.signal\n",
    "\n",
    "    # then identify the peak frequency in the PSD with spindle range\n",
    "    peak_freq = spindle_range_freqs[peaks[np.argmax(psd[spindle_range][peaks])]]\n",
    "    # peaks[np.argmax(psd[spindle_mask][peaks])]]: index of highest PSD value among detected peaks\n",
    "    # spindle_range_freqs maps it to actual frequency\n",
    "    \n",
    "    # 4: Band-pass filter centered at peak frequency\n",
    "    \n",
    "    bandpass_freqs = (peak_freq - 3 / 2, peak_freq + 3 / 2)\n",
    "    # band-pass width of 3 Hz\n",
    "    bandpassed_data = mne.filter.filter_data(channel_data, sfreq, l_freq=bandpass_freqs[0], h_freq=bandpass_freqs[1])\n",
    "    \n",
    "    # 5: Calculate amplitude by applying Hilbert transformation\n",
    "\n",
    "    hilbert_signal = signal.hilbert(bandpassed_data)\n",
    "    # apply hilbert transformation to bandpassed data\n",
    "    # gives analytic signal with amplitude and phase information\n",
    "    envelope = np.abs(hilbert_signal)\n",
    "    # take the absolute part of the hilbert signal\n",
    "    # gives the envelope: amplitude modulation\n",
    "    # how strength of oscillations change over time\n",
    "    # size of sliding window\n",
    "    \n",
    "    # 6: Perform smoothing with a sliding window of 0.2 seconds\n",
    "    # this removes high-frequency noise\n",
    "    \n",
    "    sliding_window = int(0.2 * sfreq)\n",
    "    smoothed_envelope = np.convolve(envelope, np.ones(sliding_window) / sliding_window, mode='same')\n",
    "    # convolving envelope with a uniform filter over the sliding window\n",
    "    # convolution takes rolling average of 20 samples at a time\n",
    "    # smooth the signal with the average of values in the window\n",
    "    # in the smoothed envelope, can detect regions with higher amplitude \n",
    "    # which is when a spindle event occurs\n",
    "    # np.ones: creates a filter kernel\n",
    "    # have a filter where the sum of all elements equals 1\n",
    "    # mode = 'same': so that output of convolution has same length as original envelope\n",
    "\n",
    "    # 7. Define spindle detection threshold\n",
    "\n",
    "    threshold = np.mean(smoothed_envelope) + 1.5 * np.std(smoothed_envelope)\n",
    "    spindle_threshold = smoothed_envelope > threshold\n",
    "    \n",
    "    # 8. Define peaks and troughs\n",
    "    \n",
    "    spindles = []\n",
    "    above_threshold = np.where(spindle_threshold)[0]\n",
    "    # returns indices where signal above the threshold\n",
    "    stacked_spindles = []\n",
    "    \n",
    "    if len(above_threshold) > 0:\n",
    "        # checking it's not empty\n",
    "        start_idx = above_threshold[0]\n",
    "        # would be the start of a potential spindle\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] > above_threshold[i - 1] + 1:  \n",
    "                # if above threshold[1] > above_threshold[0] + 1\n",
    "                # because all indices should be separated by 1\n",
    "                # so here detects gaps\n",
    "                end_idx = above_threshold[i - 1]\n",
    "                # so if above condition is true, this is the end of the spindle\n",
    "                duration = (end_idx - start_idx) / sfreq\n",
    "                if 0.5 <= duration <= 3:\n",
    "                    # only keep spindles lasting 0.5 to 3 seconds\n",
    "                    segment = bandpassed_data[start_idx:end_idx]\n",
    "                    # extract EEG segment corresponding to detected spindle\n",
    "                    peak_idx = start_idx + np.argmax(segment) \n",
    "                    # extract the peak of the spindle\n",
    "                    # this will be useful for later\n",
    "                    spindles.append(f\"Spindle detected from {start_idx / sfreq:.2f}s to {end_idx / sfreq:.2f}s, peak at {peak_idx / sfreq:.2f}s\")\n",
    "                    # all the spindles are stored in spindles\n",
    "                    \n",
    "                    # Aligning spindles at peak for visualization\n",
    "                    before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "                    after_peak_idx = min(len(bandpassed_data), peak_idx + int(1.5 * sfreq))\n",
    "                    # extracting 1.5 seconds before and after peak\n",
    "                    # max and min are used for out of bounds situations\n",
    "                    aligned_segment = bandpassed_data[before_peak_idx:after_peak_idx]\n",
    "                    stacked_spindles.append(aligned_segment)\n",
    "                    # the aligned segment is saved in stacked spindles\n",
    "                \n",
    "                start_idx = above_threshold[i]\n",
    "    \n",
    "    # Visualization of the average spindle waveform\n",
    "    # input directly in function because means less repeating\n",
    "    # same method as slow oscillation\n",
    "    if stacked_spindles:\n",
    "        # if stacked_spindles does exist\n",
    "        max_len = max(len(seg) for seg in stacked_spindles)\n",
    "        padded_stacked_spindles = [np.pad(seg, (0, max_len - len(seg)), constant_values=np.nan) for seg in stacked_spindles]\n",
    "        # take the max spindle length\n",
    "        # and pad the short ones with NaN\n",
    "        avg_spindle_waveform = np.nanmean(padded_stacked_spindles, axis=0)\n",
    "        # take the average waveform\n",
    "        # of all the padded stacked spindles\n",
    "        time_axis = np.linspace(-1.5, 1.5, len(avg_spindle_waveform))\n",
    "        \n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(time_axis, avg_spindle_waveform, color=\"blue\", label=\"Mean Spindle\")\n",
    "        plt.axvline(0, color=\"red\", linestyle=\"--\", label=\"Peak (0s)\")\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude (µV)')\n",
    "        plt.title('Average Spindle (Peak-centered) for Participant 020')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return spindles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83acc801-51f1-4019-bd88-549c70d48853",
   "metadata": {},
   "source": [
    "##### Times for spindles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019e973a-9d9a-4a3b-b243-2fe34bfdd2b0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "spindles_020_peak_frequency = detect_spindles_peak_frequency(combined_raw_020)\n",
    "spindles_020_peak_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789fe427-4235-4488-89e1-209ccccf6dd9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "len(spindles_020_peak_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a04ef93-900b-4a24-93dc-95b89b0828f3",
   "metadata": {},
   "source": [
    "### *Spindle detection without peak frequency (Klinzing et al., 2016): correct one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb40c0c-3082-49d2-8d72-b39097ebee14",
   "metadata": {},
   "source": [
    "##### *Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b299a49-5557-42c6-866d-e9a0343b42df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as signal\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def detect_spindles_times_old(eeg_raw):\n",
    "    # Parameters\n",
    "    #channel = 'Fz'\n",
    "    \n",
    "    # 1. Low-pass filter of 35 Hz\n",
    "    \n",
    "    filtered_data = eeg_raw.copy().pick_channels(['Fz'])\n",
    "    filtered_data.filter(l_freq=None, h_freq=35)\n",
    "    \n",
    "    # 2. Downsample at 100 Hz (100 samples per second)\n",
    "    \n",
    "    filtered_data.resample(100)\n",
    "    sfreq = filtered_data.info['sfreq']  \n",
    "    # update to new sampling frequency\n",
    "    # because used later in the code\n",
    "    channel_data = filtered_data.get_data(picks='Fz')[0]\n",
    "    # extract the filtered data\n",
    "    \n",
    "    # 3: Filter EEG data between 12 and 16 Hz, with a wide transition bandwidth of 1.5 Hz\n",
    "    \n",
    "    bandpassed_data = mne.filter.filter_data(channel_data, sfreq, l_freq=12, h_freq=16, l_trans_bandwidth=1.5, h_trans_bandwidth=1.5)\n",
    "    \n",
    "    # 4: Calculate amplitude by applying Hilbert transformation\n",
    "\n",
    "    hilbert_signal = signal.hilbert(bandpassed_data)\n",
    "    # apply hilbert transformation to bandpassed data\n",
    "    # gives analytic signal with amplitude and phase information\n",
    "    envelope = np.abs(hilbert_signal)\n",
    "    # take the absolute part of the hilbert signal\n",
    "    # also the instantaneous power of the signal\n",
    "    # gives the envelope: amplitude modulation\n",
    "    # how strength of oscillations change over time\n",
    "    # size of sliding window\n",
    "    \n",
    "    # 5: Perform smoothing with a sliding window of 0.2 seconds\n",
    "    # this removes high-frequency noise\n",
    "    \n",
    "    sliding_window = int(0.2 * sfreq)\n",
    "    smoothed_envelope = np.convolve(envelope, np.ones(sliding_window) / sliding_window, mode='same')\n",
    "    # convolving envelope with a uniform filter over the sliding window\n",
    "    # convolution takes rolling average of 20 samples at a time\n",
    "    # smooth the signal with the average of values in the window\n",
    "    # in the smoothed envelope, can detect regions with higher amplitude \n",
    "    # which is when a spindle event occurs\n",
    "    # np.ones: creates a filter kernel\n",
    "    # have a filter where the sum of all elements equals 1\n",
    "    # this filter is replaced by the average of the 20 surrounding samples\n",
    "    # convolution between envelope and averaging filter\n",
    "    # mode = 'same': so that output of convolution has same length as original envelope\n",
    "\n",
    "    # 7. Define spindle detection threshold\n",
    "\n",
    "    threshold = np.mean(smoothed_envelope) + 1.5 * np.std(smoothed_envelope)\n",
    "    spindle_threshold = smoothed_envelope > threshold\n",
    "    # first only look at the 1.5 SD over filtered signal\n",
    "    # will look at the duration later\n",
    "    \n",
    "    # 8. Detect spindles and define peaks and troughs for visualisation\n",
    "    \n",
    "    spindles = []\n",
    "    # initialize list with spindles\n",
    "    above_threshold = np.where(spindle_threshold)[0]\n",
    "    # returns indices where signal above the threshold\n",
    "    stacked_spindles = []\n",
    "    # initialize list for stacking the spindles for the visualisation\n",
    "    # contains aligned spindles at peak\n",
    "    \n",
    "    if len(above_threshold) > 0:\n",
    "        # checking it's not empty\n",
    "        start_idx = above_threshold[0]\n",
    "        # would be the start of a potential spindle\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] > above_threshold[i - 1] + 1:  \n",
    "                # if above threshold[1] > above_threshold[0] + 1\n",
    "                # because all indices should be separated by 1\n",
    "                # so here detects gaps\n",
    "                end_idx = above_threshold[i - 1]\n",
    "                # so if above condition is true, this is the end of the spindle\n",
    "                duration = (end_idx - start_idx) / sfreq\n",
    "                if 0.5 <= duration <= 3:\n",
    "                    # only keep spindles lasting 0.5 to 3 seconds\n",
    "                    segment = bandpassed_data[start_idx:end_idx]\n",
    "                    # extract EEG segment corresponding to detected spindle\n",
    "                    peak_idx = start_idx + np.argmax(segment) \n",
    "                    # extract the peak of the spindle\n",
    "                    # this will be useful for later\n",
    "                    #spindles.append(f\"Spindle detected from {start_idx / sfreq:.2f}s to {end_idx / sfreq:.2f}s, peak at {peak_idx / sfreq:.2f}s\")\n",
    "                    spindles.append((start_idx / sfreq, end_idx / sfreq))\n",
    "                    #spindles.append(np.float64(end_idx / sfreq))\n",
    "                    # all the spindles are stored in spindles\n",
    "                    \n",
    "                    # Aligning spindles at peak for visualization\n",
    "                    before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "                    # still in the for loop, so this is the peak index of individual peak\n",
    "                    after_peak_idx = min(len(bandpassed_data), peak_idx + int(1.5 * sfreq))\n",
    "                    # extracting 1.5 seconds before and after peak\n",
    "                    # max and min are used for out of bounds situations at the start and end of EEG data\n",
    "                    aligned_segment = bandpassed_data[before_peak_idx:after_peak_idx]\n",
    "                    stacked_spindles.append(aligned_segment)\n",
    "                    # the aligned segment is saved in stacked spindles\n",
    "                \n",
    "                start_idx = above_threshold[i]\n",
    "                # update the start index for the for loop\n",
    "    \n",
    "    return spindles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5988f09f-7551-4cb9-bd73-34da55c18932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as signal\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def detect_spindles_peaks_old(eeg_raw):\n",
    "    # Parameters\n",
    "    #channel = 'Fz'\n",
    "    \n",
    "    # 1. Low-pass filter of 35 Hz\n",
    "    \n",
    "    filtered_data = eeg_raw.copy().pick_channels(['Fz'])\n",
    "    filtered_data.filter(l_freq=None, h_freq=35)\n",
    "    \n",
    "    # 2. Downsample at 100 Hz (100 samples per second)\n",
    "    \n",
    "    filtered_data.resample(100)\n",
    "    sfreq = filtered_data.info['sfreq']  \n",
    "    # update to new sampling frequency\n",
    "    # because used later in the code\n",
    "    channel_data = filtered_data.get_data(picks='Fz')[0]\n",
    "    # extract the filtered data\n",
    "    # call [0] to get the 1D signal\n",
    "    # because otherwise get_data() returns a 2D array of shape (1, n_times)\n",
    "    \n",
    "    # 3: Filter EEG data between 12 and 16 Hz, with a wide transition bandwidth of 1.5 Hz\n",
    "    \n",
    "    bandpassed_data = mne.filter.filter_data(channel_data, sfreq, l_freq=12, h_freq=16, l_trans_bandwidth=1.5, h_trans_bandwidth=1.5)\n",
    "    \n",
    "    # 4: Calculate amplitude by applying Hilbert transformation\n",
    "\n",
    "    hilbert_signal = signal.hilbert(bandpassed_data)\n",
    "    # apply hilbert transformation to bandpassed data\n",
    "    # gives analytic signal with amplitude and phase information\n",
    "    envelope = np.abs(hilbert_signal)\n",
    "    # take the absolute part of the hilbert signal\n",
    "    # also the instantaneous power of the signal\n",
    "    # gives the envelope: amplitude modulation\n",
    "    # how strength of oscillations change over time\n",
    "    # size of sliding window\n",
    "    \n",
    "    # 5: Perform smoothing with a sliding window of 0.2 seconds\n",
    "    # this removes high-frequency noise\n",
    "    \n",
    "    sliding_window = int(0.2 * sfreq)\n",
    "    smoothed_envelope = np.convolve(envelope, np.ones(sliding_window) / sliding_window, mode='same')\n",
    "    # convolving envelope with a uniform filter over the sliding window\n",
    "    # convolution takes rolling average of 20 samples at a time\n",
    "    # smooth the signal with the average of values in the window\n",
    "    # in the smoothed envelope, can detect regions with higher amplitude \n",
    "    # which is when a spindle event occurs\n",
    "    # np.ones: creates a filter kernel\n",
    "    # have a filter where the sum of all elements equals 1\n",
    "    # this filter is replaced by the average of the 20 surrounding samples\n",
    "    # convolution between envelope and averaging filter\n",
    "    # mode = 'same': so that output of convolution has same length as original envelope\n",
    "\n",
    "    # 7. Define spindle detection threshold\n",
    "\n",
    "    threshold = np.mean(smoothed_envelope) + 1.5 * np.std(smoothed_envelope)\n",
    "    spindle_threshold = smoothed_envelope > threshold\n",
    "    # first only look at the 1.5 SD over filtered signal\n",
    "    # will look at the duration later\n",
    "    \n",
    "    # 8. Detect spindles and define peaks and troughs for visualisation\n",
    "    \n",
    "    spindles = []\n",
    "    # initialize list with spindles\n",
    "    above_threshold = np.where(spindle_threshold)[0]\n",
    "    # returns indices where signal above the threshold\n",
    "    stacked_spindles = []\n",
    "    # initialize list for stacking the spindles for the visualisation\n",
    "    # contains aligned spindles at peak\n",
    "    \n",
    "    if len(above_threshold) > 0:\n",
    "        # checking it's not empty\n",
    "        start_idx = above_threshold[0]\n",
    "        # would be the start of a potential spindle\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] > above_threshold[i - 1] + 1:  \n",
    "                # if above threshold[1] > above_threshold[0] + 1\n",
    "                # because all indices should be separated by 1\n",
    "                # so here detects gaps\n",
    "                end_idx = above_threshold[i - 1]\n",
    "                # so if above condition is true, this is the end of the spindle\n",
    "                duration = (end_idx - start_idx) / sfreq\n",
    "                if 0.5 <= duration <= 3:\n",
    "                    # only keep spindles lasting 0.5 to 3 seconds\n",
    "                    segment = bandpassed_data[start_idx:end_idx]\n",
    "                    # extract EEG segment corresponding to detected spindle\n",
    "                    peak_idx = start_idx + np.argmax(segment) \n",
    "                    # extract the peak of the spindle\n",
    "                    # this will be useful for later\n",
    "                    #spindles.append(f\"Spindle detected from {start_idx / sfreq:.2f}s to {end_idx / sfreq:.2f}s, peak at {peak_idx / sfreq:.2f}s\")\n",
    "                    spindles.append((peak_idx / sfreq))\n",
    "                    # all the spindles are stored in spindles\n",
    "                    \n",
    "                    # Aligning spindles at peak for visualization\n",
    "                    before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "                    # still in the for loop, so this is the peak index of individual peak\n",
    "                    after_peak_idx = min(len(bandpassed_data), peak_idx + int(1.5 * sfreq))\n",
    "                    # extracting 1.5 seconds before and after peak\n",
    "                    # max and min are used for out of bounds situations at the start and end of EEG data\n",
    "                    aligned_segment = bandpassed_data[before_peak_idx:after_peak_idx]\n",
    "                    stacked_spindles.append(aligned_segment)\n",
    "                    # the aligned segment is saved in stacked spindles\n",
    "                \n",
    "                start_idx = above_threshold[i]\n",
    "                # update the start index for the for loop\n",
    "\n",
    "    \n",
    "    return spindles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492ae7bc-d7a1-4697-975a-80c2e413d408",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### *Spindle visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2150cadb-e0b0-441e-ac95-a2cc7d19729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_spindles(combined_raw_020, 'Average Spindle (Peak-centered) for Participant 020 (12-16 Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fdf415-b74a-4c2a-b2ac-d20abed37b3a",
   "metadata": {},
   "source": [
    "##### *spindles_020_times : spindle times returned as list of np.floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18034767-7bbc-4483-9dd6-bc3d7c4e4ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spindles_020_times = detect_spindles_times(combined_raw_020)\n",
    "spindles_020_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabfb2c6-4d61-4480-b8ca-30b188e741ab",
   "metadata": {},
   "source": [
    "##### *spindles_020_peaks: spindle peak time returned as a list of np.floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a4e1c-5001-43de-b657-b0ef5e5af0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spindles_020_peaks = detect_spindles_peaks(combined_raw_020)\n",
    "spindles_020_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5211b259-996c-4c81-9866-6cb027939acf",
   "metadata": {},
   "source": [
    "##### sanity check of length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9149fcd9-9efa-4309-be75-335c435442de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(spindles_020_times))\n",
    "print(len(spindles_020_peaks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a6a25d-7249-4bdf-9ba9-2df7363438f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Spindle detection (Staresina et al., 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b881c13-6b22-4f62-8e73-ecff0c47185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "\n",
    "\n",
    "def detect_spindles_staresina(raw_data, channel_name):\n",
    "\n",
    "    # 1. Filter data between 12-16 Hz\n",
    "    filtered_data = raw_data.copy().filter(l_freq=12, h_freq=16)\n",
    "    filtered_data_array = filtered_data.get_data(picks=channel_name)[0]  # Extract data array\n",
    "\n",
    "    # 2. Calculate RMS signal using a moving average of 200 ms\n",
    "    window_size = int(0.2 * raw_data.info['sfreq'])  # Window size in samples\n",
    "    rms_signal = np.convolve(filtered_data_array**2, np.ones(window_size), 'same') / window_size\n",
    "    # convolution is to slide through the data\n",
    "    rms_signal = np.sqrt(rms_signal)\n",
    "\n",
    "    # 3. Apply criteria\n",
    "    amplitude_threshold = np.percentile(rms_signal, 75)  # 75th percentile of RMS values\n",
    "    min_duration = 0.5  # Minimum duration in seconds\n",
    "    max_duration = 3.0  # Maximum duration in seconds\n",
    "\n",
    "    # 4. Detect spindles\n",
    "    spindles = []\n",
    "    above_threshold = np.where(rms_signal > amplitude_threshold)[0]\n",
    "\n",
    "    if len(above_threshold) > 0:\n",
    "        start_idx = above_threshold[0]\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] - above_threshold[i - 1] > 1:  # Check for discontinuity\n",
    "                duration = (above_threshold[i - 1] - start_idx + 1) / raw_data.info['sfreq']\n",
    "                if min_duration <= duration <= max_duration:\n",
    "                    spindles.append((start_idx / raw_data.info['sfreq'], (above_threshold[i - 1] + 1) / raw_data.info['sfreq']))\n",
    "                start_idx = above_threshold[i]  # Start new segment\n",
    "\n",
    "        # Check last segment\n",
    "        duration = (above_threshold[-1] - start_idx + 1) / raw_data.info['sfreq']\n",
    "        if min_duration <= duration <= max_duration:\n",
    "            spindles.append((start_idx / raw_data.info['sfreq'], (above_threshold[-1] + 1) / raw_data.info['sfreq']))\n",
    "\n",
    "    return spindles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75a6411-81b1-41f9-8a8a-f1656cba0148",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "spindles_staresina_020 = detect_spindles_staresina(combined_raw_020, 'Fz')\n",
    "\n",
    "for start_time, end_time in spindles_staresina_020:\n",
    "    print(f\"Spindle detected from {start_time:.2f}s to {end_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa3a878-536d-4693-9da5-f9ab32744cc6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "len(spindles_staresina_020)\n",
    "\n",
    "# Using Staresina et al. (2015): 2211 spindles detected\n",
    "# Using Klinzing et al. (2016): 512 spindles detected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba18ca88-d06c-461d-b5d9-161593eccaa6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### *Summary number of slow oscillations and spindles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e9492-69ed-44c9-9230-49a39eead7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(slow_oscillations_020_times))\n",
    "print(len(spindles_020_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0282b734-faeb-415b-934b-d095a89565c5",
   "metadata": {},
   "source": [
    "Number of slow oscillations: 436\n",
    "Number of spindles: 503\n",
    "(note that although the lists contain values for start and end times, the structure of the list counts those start and end times as one value, so we are indeed checking the amount of slow oscillations and spindles).\n",
    "\n",
    "It appears that slow oscillations are more prominent than spindles ? (Solano et al., 2021), so either slow oscillation code is too conservative or spindle code is too lenient.\n",
    "\n",
    "Probably due to the Klinzing et al. (2016) criterion for slow oscillation detection, defined according to subject's average peak in SO compared to SD across all participants for spindles.\n",
    "\n",
    "Also we used a 12-16 Hz criteria for the spindles although Klinzing et al. (2016) used 12-15 Hz. Furthermore, we slightly adapted their method, for example used Hilbert transform instead of RMS, and performed smoothing only once.\n",
    "\n",
    "Finally, the analysis focused on channel Fz, which was not necesarily the case in Klinzing et al. (2016). \n",
    "\n",
    "In comparison, Klinzing et al. (2016) found a total of 541.82 +/- 40.43 SOs per subject during NREM sleep stages 2 and 4, and 78.27 +/- 8.72 SOs that co-occurred with a fast spindle. \n",
    "\n",
    "For the spindles, they found 191.09 +/- 14.21 fast spindles occurring in channel C3, 436.09 +/- 53.73 fast spindles occurring in channel Cz, and 211.64 +/- 24.23 fast spindles occurring in channel C4. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d32fbae-ca64-41ae-a8c3-a62d40a06814",
   "metadata": {},
   "source": [
    "### *Slow oscillation spindle coupling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d663d9bb-ae6a-42f0-846e-cab800a5e495",
   "metadata": {},
   "source": [
    "##### *Function where output is coupling time (spindle peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41122c72-a1aa-4f38-9ecf-fe93db17f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupling_020_peaks = detect_slow_oscillations_spindles_coupling_peaks(combined_raw_020)\n",
    "coupling_020_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb55dc-9092-49bf-9475-5a027d860110",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coupling_020_peaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82324b06-2d30-4ed9-8448-07884de5dea8",
   "metadata": {},
   "source": [
    "##### *Function where output is slow oscillation length when there is coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38088d6e-3daa-4ac5-a802-180a00920a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupling_020_so_times = detect_slow_oscillations_spindles_coupling_so_times(combined_raw_020)\n",
    "coupling_020_so_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac0545-c50f-415d-b642-2ac2b59085ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coupling_020_so_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9eed73-e5c4-4815-ad2e-594628c008b3",
   "metadata": {},
   "source": [
    "##### *Function where output is spindle length when there is coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e67a639-305a-4885-99bd-cd7bdfe325bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupling_020_spindles_times = detect_slow_oscillations_spindles_coupling_spindles_times(combined_raw_020)\n",
    "coupling_020_spindles_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0ade57-a5b7-4594-9436-a75d93f119dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coupling_020_spindles_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b29287-e779-4aea-a350-b5cfc34f7801",
   "metadata": {},
   "source": [
    "##### *Function which detects coupling when spindle peak occurs precisely at slow oscillation midpoint between negative and positive peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1796efb-f2d6-4063-abee-4c16626a240c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupling_020_precise = detect_slow_oscillations_spindles_coupling_precise(combined_raw_020)\n",
    "coupling_020_precise\n",
    "# so the coupling detected before is not happening exactly in the middle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32f4134-5c0d-4824-b140-35613cadfd1d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### *Visualization of average slow oscillation when coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c19d3-a3bf-41b0-ae36-8eb24e955cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_and_stack_slow_oscillations_trough(combined_raw_020, coupling_020_so_times, 'Average Coupled Slow Oscillation (Trough-centered) for Participant 020 (0.3-1.25 Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a57e99f-030c-4b18-884d-02e640173613",
   "metadata": {},
   "source": [
    "The average slow oscillation when there is a coupling does not look exactly like the average slow oscillation for the same participant. This maybe reflects a problem in the function, which only detects these kinds of slow oscillations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a6d671-c629-4f68-903e-52b62a38535f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### *Visualization of spindle average time frequency plot when coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6f607-5fbe-445f-907d-c49c458c83f8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.signal import spectrogram\n",
    "\n",
    "def plot_average_time_frequency(combined_raw, coupling_times_spindles, plot_name):\n",
    "\n",
    "    # here reuse code from average spindle waveform code\n",
    "\n",
    "    # Extract EEG data from the specified channel\n",
    "    filtered_data = combined_raw.copy().pick_channels(['Fz'])\n",
    "    filtered_data.resample(100)\n",
    "    sfreq = filtered_data.info['sfreq']\n",
    "    channel_data = filtered_data.get_data(picks='Fz')[0]\n",
    "    \n",
    "    # Bandpass filter between 12-16 Hz\n",
    "    bandpassed_data = mne.filter.filter_data(channel_data, sfreq, l_freq=12, h_freq=16, l_trans_bandwidth=1.5, h_trans_bandwidth=1.5)\n",
    "\n",
    "    stacked_spindles = []\n",
    "    \n",
    "    for start_time, end_time in coupling_times_spindles:\n",
    "        start_idx = int(start_time * sfreq)\n",
    "        end_idx = int(end_time * sfreq)\n",
    "        segment = bandpassed_data[start_idx:end_idx]\n",
    "        \n",
    "        # Find the peak within the spindle\n",
    "        peak_idx = start_idx + np.argmax(segment)\n",
    "        \n",
    "        # Extract 1.5s before and after the peak\n",
    "        before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "        after_peak_idx = min(len(bandpassed_data), peak_idx + int(1.5 * sfreq))\n",
    "        aligned_segment = bandpassed_data[before_peak_idx:after_peak_idx]\n",
    "        stacked_spindles.append(aligned_segment)\n",
    "\n",
    "    \n",
    "    # Pad spindles to the same length\n",
    "    max_len = max(len(seg) for seg in stacked_spindles)\n",
    "    padded_stacked_spindles = [np.pad(seg, (0, max_len - len(seg)), constant_values=np.nan) for seg in stacked_spindles]\n",
    "    \n",
    "    # Compute the average spindle waveform\n",
    "    average_spindle_waveform = np.nanmean(padded_stacked_spindles, axis=0)\n",
    "    time_axis = np.linspace(-1.5, 1.5, len(average_spindle_waveform))\n",
    "\n",
    "    # new code here\n",
    "    # Compute the spectrogram of the average spindle\n",
    "    f, t, Sxx = spectrogram(average_spindle_waveform, fs=sfreq, nperseg=50, noverlap=40)\n",
    "    # this computes a spectrogram (time-frequency representation) with consecutive Fourier\n",
    "    # transforms\n",
    "\n",
    "    # Plot the time-frequency representation\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.pcolormesh(t - 1.5, f, np.log(Sxx), shading='auto', cmap='jet')\n",
    "    plt.axvline(0, color=\"red\", linestyle=\"--\", label=\"Peak (0s)\")\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.title(plot_name)\n",
    "    plt.colorbar(label=\"Log Power\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e70fec-44ed-4774-99f2-e20391ee2de0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_average_time_frequency(combined_raw_020, coupling_020_spindles_times, 'Average Time-Frequency Representation of Spindles When Coupling for Participant 020')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0376d7-fe8e-4425-9056-cd01fd4ebae4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### *Visualization: overlay slow oscillation waveform and spindle spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd8bd6b-45f7-4df8-9415-5a0c35d84f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import spectrogram\n",
    "\n",
    "def visualise_so_spindle_coupling(combined_raw, plot_name):\n",
    "    \n",
    "    # 1: Get slow oscillation and spindle coupling times\n",
    "    # reuse previous functions\n",
    "    coupling_020_so_times = detect_slow_oscillations_spindles_coupling_so_times(combined_raw)\n",
    "    coupling_020_spindles_times = detect_slow_oscillations_spindles_coupling_spindles_times(combined_raw)\n",
    "\n",
    "    # 2: Compute average slow oscillation waveform\n",
    "    # reuse code from slow oscillation visualisation\n",
    "    filtered_data_so = combined_raw.copy().filter(l_freq=0.3, h_freq=1.25)\n",
    "    filtered_data_so.resample(100)  # Downsample to 100 Hz\n",
    "    sfreq = filtered_data_so.info['sfreq']\n",
    "    channel_data_so = filtered_data_so.get_data(picks=\"Fz\")[0]\n",
    "\n",
    "    stacked_so = []\n",
    "    for start_time, end_time in coupling_020_so_times:\n",
    "        start_idx = int(start_time * sfreq)\n",
    "        end_idx = int(end_time * sfreq)\n",
    "        segment = channel_data_so[start_idx:end_idx]\n",
    "        global_trough_idx = start_idx + np.argmin(segment)\n",
    "        before_trough_idx = max(0, global_trough_idx - int(1.5 * sfreq))\n",
    "        after_trough_idx = min(len(channel_data_so), global_trough_idx + int(1.5 * sfreq))\n",
    "        aligned_segment = channel_data_so[before_trough_idx:after_trough_idx]\n",
    "        stacked_so.append(aligned_segment)\n",
    "\n",
    "    max_len_so = max(len(seg) for seg in stacked_so)\n",
    "    padded_stacked_so = [np.pad(seg, (0, max_len_so - len(seg)), constant_values=np.nan) for seg in stacked_so]\n",
    "    avg_so_waveform = np.nanmean(padded_stacked_so, axis=0)\n",
    "    time_axis = np.linspace(-1.5, 1.5, len(avg_so_waveform))\n",
    "\n",
    "    # 3: Compute spindle time-frequency representation\n",
    "    # here reuse code from above\n",
    "    filtered_data_spindle = combined_raw.copy().pick_channels(['Fz'])\n",
    "    filtered_data_spindle.resample(100)\n",
    "    sfreq = filtered_data_spindle.info['sfreq']\n",
    "    channel_data_spindle = filtered_data_spindle.get_data(picks='Fz')[0]\n",
    "    \n",
    "    bandpassed_spindle = mne.filter.filter_data(channel_data_spindle, sfreq, l_freq=12, h_freq=16, l_trans_bandwidth=1.5, h_trans_bandwidth=1.5)\n",
    "\n",
    "    stacked_spindles = []\n",
    "    for start_time, end_time in coupling_020_spindles_times:\n",
    "        start_idx = int(start_time * sfreq)\n",
    "        end_idx = int(end_time * sfreq)\n",
    "        segment = bandpassed_spindle[start_idx:end_idx]\n",
    "        stacked_spindles.append(segment)\n",
    "    \n",
    "    max_len_spindle = max(len(seg) for seg in stacked_spindles)\n",
    "    padded_stacked_spindles = [np.pad(seg, (0, max_len_spindle - len(seg)), constant_values=np.nan) for seg in stacked_spindles]\n",
    "    avg_spindle_waveform = np.nanmean(padded_stacked_spindles, axis=0)\n",
    "\n",
    "    # Compute Spectrogram using slow oscillation-aligned time\n",
    "    f, t, Sxx = spectrogram(avg_spindle_waveform, fs=sfreq, nperseg=50, noverlap=40)\n",
    "    # this computes a spectrogram (time-frequency representation) with consecutive Fourier\n",
    "    # transforms\n",
    "    t = np.linspace(-1.5, 1.5, len(t))  \n",
    "    # here to have same time axis as slow oscillation\n",
    "\n",
    "    # 4: Plot overlayed visualization\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    # first plot the spindle spectrogram in the background\n",
    "    img = ax1.pcolormesh(t, f, np.log(Sxx), shading='auto', cmap='jet', alpha=0.7)\n",
    "    # log power to see power changes better\n",
    "    ax1.set_ylabel('Frequency (Hz)', color='black')\n",
    "    ax1.tick_params(axis='y', labelcolor='black')\n",
    "    cbar = fig.colorbar(img, ax=ax1, pad=0.1)\n",
    "    # colourbar for the log power\n",
    "    cbar.set_label('Log Power')\n",
    "\n",
    "    # then overlay the slow oscillation waveform\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(time_axis, avg_so_waveform, color='white', linewidth=2, label=\"Mean Slow Oscillation\")\n",
    "    ax2.axvline(0, color=\"red\", linestyle=\"--\", label=\"Trough (0s)\")\n",
    "    ax2.set_ylabel('Amplitude (µV)', color='white')\n",
    "    ax2.tick_params(axis='y', labelcolor='white')\n",
    "\n",
    "    # then add title\n",
    "    plt.title(plot_name)\n",
    "    ax2.legend(loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4035155-c12a-4ce0-8403-983a73a77e9a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "visualise_so_spindle_coupling(combined_raw_020, 'Average Spindle Time-Frequency & Slow Oscillation Coupling for Participant 020')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa10c53-4bc5-4a7d-aca2-05d69d04bb03",
   "metadata": {},
   "source": [
    "# *Raw EEG Data Participant 033"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8529f1af-b200-4a5b-8738-82d3e78310b6",
   "metadata": {},
   "source": [
    "### *Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a937add5-372c-48d9-8308-2edd0268eafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from C:\\EEG DATA\\033\\eeg\\TMR.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 11859549  =      0.000 ... 23719.098 secs...\n"
     ]
    }
   ],
   "source": [
    "participant_033_file = r\"C:\\EEG DATA\\033\\eeg\\TMR.vhdr\"\n",
    "\n",
    "participant_033_raw = mne.io.read_raw_brainvision(vhdr_fname=participant_033_file, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ea286fd-e6ac-4bd8-91f7-ec12f1c2fa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RawBrainVision | TMR.eeg, 64 x 11859550 (23719.1 s), ~5.66 GiB, data loaded>\n",
      "<Info | 7 non-empty values\n",
      " bads: []\n",
      " ch_names: Fp1, Fp2, F3, F4, C3, C4, P3, P4, O1, O2, F7, F8, T7, T8, P7, ...\n",
      " chs: 64 EEG\n",
      " custom_ref_applied: False\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 1000.0 Hz\n",
      " meas_date: 2023-05-18 00:23:46 UTC\n",
      " nchan: 64\n",
      " projs: []\n",
      " sfreq: 500.0 Hz\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "print(participant_033_raw)\n",
    "print(participant_033_raw.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937e3e62-3e28-40a9-a3da-05ec8d38fbbf",
   "metadata": {},
   "source": [
    "### *Onset times for participant 033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de455525-510d-44cd-82df-c33c306d15f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data_onsets_033 = label_data_onsets['033']\n",
    "#label_data_onsets_033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f31557c6-3d0b-4d55-9e5b-75d67920f238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[180.0,\n",
       "  210.0,\n",
       "  240.0,\n",
       "  270.0,\n",
       "  300.0,\n",
       "  330.0,\n",
       "  360.0,\n",
       "  390.0,\n",
       "  420.0,\n",
       "  450.0,\n",
       "  480.0,\n",
       "  510.0,\n",
       "  540.0,\n",
       "  570.0,\n",
       "  600.0,\n",
       "  630.0],\n",
       " [690.0, 720.0, 750.0, 780.0],\n",
       " [840.0, 870.0, 900.0],\n",
       " [960.0, 990.0, 1020.0, 1050.0, 1080.0, 1110.0, 1140.0, 1170.0],\n",
       " [1230.0,\n",
       "  1260.0,\n",
       "  1290.0,\n",
       "  1320.0,\n",
       "  1350.0,\n",
       "  1380.0,\n",
       "  1410.0,\n",
       "  1440.0,\n",
       "  1470.0,\n",
       "  1500.0,\n",
       "  1530.0,\n",
       "  1560.0,\n",
       "  1590.0,\n",
       "  1620.0,\n",
       "  1650.0,\n",
       "  1680.0,\n",
       "  1710.0,\n",
       "  1740.0,\n",
       "  1770.0,\n",
       "  1800.0,\n",
       "  1830.0,\n",
       "  1860.0,\n",
       "  1890.0,\n",
       "  1920.0,\n",
       "  1950.0,\n",
       "  1980.0,\n",
       "  2010.0,\n",
       "  2040.0,\n",
       "  2070.0,\n",
       "  2100.0,\n",
       "  2130.0,\n",
       "  2160.0,\n",
       "  2190.0,\n",
       "  2220.0,\n",
       "  2250.0,\n",
       "  2280.0,\n",
       "  2310.0,\n",
       "  2340.0,\n",
       "  2370.0,\n",
       "  2400.0,\n",
       "  2430.0,\n",
       "  2460.0,\n",
       "  2490.0,\n",
       "  2520.0,\n",
       "  2550.0,\n",
       "  2580.0,\n",
       "  2610.0,\n",
       "  2640.0,\n",
       "  2670.0,\n",
       "  2700.0,\n",
       "  2730.0,\n",
       "  2760.0,\n",
       "  2790.0,\n",
       "  2820.0,\n",
       "  2850.0,\n",
       "  2880.0,\n",
       "  2910.0,\n",
       "  2940.0,\n",
       "  2970.0,\n",
       "  3000.0,\n",
       "  3030.0,\n",
       "  3060.0,\n",
       "  3090.0,\n",
       "  3120.0,\n",
       "  3150.0,\n",
       "  3180.0,\n",
       "  3210.0,\n",
       "  3240.0],\n",
       " [3330.0,\n",
       "  3360.0,\n",
       "  3390.0,\n",
       "  3420.0,\n",
       "  3450.0,\n",
       "  3480.0,\n",
       "  3510.0,\n",
       "  3540.0,\n",
       "  3570.0,\n",
       "  3600.0],\n",
       " [4560.0],\n",
       " [4680.0,\n",
       "  4710.0,\n",
       "  4740.0,\n",
       "  4770.0,\n",
       "  4800.0,\n",
       "  4830.0,\n",
       "  4860.0,\n",
       "  4890.0,\n",
       "  4920.0,\n",
       "  4950.0,\n",
       "  4980.0,\n",
       "  5010.0,\n",
       "  5040.0,\n",
       "  5070.0,\n",
       "  5100.0,\n",
       "  5130.0,\n",
       "  5160.0,\n",
       "  5190.0,\n",
       "  5220.0,\n",
       "  5250.0,\n",
       "  5280.0,\n",
       "  5310.0,\n",
       "  5340.0,\n",
       "  5370.0,\n",
       "  5400.0,\n",
       "  5430.0,\n",
       "  5460.0,\n",
       "  5490.0,\n",
       "  5520.0,\n",
       "  5550.0,\n",
       "  5580.0,\n",
       "  5610.0,\n",
       "  5640.0,\n",
       "  5670.0],\n",
       " [5760.0, 5790.0, 5820.0],\n",
       " [5880.0,\n",
       "  5910.0,\n",
       "  5940.0,\n",
       "  5970.0,\n",
       "  6000.0,\n",
       "  6030.0,\n",
       "  6060.0,\n",
       "  6090.0,\n",
       "  6120.0,\n",
       "  6150.0,\n",
       "  6180.0,\n",
       "  6210.0,\n",
       "  6240.0,\n",
       "  6270.0,\n",
       "  6300.0,\n",
       "  6330.0,\n",
       "  6360.0,\n",
       "  6390.0,\n",
       "  6420.0,\n",
       "  6450.0,\n",
       "  6480.0,\n",
       "  6510.0,\n",
       "  6540.0,\n",
       "  6570.0,\n",
       "  6600.0,\n",
       "  6630.0,\n",
       "  6660.0,\n",
       "  6690.0,\n",
       "  6720.0,\n",
       "  6750.0,\n",
       "  6780.0,\n",
       "  6810.0,\n",
       "  6840.0,\n",
       "  6870.0,\n",
       "  6900.0,\n",
       "  6930.0,\n",
       "  6960.0,\n",
       "  6990.0,\n",
       "  7020.0,\n",
       "  7050.0,\n",
       "  7080.0,\n",
       "  7110.0,\n",
       "  7140.0,\n",
       "  7170.0,\n",
       "  7200.0,\n",
       "  7230.0,\n",
       "  7260.0,\n",
       "  7290.0,\n",
       "  7320.0,\n",
       "  7350.0,\n",
       "  7380.0,\n",
       "  7410.0,\n",
       "  7440.0,\n",
       "  7470.0,\n",
       "  7500.0,\n",
       "  7530.0,\n",
       "  7560.0,\n",
       "  7590.0,\n",
       "  7620.0,\n",
       "  7650.0,\n",
       "  7680.0,\n",
       "  7710.0,\n",
       "  7740.0,\n",
       "  7770.0,\n",
       "  7800.0,\n",
       "  7830.0,\n",
       "  7860.0,\n",
       "  7890.0,\n",
       "  7920.0,\n",
       "  7950.0,\n",
       "  7980.0,\n",
       "  8010.0,\n",
       "  8040.0,\n",
       "  8070.0,\n",
       "  8100.0,\n",
       "  8130.0,\n",
       "  8160.0],\n",
       " [8250.0, 8280.0, 8310.0, 8340.0, 8370.0, 8400.0, 8430.0, 8460.0, 8490.0],\n",
       " [10200.0, 10230.0, 10260.0, 10290.0, 10320.0],\n",
       " [10380.0, 10410.0],\n",
       " [10470.0,\n",
       "  10500.0,\n",
       "  10530.0,\n",
       "  10560.0,\n",
       "  10590.0,\n",
       "  10620.0,\n",
       "  10650.0,\n",
       "  10680.0,\n",
       "  10710.0,\n",
       "  10740.0,\n",
       "  10770.0,\n",
       "  10800.0,\n",
       "  10830.0,\n",
       "  10860.0,\n",
       "  10890.0,\n",
       "  10920.0,\n",
       "  10950.0,\n",
       "  10980.0,\n",
       "  11010.0,\n",
       "  11040.0,\n",
       "  11070.0,\n",
       "  11100.0,\n",
       "  11130.0],\n",
       " [11190.0,\n",
       "  11220.0,\n",
       "  11250.0,\n",
       "  11280.0,\n",
       "  11310.0,\n",
       "  11340.0,\n",
       "  11370.0,\n",
       "  11400.0,\n",
       "  11430.0,\n",
       "  11460.0,\n",
       "  11490.0,\n",
       "  11520.0,\n",
       "  11550.0,\n",
       "  11580.0,\n",
       "  11610.0,\n",
       "  11640.0,\n",
       "  11670.0,\n",
       "  11700.0,\n",
       "  11730.0,\n",
       "  11760.0,\n",
       "  11790.0,\n",
       "  11820.0,\n",
       "  11850.0,\n",
       "  11880.0,\n",
       "  11910.0,\n",
       "  11940.0,\n",
       "  11970.0,\n",
       "  12000.0,\n",
       "  12030.0,\n",
       "  12060.0,\n",
       "  12090.0,\n",
       "  12120.0,\n",
       "  12150.0,\n",
       "  12180.0,\n",
       "  12210.0,\n",
       "  12240.0,\n",
       "  12270.0,\n",
       "  12300.0,\n",
       "  12330.0,\n",
       "  12360.0,\n",
       "  12390.0,\n",
       "  12420.0,\n",
       "  12450.0,\n",
       "  12480.0,\n",
       "  12510.0,\n",
       "  12540.0,\n",
       "  12570.0,\n",
       "  12600.0,\n",
       "  12630.0,\n",
       "  12660.0,\n",
       "  12690.0,\n",
       "  12720.0],\n",
       " [12810.0, 12840.0],\n",
       " [12900.0,\n",
       "  12930.0,\n",
       "  12960.0,\n",
       "  12990.0,\n",
       "  13020.0,\n",
       "  13050.0,\n",
       "  13080.0,\n",
       "  13110.0,\n",
       "  13140.0,\n",
       "  13170.0,\n",
       "  13200.0,\n",
       "  13230.0,\n",
       "  13260.0,\n",
       "  13290.0,\n",
       "  13320.0,\n",
       "  13350.0,\n",
       "  13380.0,\n",
       "  13410.0,\n",
       "  13440.0,\n",
       "  13470.0,\n",
       "  13500.0],\n",
       " [13560.0,\n",
       "  13590.0,\n",
       "  13620.0,\n",
       "  13650.0,\n",
       "  13680.0,\n",
       "  13710.0,\n",
       "  13740.0,\n",
       "  13770.0,\n",
       "  13800.0,\n",
       "  13830.0],\n",
       " [13890.0],\n",
       " [14730.0,\n",
       "  14760.0,\n",
       "  14790.0,\n",
       "  14820.0,\n",
       "  14850.0,\n",
       "  14880.0,\n",
       "  14910.0,\n",
       "  14940.0,\n",
       "  14970.0,\n",
       "  15000.0,\n",
       "  15030.0,\n",
       "  15060.0],\n",
       " [15120.0,\n",
       "  15150.0,\n",
       "  15180.0,\n",
       "  15210.0,\n",
       "  15240.0,\n",
       "  15270.0,\n",
       "  15300.0,\n",
       "  15330.0,\n",
       "  15360.0,\n",
       "  15390.0,\n",
       "  15420.0,\n",
       "  15450.0,\n",
       "  15480.0,\n",
       "  15510.0,\n",
       "  15540.0,\n",
       "  15570.0,\n",
       "  15600.0,\n",
       "  15630.0,\n",
       "  15660.0,\n",
       "  15690.0,\n",
       "  15720.0,\n",
       "  15750.0,\n",
       "  15780.0,\n",
       "  15810.0,\n",
       "  15840.0,\n",
       "  15870.0,\n",
       "  15900.0,\n",
       "  15930.0,\n",
       "  15960.0,\n",
       "  15990.0,\n",
       "  16020.0,\n",
       "  16050.0,\n",
       "  16080.0],\n",
       " [16200.0,\n",
       "  16230.0,\n",
       "  16260.0,\n",
       "  16290.0,\n",
       "  16320.0,\n",
       "  16350.0,\n",
       "  16380.0,\n",
       "  16410.0,\n",
       "  16440.0,\n",
       "  16470.0,\n",
       "  16500.0,\n",
       "  16530.0,\n",
       "  16560.0,\n",
       "  16590.0],\n",
       " [16650.0,\n",
       "  16680.0,\n",
       "  16710.0,\n",
       "  16740.0,\n",
       "  16770.0,\n",
       "  16800.0,\n",
       "  16830.0,\n",
       "  16860.0,\n",
       "  16890.0,\n",
       "  16920.0,\n",
       "  16950.0,\n",
       "  16980.0,\n",
       "  17010.0,\n",
       "  17040.0,\n",
       "  17070.0,\n",
       "  17100.0,\n",
       "  17130.0,\n",
       "  17160.0,\n",
       "  17190.0,\n",
       "  17220.0,\n",
       "  17250.0,\n",
       "  17280.0,\n",
       "  17310.0,\n",
       "  17340.0,\n",
       "  17370.0,\n",
       "  17400.0,\n",
       "  17430.0,\n",
       "  17460.0,\n",
       "  17490.0,\n",
       "  17520.0,\n",
       "  17550.0,\n",
       "  17580.0,\n",
       "  17610.0,\n",
       "  17640.0,\n",
       "  17670.0,\n",
       "  17700.0],\n",
       " [17850.0, 17880.0],\n",
       " [18000.0],\n",
       " [20700.0,\n",
       "  20730.0,\n",
       "  20760.0,\n",
       "  20790.0,\n",
       "  20820.0,\n",
       "  20850.0,\n",
       "  20880.0,\n",
       "  20910.0,\n",
       "  20940.0,\n",
       "  20970.0,\n",
       "  21000.0,\n",
       "  21030.0,\n",
       "  21060.0,\n",
       "  21090.0,\n",
       "  21120.0,\n",
       "  21150.0,\n",
       "  21180.0,\n",
       "  21210.0,\n",
       "  21240.0,\n",
       "  21270.0,\n",
       "  21300.0,\n",
       "  21330.0,\n",
       "  21360.0,\n",
       "  21390.0,\n",
       "  21420.0,\n",
       "  21450.0,\n",
       "  21480.0,\n",
       "  21510.0,\n",
       "  21540.0,\n",
       "  21570.0,\n",
       "  21600.0,\n",
       "  21630.0,\n",
       "  21660.0,\n",
       "  21690.0,\n",
       "  21720.0],\n",
       " [21810.0,\n",
       "  21840.0,\n",
       "  21870.0,\n",
       "  21900.0,\n",
       "  21930.0,\n",
       "  21960.0,\n",
       "  21990.0,\n",
       "  22020.0,\n",
       "  22050.0,\n",
       "  22080.0,\n",
       "  22110.0,\n",
       "  22140.0,\n",
       "  22170.0,\n",
       "  22200.0,\n",
       "  22230.0,\n",
       "  22260.0,\n",
       "  22290.0],\n",
       " [22380.0, 22410.0, 22440.0],\n",
       " [22530.0,\n",
       "  22560.0,\n",
       "  22590.0,\n",
       "  22620.0,\n",
       "  22650.0,\n",
       "  22680.0,\n",
       "  22710.0,\n",
       "  22740.0,\n",
       "  22770.0,\n",
       "  22800.0,\n",
       "  22830.0,\n",
       "  22860.0,\n",
       "  22890.0,\n",
       "  22920.0],\n",
       " [22980.0, 23010.0],\n",
       " [23370.0,\n",
       "  23400.0,\n",
       "  23430.0,\n",
       "  23460.0,\n",
       "  23490.0,\n",
       "  23520.0,\n",
       "  23550.0,\n",
       "  23580.0,\n",
       "  23610.0,\n",
       "  23640.0,\n",
       "  23670.0]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups_033 = group_by_increment(label_data_onsets_033, increment=30)\n",
    "groups_033"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d12cf28-3261-4d7b-ac81-bcb7b2e30c35",
   "metadata": {},
   "source": [
    "### *Plot raw segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7575529e-39bf-4c1c-81bc-79e39e6421d9",
   "metadata": {},
   "source": [
    "#### *Combine raws + pick channel and filter directly in plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "229661d3-2854-466c-9fee-0530ca861a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying a custom ('EEG',) reference.\n"
     ]
    }
   ],
   "source": [
    "# to check that EEG data looks correct\n",
    "\n",
    "# Extract segments\n",
    "segments_033 = extract_segments(participant_033_raw, groups_033)\n",
    "\n",
    "if segments_033:\n",
    "    combined_raw_033 = mne.concatenate_raws(segments_033)\n",
    "    # concatenates raw segments as if they were continuous\n",
    "    # boundaries of the raw files are annotated bad\n",
    "    #combined_raw_033.pick([\"Fz\"]).filter(l_freq=0.1, h_freq=40).plot()\n",
    "    combined_raw_033.set_eeg_reference(ref_channels = ['M1', 'M2'])\n",
    "    combined_raw_033.apply_function(lambda x: x * 1e6, picks='eeg')\n",
    "    combined_raw_033.pick([\"Fz\"])\n",
    "# this is to be able to visualize all the EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb3d96f3-8be2-49d9-a873-5b0afad5db0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14940.06\n",
      "23719.098\n"
     ]
    }
   ],
   "source": [
    "print(combined_raw_033.times[-1])\n",
    "print(participant_033_raw.times[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578706f2-904f-4e7c-855c-b531fbf4e1f7",
   "metadata": {},
   "source": [
    "### *Slow oscillation detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c39d089-08c0-4b63-8909-07726b32fe03",
   "metadata": {},
   "source": [
    "##### *slow_oscillations_033_times: slow oscillations times returned as a list of np.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f07d50f0-721c-4f83-88c9-43b5355dc86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_oscillations_033_times = detect_slow_oscillations_times(combined_raw_033)\n",
    "#slow_oscillations_033_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ebb1f8-16e9-4687-be2f-78009cc60bdc",
   "metadata": {},
   "source": [
    "##### slow_oscillations_033_peaks: slow oscillations peaks returned as a list of np.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "553d4e68-1aaa-4815-aee6-786f5bb558d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_oscillations_033_peaks = detect_slow_oscillations_peaks(combined_raw_033)\n",
    "#slow_oscillations_033_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c75fb7-fbad-468b-bada-bf1158308879",
   "metadata": {},
   "source": [
    "##### *sanity check of length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "553190ca-fc62-459f-9047-46165ecfd4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204\n",
      "1204\n"
     ]
    }
   ],
   "source": [
    "print(len(slow_oscillations_033_times))\n",
    "print(len(slow_oscillations_033_peaks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63bf626-1bd7-4416-8357-8c7173438dd5",
   "metadata": {},
   "source": [
    "##### *Average slow oscillation visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28b1ea3-3650-495b-8f80-de226f9cd939",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_and_stack_slow_oscillations_trough(combined_raw_033, slow_oscillations_033_times, 'Average Slow Oscillation (Trough-centered) for Participant 033 (0.3-1.25 Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484a9549-82a8-4bf9-97d0-88b04b571351",
   "metadata": {},
   "source": [
    "### *Spindle detection without peak frequency (Klinzing et al., 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca2e4f2-955e-4eef-b96b-e3eeb7ea0485",
   "metadata": {},
   "source": [
    "##### *spindles_033_times : spindle times returned as list of np.floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d73c7a5e-3693-45fc-9338-421ff1c79e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 31 contiguous segments\n",
      "Setting up band-pass filter from 12 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 12.00\n",
      "- Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 551 samples (1.102 s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spindles_033_times = detect_spindles_times(combined_raw_033)\n",
    "#spindles_033_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c16ea78-41e5-4488-b5b4-5a7a30bcd083",
   "metadata": {},
   "source": [
    "##### *spindles_033_peaks: spindle peak time returned as a list of np.floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f06c7dfe-e260-427a-a030-f9e1d136cf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 31 contiguous segments\n",
      "Setting up band-pass filter from 12 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 12.00\n",
      "- Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 551 samples (1.102 s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spindles_033_peaks = detect_spindles_times(combined_raw_033)\n",
    "#spindles_033_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700a5fb4-504a-4632-b3fd-590c5cc1fac7",
   "metadata": {},
   "source": [
    "##### *sanity check of length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e15b228-d5f4-4862-95fd-5f2ebf249feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2301\n",
      "2301\n"
     ]
    }
   ],
   "source": [
    "print(len(spindles_033_times))\n",
    "print(len(spindles_033_peaks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9920d845-dfd0-4d91-8ada-9f3983d0c4c2",
   "metadata": {},
   "source": [
    "##### *Average spindle visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af3c152-d65a-4100-b000-b5860e464aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_spindles(combined_raw_033, 'Average Spindle (Peak-centered) for Participant 033 (12-16 Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62b2dd1-ff7f-49a6-94a5-56a3f8f61d48",
   "metadata": {},
   "source": [
    "### *Slow oscillation spindle coupling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3e0bf7-ac9a-4e79-9ef6-051ff4f9e381",
   "metadata": {},
   "source": [
    "##### *coupling_033_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "942dd52b-6930-4845-bd72-44275039c5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 31 contiguous segments\n",
      "Setting up band-pass filter from 12 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 12.00\n",
      "- Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 551 samples (1.102 s)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[np.float64(21.48),\n",
       " np.float64(36.376),\n",
       " np.float64(137.246),\n",
       " np.float64(162.596),\n",
       " np.float64(163.528),\n",
       " np.float64(194.766),\n",
       " np.float64(204.088),\n",
       " np.float64(222.538),\n",
       " np.float64(223.026),\n",
       " np.float64(256.344),\n",
       " np.float64(270.048),\n",
       " np.float64(281.164),\n",
       " np.float64(287.378),\n",
       " np.float64(289.92),\n",
       " np.float64(290.66),\n",
       " np.float64(318.974),\n",
       " np.float64(329.754),\n",
       " np.float64(348.878),\n",
       " np.float64(349.51),\n",
       " np.float64(350.65),\n",
       " np.float64(364.684),\n",
       " np.float64(390.134),\n",
       " np.float64(392.418),\n",
       " np.float64(400.272),\n",
       " np.float64(404.658),\n",
       " np.float64(406.486),\n",
       " np.float64(407.72),\n",
       " np.float64(420.862),\n",
       " np.float64(452.136),\n",
       " np.float64(492.69),\n",
       " np.float64(504.81),\n",
       " np.float64(518.358),\n",
       " np.float64(558.598),\n",
       " np.float64(579.964),\n",
       " np.float64(588.974),\n",
       " np.float64(589.54),\n",
       " np.float64(597.318),\n",
       " np.float64(606.726),\n",
       " np.float64(608.136),\n",
       " np.float64(623.656),\n",
       " np.float64(627.05),\n",
       " np.float64(668.94),\n",
       " np.float64(679.806),\n",
       " np.float64(698.512),\n",
       " np.float64(715.484),\n",
       " np.float64(727.896),\n",
       " np.float64(740.07),\n",
       " np.float64(741.958),\n",
       " np.float64(755.65),\n",
       " np.float64(786.362),\n",
       " np.float64(799.77),\n",
       " np.float64(808.996),\n",
       " np.float64(823.102),\n",
       " np.float64(840.196),\n",
       " np.float64(906.508),\n",
       " np.float64(935.254),\n",
       " np.float64(966.068),\n",
       " np.float64(993.134),\n",
       " np.float64(996.138),\n",
       " np.float64(1038.428),\n",
       " np.float64(1043.97),\n",
       " np.float64(1049.192),\n",
       " np.float64(1059.556),\n",
       " np.float64(1115.174),\n",
       " np.float64(1176.804),\n",
       " np.float64(1180.232),\n",
       " np.float64(1183.626),\n",
       " np.float64(1194.79),\n",
       " np.float64(1216.674),\n",
       " np.float64(1227.324),\n",
       " np.float64(1238.95),\n",
       " np.float64(1258.592),\n",
       " np.float64(1261.33),\n",
       " np.float64(1262.196),\n",
       " np.float64(1268.8),\n",
       " np.float64(1271.33),\n",
       " np.float64(1274.754),\n",
       " np.float64(1295.304),\n",
       " np.float64(1306.292),\n",
       " np.float64(1343.58),\n",
       " np.float64(1344.208),\n",
       " np.float64(1356.48),\n",
       " np.float64(1387.748),\n",
       " np.float64(1430.792),\n",
       " np.float64(1505.588),\n",
       " np.float64(1508.022),\n",
       " np.float64(1521.676),\n",
       " np.float64(1561.51),\n",
       " np.float64(1585.606),\n",
       " np.float64(1610.89),\n",
       " np.float64(1645.482),\n",
       " np.float64(1675.178),\n",
       " np.float64(1677.488),\n",
       " np.float64(1704.272),\n",
       " np.float64(1708.828),\n",
       " np.float64(1793.946),\n",
       " np.float64(1817.72),\n",
       " np.float64(1826.406),\n",
       " np.float64(1832.15),\n",
       " np.float64(1856.206),\n",
       " np.float64(1865.376),\n",
       " np.float64(1872.712),\n",
       " np.float64(1900.794),\n",
       " np.float64(1941.528),\n",
       " np.float64(1969.346),\n",
       " np.float64(1984.434),\n",
       " np.float64(2009.154),\n",
       " np.float64(2023.674),\n",
       " np.float64(2042.042),\n",
       " np.float64(2081.656),\n",
       " np.float64(2099.16),\n",
       " np.float64(2104.982),\n",
       " np.float64(2111.37),\n",
       " np.float64(2128.762),\n",
       " np.float64(2168.466),\n",
       " np.float64(2175.854),\n",
       " np.float64(2236.35),\n",
       " np.float64(2241.068),\n",
       " np.float64(2253.708),\n",
       " np.float64(2272.13),\n",
       " np.float64(2284.632),\n",
       " np.float64(2308.992),\n",
       " np.float64(2329.06),\n",
       " np.float64(2366.208),\n",
       " np.float64(2379.498),\n",
       " np.float64(2402.618),\n",
       " np.float64(2453.53),\n",
       " np.float64(2484.576),\n",
       " np.float64(2642.244),\n",
       " np.float64(2643.122),\n",
       " np.float64(2679.94),\n",
       " np.float64(2705.82),\n",
       " np.float64(2746.054),\n",
       " np.float64(2776.26),\n",
       " np.float64(2802.276),\n",
       " np.float64(2808.516),\n",
       " np.float64(2840.732),\n",
       " np.float64(3028.996),\n",
       " np.float64(3045.952),\n",
       " np.float64(3047.146),\n",
       " np.float64(3088.92),\n",
       " np.float64(3528.566),\n",
       " np.float64(3633.164),\n",
       " np.float64(3669.01),\n",
       " np.float64(3679.386),\n",
       " np.float64(3681.628),\n",
       " np.float64(3779.324),\n",
       " np.float64(3839.558),\n",
       " np.float64(3853.274),\n",
       " np.float64(3860.796),\n",
       " np.float64(3868.414),\n",
       " np.float64(3884.22),\n",
       " np.float64(3946.974),\n",
       " np.float64(3972.464),\n",
       " np.float64(4004.072),\n",
       " np.float64(4025.078),\n",
       " np.float64(4049.44),\n",
       " np.float64(4051.948),\n",
       " np.float64(4076.244),\n",
       " np.float64(4102.424),\n",
       " np.float64(4317.488),\n",
       " np.float64(4322.99),\n",
       " np.float64(4435.066),\n",
       " np.float64(4493.734),\n",
       " np.float64(4494.268),\n",
       " np.float64(4496.548),\n",
       " np.float64(4537.468),\n",
       " np.float64(4542.072),\n",
       " np.float64(4542.87),\n",
       " np.float64(4553.784),\n",
       " np.float64(4560.692),\n",
       " np.float64(4591.724),\n",
       " np.float64(4607.318),\n",
       " np.float64(4644.03),\n",
       " np.float64(4653.452),\n",
       " np.float64(4700.064),\n",
       " np.float64(4718.94),\n",
       " np.float64(4722.884),\n",
       " np.float64(4807.752),\n",
       " np.float64(4814.784),\n",
       " np.float64(4824.338),\n",
       " np.float64(4840.752),\n",
       " np.float64(4864.102),\n",
       " np.float64(4897.808),\n",
       " np.float64(4902.496),\n",
       " np.float64(4968.316),\n",
       " np.float64(5041.198),\n",
       " np.float64(5043.868),\n",
       " np.float64(5060.812),\n",
       " np.float64(5076.3),\n",
       " np.float64(5088.234),\n",
       " np.float64(5097.726),\n",
       " np.float64(5127.62),\n",
       " np.float64(5144.616),\n",
       " np.float64(5157.952),\n",
       " np.float64(5192.768),\n",
       " np.float64(5208.836),\n",
       " np.float64(5240.862),\n",
       " np.float64(5265.848),\n",
       " np.float64(5280.546),\n",
       " np.float64(5288.218),\n",
       " np.float64(5342.51),\n",
       " np.float64(5348.424),\n",
       " np.float64(5370.11),\n",
       " np.float64(5431.044),\n",
       " np.float64(5455.398),\n",
       " np.float64(5471.91),\n",
       " np.float64(5480.678),\n",
       " np.float64(5482.262),\n",
       " np.float64(5487.986),\n",
       " np.float64(5494.172),\n",
       " np.float64(5553.362),\n",
       " np.float64(5560.642),\n",
       " np.float64(5568.878),\n",
       " np.float64(5602.668),\n",
       " np.float64(5627.054),\n",
       " np.float64(5706.754),\n",
       " np.float64(5730.438),\n",
       " np.float64(5758.528),\n",
       " np.float64(5761.808),\n",
       " np.float64(5805.582),\n",
       " np.float64(5819.326),\n",
       " np.float64(5822.16),\n",
       " np.float64(5823.026),\n",
       " np.float64(5868.308),\n",
       " np.float64(5904.14),\n",
       " np.float64(5907.082),\n",
       " np.float64(5910.21),\n",
       " np.float64(5920.444),\n",
       " np.float64(5943.888),\n",
       " np.float64(5970.46),\n",
       " np.float64(5982.6),\n",
       " np.float64(6005.554),\n",
       " np.float64(6013.758),\n",
       " np.float64(6057.224),\n",
       " np.float64(6065.188),\n",
       " np.float64(6164.246),\n",
       " np.float64(6171.264),\n",
       " np.float64(6175.204),\n",
       " np.float64(6175.744),\n",
       " np.float64(6195.692),\n",
       " np.float64(6291.818),\n",
       " np.float64(6297.444),\n",
       " np.float64(6358.49),\n",
       " np.float64(6380.68),\n",
       " np.float64(6465.594),\n",
       " np.float64(6476.62),\n",
       " np.float64(6500.048),\n",
       " np.float64(6563.688),\n",
       " np.float64(6564.418),\n",
       " np.float64(6655.47),\n",
       " np.float64(6912.17),\n",
       " np.float64(6981.358),\n",
       " np.float64(7210.888),\n",
       " np.float64(7270.11),\n",
       " np.float64(7329.032),\n",
       " np.float64(7345.37),\n",
       " np.float64(7451.014),\n",
       " np.float64(7461.462),\n",
       " np.float64(7488.14),\n",
       " np.float64(7488.874),\n",
       " np.float64(7582.196),\n",
       " np.float64(7640.054),\n",
       " np.float64(7670.864),\n",
       " np.float64(7675.04),\n",
       " np.float64(7675.806),\n",
       " np.float64(7785.024),\n",
       " np.float64(7813.804),\n",
       " np.float64(7828.198),\n",
       " np.float64(7829.406),\n",
       " np.float64(7899.46),\n",
       " np.float64(7984.594),\n",
       " np.float64(8011.562),\n",
       " np.float64(8022.456),\n",
       " np.float64(8060.872),\n",
       " np.float64(8069.706),\n",
       " np.float64(8111.404),\n",
       " np.float64(8119.118),\n",
       " np.float64(8151.72),\n",
       " np.float64(8152.748),\n",
       " np.float64(8158.666),\n",
       " np.float64(8215.958),\n",
       " np.float64(8217.196),\n",
       " np.float64(8239.938),\n",
       " np.float64(8286.602),\n",
       " np.float64(8333.42),\n",
       " np.float64(8397.564),\n",
       " np.float64(8414.702),\n",
       " np.float64(8440.53),\n",
       " np.float64(8462.316),\n",
       " np.float64(8463.024),\n",
       " np.float64(8465.924),\n",
       " np.float64(8513.01),\n",
       " np.float64(8517.976),\n",
       " np.float64(8590.48),\n",
       " np.float64(8623.948),\n",
       " np.float64(8633.058),\n",
       " np.float64(8654.866),\n",
       " np.float64(8700.248),\n",
       " np.float64(8719.062),\n",
       " np.float64(8765.114),\n",
       " np.float64(8805.498),\n",
       " np.float64(8843.952),\n",
       " np.float64(8888.452),\n",
       " np.float64(8909.84),\n",
       " np.float64(8923.978),\n",
       " np.float64(8952.832),\n",
       " np.float64(8990.138),\n",
       " np.float64(9217.146),\n",
       " np.float64(9247.834),\n",
       " np.float64(9325.312),\n",
       " np.float64(9408.998),\n",
       " np.float64(9422.488),\n",
       " np.float64(9491.464),\n",
       " np.float64(9621.396),\n",
       " np.float64(9683.358),\n",
       " np.float64(9683.954),\n",
       " np.float64(9737.034),\n",
       " np.float64(9738.06),\n",
       " np.float64(9748.194),\n",
       " np.float64(9820.916),\n",
       " np.float64(9838.032),\n",
       " np.float64(9838.846),\n",
       " np.float64(9881.33),\n",
       " np.float64(9934.148),\n",
       " np.float64(9934.668),\n",
       " np.float64(10192.344),\n",
       " np.float64(10383.338),\n",
       " np.float64(10407.046),\n",
       " np.float64(10443.428),\n",
       " np.float64(10537.466),\n",
       " np.float64(10602.686),\n",
       " np.float64(10658.996),\n",
       " np.float64(10715.44),\n",
       " np.float64(10741.692),\n",
       " np.float64(10751.188),\n",
       " np.float64(10784.784),\n",
       " np.float64(10785.692),\n",
       " np.float64(10828.212),\n",
       " np.float64(10848.154),\n",
       " np.float64(10886.748),\n",
       " np.float64(10909.876),\n",
       " np.float64(10942.128),\n",
       " np.float64(11033.398),\n",
       " np.float64(11082.99),\n",
       " np.float64(11084.01),\n",
       " np.float64(11101.152),\n",
       " np.float64(11108.08),\n",
       " np.float64(11135.254),\n",
       " np.float64(11141.852),\n",
       " np.float64(11146.176),\n",
       " np.float64(11177.378),\n",
       " np.float64(11178.464),\n",
       " np.float64(11212.478),\n",
       " np.float64(11314.394),\n",
       " np.float64(11334.94),\n",
       " np.float64(11340.462),\n",
       " np.float64(11452.738),\n",
       " np.float64(11466.658),\n",
       " np.float64(11515.69),\n",
       " np.float64(11557.634),\n",
       " np.float64(11571.638),\n",
       " np.float64(11604.438),\n",
       " np.float64(11689.96),\n",
       " np.float64(11690.764),\n",
       " np.float64(11740.166),\n",
       " np.float64(11786.956),\n",
       " np.float64(11869.818),\n",
       " np.float64(11884.316),\n",
       " np.float64(11969.638),\n",
       " np.float64(12025.946),\n",
       " np.float64(12042.554),\n",
       " np.float64(12091.352),\n",
       " np.float64(12136.352),\n",
       " np.float64(12138.136),\n",
       " np.float64(12161.334),\n",
       " np.float64(12167.036),\n",
       " np.float64(12185.586),\n",
       " np.float64(12186.976),\n",
       " np.float64(12218.616),\n",
       " np.float64(12232.666),\n",
       " np.float64(12254.44),\n",
       " np.float64(12262.746),\n",
       " np.float64(12268.196),\n",
       " np.float64(12273.566),\n",
       " np.float64(12291.034),\n",
       " np.float64(12296.848),\n",
       " np.float64(12325.782),\n",
       " np.float64(12333.39),\n",
       " np.float64(12341.076),\n",
       " np.float64(12363.588),\n",
       " np.float64(12368.234),\n",
       " np.float64(12377.446),\n",
       " np.float64(12393.016),\n",
       " np.float64(12404.208),\n",
       " np.float64(12407.63),\n",
       " np.float64(12496.944),\n",
       " np.float64(12533.99),\n",
       " np.float64(12591.664),\n",
       " np.float64(12626.472),\n",
       " np.float64(12776.036),\n",
       " np.float64(13052.77),\n",
       " np.float64(13145.196),\n",
       " np.float64(13209.456),\n",
       " np.float64(13299.57),\n",
       " np.float64(13562.606),\n",
       " np.float64(13844.706),\n",
       " np.float64(14018.362),\n",
       " np.float64(14094.438),\n",
       " np.float64(14103.648),\n",
       " np.float64(14105.112),\n",
       " np.float64(14158.068),\n",
       " np.float64(14183.922),\n",
       " np.float64(14203.542),\n",
       " np.float64(14204.164),\n",
       " np.float64(14205.07),\n",
       " np.float64(14267.596),\n",
       " np.float64(14285.68),\n",
       " np.float64(14383.462),\n",
       " np.float64(14480.916),\n",
       " np.float64(14497.442),\n",
       " np.float64(14504.742),\n",
       " np.float64(14547.196),\n",
       " np.float64(14582.408),\n",
       " np.float64(14583.018),\n",
       " np.float64(14590.586),\n",
       " np.float64(14825.524),\n",
       " np.float64(14901.93)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coupling_033_peaks = detect_slow_oscillations_spindles_coupling_peaks(combined_raw_033)\n",
    "coupling_033_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bc8af51-1988-4f1b-9265-3bd6d0afcff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "428"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coupling_033_peaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d2820-d139-4fee-8bfc-85951e107231",
   "metadata": {},
   "source": [
    "##### *coupling_033_so_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacf1a06-69ea-49af-a82f-191aa9b921cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupling_033_so_times = detect_slow_oscillations_spindles_coupling_so_times(combined_raw_033)\n",
    "coupling_033_so_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763b093b-00a8-41cd-bec2-f634e7618af4",
   "metadata": {},
   "source": [
    "##### *coupling_033_spindles_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0939ad41-3ad6-4b21-9ad2-a9db20487f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupling_033_spindles_times = detect_slow_oscillations_spindles_coupling_spindles_times(combined_raw_033)\n",
    "coupling_033_spindles_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f875b3-f37f-451c-9651-1723f0f93c88",
   "metadata": {},
   "source": [
    "##### *Visualization of average slow oscillation when coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10978cb6-2d3b-4130-a17a-3abe10781dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_and_stack_slow_oscillations_trough(combined_raw_033, coupling_033_so_times, 'Average Coupled Slow Oscillation (Trough-centered) for Participant 033 (0.3-1.25 Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6079386-e66d-4cab-bafc-7c3585703f4f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### *Visualization of spindle average time frequency plot when coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b319199e-91ee-4b53-9b9f-c99009e111c8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_average_time_frequency(combined_raw_033, coupling_033_spindles_times, 'Average Time-Frequency Representation of Spindles When Coupling for Participant 033')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c23119-c55f-4297-bd38-d2d26fe0f6f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### *Visualization: overlay slow oscillation waveform and spindle spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a892e2fe-93a1-4a6f-a21a-e74fa58c9c85",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "visualise_so_spindle_coupling(combined_raw_033, 'Average Spindle Time-Frequency & Slow Oscillation Coupling for Participant 033')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d087c5f-0448-4907-b1cd-59d7977eed18",
   "metadata": {},
   "source": [
    "# *Raw EEG Data Participant 046"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3be71e3-98d7-4a49-8ec5-6a49a52490ea",
   "metadata": {},
   "source": [
    "### *Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c684eb-dd93-4c78-b236-c045823d2d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_046_file = r\"C:\\EEG DATA\\046\\eeg\\TMR.vhdr\"\n",
    "\n",
    "participant_046_raw = mne.io.read_raw_brainvision(vhdr_fname=participant_046_file, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d171287-bb65-4629-92bb-6a42e48d24a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(participant_046_raw)\n",
    "print(participant_046_raw.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3ab840-1a94-4b51-8121-36377b4ec29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nrem_segments(raw, label_data_entry, epoch_duration=30.0, pad=0.0):\n",
    "\n",
    "    labels = np.atleast_1d(label_data_entry['label'])\n",
    "    onsets = np.atleast_1d(label_data_entry['onset'])\n",
    "\n",
    "    nrem_intervals = []\n",
    "    max_time = raw.times[-1]\n",
    "\n",
    "    for label, onset in zip(labels, onsets):\n",
    "        if label in [1, 2]:\n",
    "            start = max(0, onset - pad)\n",
    "            stop = min(onset + epoch_duration + pad, max_time)\n",
    "            nrem_intervals.append((start, stop))\n",
    "\n",
    "    # Crop and store each segment\n",
    "    segments = [raw.copy().crop(tmin=start, tmax=stop) for start, stop in nrem_intervals]\n",
    "\n",
    "    if segments:\n",
    "        # Concatenate all N2/N3 segments into one Raw object\n",
    "        combined = mne.concatenate_raws(segments)\n",
    "        combined.pick([\"Fz\"]).filter(l_freq=0.1, h_freq=40.0)\n",
    "        return combined\n",
    "    else:\n",
    "        print(\"No NREM segments found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180c6bb-d4e6-463d-b636-421ef41aa666",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_raw_046.times[-1])\n",
    "print(participant_046_raw.times[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f90569-0c9c-4982-a47c-ba8b4b511db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_raw_046 = extract_nrem_segments(participant_046_raw, label_data['046'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062e8d35-40fe-49f0-929e-4c5ff144adfd",
   "metadata": {},
   "source": [
    "### *Onset times for participant 046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f07891-4803-4347-af4e-b2b6ec0a7ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data_onsets_046 = label_data_onsets['046']\n",
    "#label_data_onsets_046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6bf971-c8f3-4f6d-8a3c-8959a6258f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_046 = group_by_increment(label_data_onsets_046, increment=30)\n",
    "groups_046"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba090aca-3c2e-4206-ab61-9f28da1c01fc",
   "metadata": {},
   "source": [
    "### *Plot raw segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be6d2f1-f330-407f-a9db-f4e5d4690339",
   "metadata": {},
   "source": [
    "#### *Combine raws + pick channel and filter directly in plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd14caf1-619d-49a8-882c-e1699a9ba2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check that EEG data looks correct\n",
    "\n",
    "# Extract segments\n",
    "segments_046 = extract_segments(participant_046_raw, groups_046)\n",
    "\n",
    "if segments_046:\n",
    "    combined_raw_046 = mne.concatenate_raws(segments_046)\n",
    "    combined_raw_046.set_eeg_reference(ref_channels = ['M1', 'M2'])\n",
    "    #combined_raw_046 = combined_raw_046 * 1e6\n",
    "    combined_raw_046.apply_function(lambda x: x * 1e6, picks='eeg')\n",
    "    # concatenates raw segments as if they were continuous\n",
    "    # boundaries of the raw files are annotated bad\n",
    "    combined_raw_046.pick([\"Fz\"])                                  \n",
    "    #combined_raw_046.pick([\"Fz\"]).filter(l_freq=0.1, h_freq=40)\n",
    "    # not filter\n",
    "\n",
    "# this is to be able to visualize all the EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6549c53f-4377-481f-ba07-31822166e6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_raw_046.times[-1])\n",
    "print(participant_046_raw.times[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf9c588-db6e-4865-845a-a043bfe30982",
   "metadata": {},
   "source": [
    "### *Slow oscillation detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052ca0ed-eeda-4fa7-aa21-fef425eea23b",
   "metadata": {},
   "source": [
    "##### *slow_oscillations_046_times: slow oscillations times returned as a list of np.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0d16e7-c2fc-41e8-87e9-2c72b087af47",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_oscillations_046_times = detect_slow_oscillations_times(combined_raw_046)\n",
    "#slow_oscillations_046_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1295cd-25c4-46d6-81b0-13c671196614",
   "metadata": {},
   "source": [
    "##### *slow_oscillations_046_peaks: slow oscillations peaks returned as a list of np.float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0bf7f-5993-4cdf-9ef1-c424147d9e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_oscillations_046_peaks = detect_slow_oscillations_peaks(combined_raw_046)\n",
    "#slow_oscillations_046_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dac72fb-9d20-4eca-a7dd-3cdc0c39df16",
   "metadata": {},
   "source": [
    "##### *sanity check of length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe902a93-0290-4277-9ba3-225407d1ee51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(slow_oscillations_046_times))\n",
    "print(len(slow_oscillations_046_peaks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b9456e-3980-431c-b0ce-d847af5503bd",
   "metadata": {},
   "source": [
    "##### *Average slow oscillation visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7204e59a-ef6e-469b-b170-4aebef3d9b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_and_stack_slow_oscillations_trough(combined_raw_046, slow_oscillations_046_times, 'Average Slow Oscillation (Trough-centered) for Participant 046 (0.16-1.25 Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4254648-992a-49b4-950f-b7d488d2cb4c",
   "metadata": {},
   "source": [
    "### *Spindle detection without peak frequency (Klinzing et al., 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fb4535-6bdd-43ba-8975-0a2b243b63ec",
   "metadata": {},
   "source": [
    "##### *spindles_046_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4515f6dc-08ff-42ae-ba99-4949427c633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spindles_046_times = detect_spindles_times(combined_raw_046)\n",
    "#spindles_046_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd2937b-1db8-4db9-8256-dfc0318cf4c3",
   "metadata": {},
   "source": [
    "##### *spindles_046_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1493dcd0-8645-4bbf-b326-c80264493773",
   "metadata": {},
   "outputs": [],
   "source": [
    "spindles_046_peaks = detect_spindles_peaks(combined_raw_046)\n",
    "#spindles_046_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20829a38-2416-4da7-b494-020b361d484f",
   "metadata": {},
   "source": [
    "##### *sanity_check_of_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f347cb3-961d-4bc3-8616-ba94cbf77609",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(spindles_046_times))\n",
    "print(len(spindles_046_peaks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b94d00-666f-4e2f-b1a8-e17d2640bda8",
   "metadata": {},
   "source": [
    "##### *Average spindle visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239476d1-fab5-42ce-a72c-f421fc7f7197",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_spindles(combined_raw_046, 'Average Spindle (Peak-centered) for Participant 046 (12-16 Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf8d492-1f28-475a-afaa-78ad783c4c0d",
   "metadata": {},
   "source": [
    "### *Slow oscillation spindle coupling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8c0e33-dc45-48e1-8fbd-e8214aff3c38",
   "metadata": {},
   "source": [
    "##### *coupling_046_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f287f47-0a14-4990-858c-ce9b0c279d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupling_046_peaks = detect_slow_oscillations_spindles_coupling_peaks(combined_raw_046)\n",
    "coupling_046_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a9e94a-8320-4411-9eab-bc1332dd7652",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coupling_046_peaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726e66bc-0ace-4677-b6f4-f40bb9e97596",
   "metadata": {},
   "source": [
    "##### *coupling_046_so_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c04e461-dc20-437c-a252-182d6fe31611",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupling_046_so_times = detect_slow_oscillations_spindles_coupling_so_times(combined_raw_046)\n",
    "coupling_046_so_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a9b9f2-0563-45e2-ac48-91d79997208e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coupling_046_so_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e90b6e0-cdae-4663-adfa-98bbee04ceac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### *coupling_046_spindles_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb8d842-ed61-499c-8207-144abb3b0ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupling_046_spindles_times = detect_slow_oscillations_spindles_coupling_spindles_times(combined_raw_046)\n",
    "coupling_046_spindles_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1947cb21-15a4-488e-8b68-0a5c80943925",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### *Visualization of average slow oscillation when coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee2d5f1-0041-48a0-bc1d-abf29f5118ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_and_stack_slow_oscillations_trough(combined_raw_046, coupling_046_so_times, 'Average Coupled Slow Oscillation (Trough-centered) for Participant 046 (0.3-1.25 Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5280acfb-0939-4468-9b60-d610ba2607ae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### *Visualization of spindle average time frequency plot when coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8207be-15a2-40ed-9fa2-21fea9d5f1cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_average_time_frequency(combined_raw_046, coupling_046_spindles_times, 'Average Time-Frequency Representation of Spindles When Coupling for Participant 046')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a71d48-bd0d-4f28-95a3-9a55e48fbdad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### *Visualization: overlay slow oscillation waveform and spindle spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3357dd20-336a-4e77-9e4d-77513945864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_so_spindle_coupling(combined_raw_046, 'Average Spindle Time-Frequency & Slow Oscillation Coupling for Participant 046')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056f7ea2-51d7-4522-b0b4-2f8bb312a26a",
   "metadata": {},
   "source": [
    "# *Raw EEG Data Participant 081"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03751049-c490-41be-8abf-2da7951ac807",
   "metadata": {},
   "source": [
    "### *Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc021da-b5df-4b21-bf4a-b05e0efabd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_081_file = r\"C:\\EEG DATA\\081\\eeg\\TMR.vhdr\"\n",
    "\n",
    "participant_081_raw = mne.io.read_raw_brainvision(vhdr_fname=participant_081_file, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9098f3-9f95-427d-8301-8214c665d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(participant_081_raw)\n",
    "print(participant_081_raw.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ebf025-ae26-466a-8c8c-87ac6944fd7e",
   "metadata": {},
   "source": [
    "### *Onset times for participant 081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed842678-df77-43c2-9f40-d93d978ecdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data_onsets_081 = label_data_onsets['081']\n",
    "#label_data_onsets_081"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c58a4f-b016-49b5-9e7c-64fab2c4bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_081 = group_by_increment(label_data_onsets_081, increment=30)\n",
    "groups_081"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119b6883-4a66-4531-92a6-69abbeb1a631",
   "metadata": {},
   "source": [
    "### *Plot raw segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418d288d-8248-46ad-9e41-c337f2b477ff",
   "metadata": {},
   "source": [
    "##### *Combine raws + pick channel and filter directly in plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1b0bb3-b601-47d0-a188-ccd9cb21e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check that EEG data looks correct\n",
    "\n",
    "# Extract segments\n",
    "segments_081 = extract_segments(participant_081_raw, groups_081)\n",
    "\n",
    "if segments_081:\n",
    "    combined_raw_081 = mne.concatenate_raws(segments_081)\n",
    "    # concatenates raw segments as if they were continuous\n",
    "    # boundaries of the raw files are annotated bad\n",
    "    combined_raw_081.set_eeg_reference(ref_channels = ['M1', 'M2'])\n",
    "    #combined_raw_046 = combined_raw_046 * 1e6\n",
    "    combined_raw_081.apply_function(lambda x: x * 1e6, picks='eeg')\n",
    "    # concatenates raw segments as if they were continuous\n",
    "    # boundaries of the raw files are annotated bad\n",
    "    combined_raw_081.pick([\"Fz\"]) \n",
    "\n",
    "# this is to be able to visualize all the EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1cc54e-4fbd-4dbd-b781-614ca32a0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_raw_081.times[-1])\n",
    "print(participant_081_raw.times[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3e893e-547d-40e5-9efc-e20f684f98e1",
   "metadata": {},
   "source": [
    "### *Slow oscillation detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f196dd-ef9e-4c51-a669-1a56837644c1",
   "metadata": {},
   "source": [
    "##### *slow_oscillations_081_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a1439e-4022-48c8-b12e-15ce9b11e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_oscillations_081_times = detect_slow_oscillations_times(combined_raw_081)\n",
    "#slow_oscillations_081_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc5b41c-2a52-47e7-ae4f-8af8dab2486c",
   "metadata": {},
   "source": [
    "##### *slow_oscillations_081_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311f9321-9747-4dd9-b385-983888e8e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_oscillations_081_peaks = detect_slow_oscillations_peaks(combined_raw_081)\n",
    "#slow_oscillations_081_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f152ee-0da8-40c7-b012-1ba940698b46",
   "metadata": {},
   "source": [
    "##### *sanity check of length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7042877f-dd59-43e4-a2e7-e9ac1e9fbff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(slow_oscillations_081_times))\n",
    "print(len(slow_oscillations_081_peaks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c943058-cbe8-4290-9d51-e85fe95e6e95",
   "metadata": {},
   "source": [
    "##### *Average slow oscillation visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a00b0f-db09-4b60-91a1-081ddcc02d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_and_stack_slow_oscillations_trough(combined_raw_081, slow_oscillations_081_times, 'Average Slow Oscillation (Trough-centered) for Participant 081 (0.3-1.25 Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9f8350-c6f5-49c1-9505-3852203be244",
   "metadata": {},
   "source": [
    "### *Spindle detection without peak frequency (Klinzing et al., 2016°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa85724-8d10-44e9-8c16-d2619d81b14f",
   "metadata": {},
   "source": [
    "##### *spindles_081_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e07f5b9-9878-45a8-a979-6c3d2ae4560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spindles_081_times = detect_spindles_times(combined_raw_081)\n",
    "#spindles_081_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4729acf-07d1-4501-8f1a-4fd398ef3067",
   "metadata": {},
   "source": [
    "##### *spindles_081_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bce180-542d-4824-ab6c-8670815f3948",
   "metadata": {},
   "outputs": [],
   "source": [
    "spindles_081_peaks = detect_spindles_peaks(combined_raw_081)\n",
    "#spindles_081_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b30c970-c2c8-4024-8fbe-13333eb453a7",
   "metadata": {},
   "source": [
    "##### *sanity check of length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7ebacc-1aa3-469f-b376-9db03bb3948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(spindles_081_times))\n",
    "print(len(spindles_081_peaks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42677c78-b361-4dec-9564-10a18ac6756e",
   "metadata": {},
   "source": [
    "##### *Average spindle visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef50819d-007c-404a-b200-b91ea5f825eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_spindles(combined_raw_081, 'Average Spindle (Peak-centered) for Participant 081 (12-16 Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16decdf-d072-4282-a065-20d0c7af29b3",
   "metadata": {},
   "source": [
    "### *Slow oscillation spindle coupling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692eb601-45a0-49b0-adf8-6303e2ac2490",
   "metadata": {},
   "source": [
    "##### *coupling_081_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b49a2-8eb1-43ed-8ec0-63f7b91a2b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupling_081_peaks = detect_slow_oscillations_spindles_coupling_peaks(combined_raw_081)\n",
    "coupling_081_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712c1392-f2a5-4c57-a40c-dbbb70e1f2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coupling_081_peaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa22d7b-3ada-46e3-adcb-5d0b6071a3dd",
   "metadata": {},
   "source": [
    "##### *coupling_081_so_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ffe54f-d0fd-4482-89fa-2556dd2638ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupling_081_so_times = detect_slow_oscillations_spindles_coupling_so_times(combined_raw_081)\n",
    "coupling_081_so_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c4f164-b93e-43cd-9c17-6e47dd0251a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coupling_081_so_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfbf1bf-0bc3-4271-ad2c-927e4365122b",
   "metadata": {},
   "source": [
    "##### *coupling_081_spindles_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf18a88-9252-40a6-8f29-31df772b285c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupling_081_spindles_times = detect_slow_oscillations_spindles_coupling_spindles_times(combined_raw_081)\n",
    "coupling_081_spindles_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f059b3fc-9da1-4390-b13a-246862c19e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(coupling_081_spindles_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f98904-d244-4866-8390-c800355784e9",
   "metadata": {},
   "source": [
    "##### *Visualization of average slow oscillation when coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5560f4-d1ff-48a6-8f16-22e2a7d35488",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_and_stack_slow_oscillations_trough(combined_raw_081, coupling_081_so_times, 'Average Coupled Slow Oscillation (Trough-centered) for Participant 081 (0.3-1.25 Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5a4121-4c48-4307-b700-f2aa6dc156b9",
   "metadata": {},
   "source": [
    "##### *Visualization: overlay slow oscillation waveform and spindle spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ed9218-8566-40fb-a1dd-411060062183",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_so_spindle_coupling(combined_raw_081, 'Average Spindle Time-Frequency & Slow Oscillation Coupling for Participant 081')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7f85e0-bc49-4b13-bcf8-b90d99a60767",
   "metadata": {},
   "source": [
    "# *Raw EEG Data Participant 067"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bdebfd-5796-4a5a-837c-b93f2276d2a0",
   "metadata": {},
   "source": [
    "### *Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f846f-2762-4246-84d0-25d92c9b3288",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_067_file = r\"C:\\EEG DATA\\067\\eeg\\TMR.vhdr\"\n",
    "\n",
    "participant_067_raw = mne.io.read_raw_brainvision(vhdr_fname=participant_067_file, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a911409b-86a1-4809-bef4-df9b015f7c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(participant_067_raw)\n",
    "print(participant_067_raw.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580ce577-d998-49d7-87b2-08fb325d940b",
   "metadata": {},
   "source": [
    "### *Onset times for participant 067"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273bf4aa-faf2-48cd-aea0-81d7367a2381",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data_onsets_067 = label_data_onsets['067']\n",
    "#label_data_onsets_067"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687f1486-fff4-4ccc-bb15-55ae19863baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_067 = group_by_increment(label_data_onsets_067, increment=30)\n",
    "groups_067"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8b4bba-59c7-4f0b-9386-fc72dc65e4fd",
   "metadata": {},
   "source": [
    "### *Plot raw segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196c26ae-764b-439d-970d-a7aadc68277f",
   "metadata": {},
   "source": [
    "#### *Combine raws + pick channel and filter directly in plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883234f1-f269-4322-851d-19c9b5247923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot it if want to check that EEG data looks correct\n",
    "\n",
    "# Extract segments\n",
    "segments_067 = extract_segments(participant_067_raw, groups_067)\n",
    "\n",
    "if segments_067:\n",
    "    combined_raw_067 = mne.concatenate_raws(segments_067)\n",
    "    # concatenates raw segments as if they were continuous\n",
    "    # boundaries of the raw files are annotated bad\n",
    "    combined_raw_067.set_eeg_reference(ref_channels = ['M1', 'M2'])\n",
    "    #combined_raw_046 = combined_raw_046 * 1e6\n",
    "    combined_raw_067.apply_function(lambda x: x * 1e6, picks='eeg')\n",
    "    # concatenates raw segments as if they were continuous\n",
    "    # boundaries of the raw files are annotated bad\n",
    "    combined_raw_067.pick([\"Fz\"]) \n",
    "# this is to be able to visualize all the EEG dataNormalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9589171e-0d0f-41f7-baea-46b80fa18a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_raw_067.times[-1])\n",
    "print(participant_067_raw.times[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69686733-a7d4-4911-a151-9e8b8c583af8",
   "metadata": {},
   "source": [
    "### *Slow oscillation detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08576c62-acbd-47ba-ac21-04ec81ce332d",
   "metadata": {},
   "source": [
    "##### *slow_oscillations_067_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5defd06c-e254-4a23-ae0e-678c91ace86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_oscillations_067_times = detect_slow_oscillations_times(combined_raw_067)\n",
    "#slow_oscillations_067_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd9e8a5-2455-49d8-aecf-16a853ea9dc3",
   "metadata": {},
   "source": [
    "##### *slow_oscillations_067_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447456af-6795-474f-bee5-bf64e447126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "slow_oscillations_067_peaks = detect_slow_oscillations_peaks(combined_raw_067)\n",
    "#slow_oscillations_067_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579bc5b1-6558-4055-b1ac-a732848a5415",
   "metadata": {},
   "source": [
    "##### *sanity check of length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b3b57-0809-4bb5-8c27-addc60866f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(slow_oscillations_067_times))\n",
    "print(len(slow_oscillations_067_peaks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f751078-673d-4368-ad35-bd6c49003e27",
   "metadata": {},
   "source": [
    "##### *Average slow oscillation visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38cdf69-cc5e-4bf6-bfca-5309e7e900d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_and_stack_slow_oscillations_trough(combined_raw_067, slow_oscillations_067_times, 'Average Slow Oscillation (Trough-centered) for Participant 067 (0.16-1.25 Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc57dd63-e022-43e7-ad66-6aa0a9dcfdef",
   "metadata": {},
   "source": [
    "### *Spindle detection without peak frequency (Klinzing et al., 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052ed50d-9247-4a8f-94b2-c4b1cd7c778f",
   "metadata": {},
   "source": [
    "##### *spindles_067_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ed2238-71c0-454b-a0aa-e95302bc879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spindles_067_times = detect_spindles_times(combined_raw_067)\n",
    "#spindles_067_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6560a9e5-ff09-44db-8184-c1b982fda649",
   "metadata": {},
   "source": [
    "##### *spindles_067_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b539180-306d-42a0-9d32-382ac48f0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "spindles_067_peaks = detect_spindles_peaks(combined_raw_067)\n",
    "#spindles_067_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8183ce-7ee3-4621-b7a2-74567f297659",
   "metadata": {},
   "source": [
    "##### *sanity_check_of_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3166d1-4300-456d-a8db-74a3336e99fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(spindles_067_times))\n",
    "print(len(spindles_067_peaks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d983d9-9316-4f5a-966d-1e9ac880fc1b",
   "metadata": {},
   "source": [
    "##### *Average spindle visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af60060b-5edc-4e84-866d-7447b80b59b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_spindles(combined_raw_067, 'Average Spindle (Peak-centered) for Participant 067 (12-16 Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a01ccbd-49e0-44fe-bd74-66a584a75a24",
   "metadata": {},
   "source": [
    "### *Slow oscillation spindle coupling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6449f2e5-860c-46f5-b0de-7c6734b1b67c",
   "metadata": {},
   "source": [
    "##### *coupling_067_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbce08a2-a7a6-4a6f-9cee-63788468cd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupling_067_peaks = detect_slow_oscillations_spindles_coupling_peaks(combined_raw_067)\n",
    "coupling_067_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68732bcf-ca5c-457d-9c08-49b5818c19db",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coupling_067_peaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2462e5-777d-4e6e-9088-605f4c759054",
   "metadata": {},
   "source": [
    "##### *coupling_067_so_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2346b7b-3b90-4e7d-99ab-41399dee455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupling_067_so_times = detect_slow_oscillations_spindles_coupling_so_times(combined_raw_067)\n",
    "coupling_067_so_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d467b8df-42f2-484b-903f-8b3e66660516",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coupling_067_so_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca164654-e5d9-4c76-9a8a-67c946284a45",
   "metadata": {},
   "source": [
    "##### *coupling_067_spindles_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679abbc3-7b50-47f0-8b9a-c7ad73b1b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coupling_067_spindles_times = detect_slow_oscillations_spindles_coupling_spindles_times(combined_raw_067)\n",
    "coupling_067_spindles_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58424159-681d-4a37-bc1a-2e47b0e67ca2",
   "metadata": {},
   "source": [
    "##### *Visualization of average slow oscillation when coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eec83f-af40-4d27-981b-42ffc35369cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_and_stack_slow_oscillations_trough(combined_raw_067, coupling_067_so_times, 'Average Coupled Slow Oscillation (Trough-centered) for Participant 067 (0.3-1.25 Hz)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9defd8-50a0-4ae2-8a4e-abeda339911e",
   "metadata": {},
   "source": [
    "##### *Visualization: overlay slow oscillation waveform and spindle spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8140ba-7a9e-43d4-8eb4-778f4917be63",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_so_spindle_coupling(combined_raw_067, 'Average Spindle Time-Frequency & Slow Oscillation Coupling for Participant 067')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
