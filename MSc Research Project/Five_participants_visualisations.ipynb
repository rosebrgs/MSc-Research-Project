{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00b3c25-4ba0-45b7-8491-528229c2ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvista\n",
    "import ipywidgets\n",
    "import ipyevents\n",
    "import pyvistaqt\n",
    "import yasa\n",
    "import os\n",
    "import random\n",
    "\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import stft\n",
    "\n",
    "import pywt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5beb49ef-a6ff-4ab0-ade8-df708e511e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356d696b-c121-42b9-a546-bf8b754ae812",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "139ca8c6-db81-46a7-ad53-db30194f04fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:\\EEG DATA\\combined_sets\\five_participants_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 1470000 ... 40455122 =   2940.000 ... 80910.244 secs\n",
      "Ready.\n",
      "Reading 0 ... 38985122  =      0.000 ... 77970.244 secs...\n"
     ]
    }
   ],
   "source": [
    "# file paths\n",
    "five_participants_file = r\"C:\\EEG DATA\\combined_sets\\five_participants_raw.fif\"\n",
    "\n",
    "# load raw files\n",
    "five_participants_raw = mne.io.read_raw_fif(five_participants_file, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df652b2-2504-4e1d-ab39-e2962d5c3e38",
   "metadata": {},
   "source": [
    "## Spindle detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "961b5a90-7636-4679-8b98-6d968587f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_spindles_times(eeg_raw, do_filter=True, do_downsample=False, downsample_rate=100):\n",
    "    \n",
    "    # 1. Filter between 12 and 16 Hz\n",
    "    \n",
    "    data = eeg_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=12, h_freq=16)\n",
    "    \n",
    "    # 2. Downsample at 100 Hz (100 samples per second)\n",
    "\n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "    \n",
    "    sfreq = data.info['sfreq']  \n",
    "    channel_data = data.get_data()[0]\n",
    "    # extract the filtered data\n",
    "    \n",
    "    \n",
    "    # 3: Calculate amplitude by applying Hilbert transformation\n",
    "\n",
    "    hilbert_signal = hilbert(channel_data)\n",
    "    # apply hilbert transformation to bandpassed data\n",
    "    # gives analytic signal with amplitude and phase information\n",
    "    envelope = np.abs(hilbert_signal)\n",
    "    # take the absolute part of the hilbert signal\n",
    "    # also the instantaneous power of the signal\n",
    "    # gives the envelope: amplitude modulation\n",
    "    # how strength of oscillations change over time\n",
    "    # size of sliding window\n",
    "    \n",
    "    # 4: Perform smoothing with a sliding window of 0.2 seconds\n",
    "    # this removes high-frequency noise\n",
    "    \n",
    "    sliding_window = int(0.2 * sfreq)\n",
    "    smoothed_envelope = np.convolve(envelope, np.ones(sliding_window) / sliding_window, mode='same')\n",
    "    # convolving envelope with a uniform filter over the sliding window\n",
    "    # convolution takes rolling average of 20 samples at a time\n",
    "    # smooth the signal with the average of values in the window\n",
    "    # in the smoothed envelope, can detect regions with higher amplitude \n",
    "    # which is when a spindle event occurs\n",
    "    # np.ones: creates a filter kernel\n",
    "    # have a filter where the sum of all elements equals 1\n",
    "    # this filter is replaced by the average of the 20 surrounding samples\n",
    "    # convolution between envelope and averaging filter\n",
    "    # mode = 'same': so that output of convolution has same length as original envelope\n",
    "\n",
    "    # 5. Define spindle detection threshold\n",
    "\n",
    "    threshold = np.percentile(smoothed_envelope, 75)\n",
    "    spindle_threshold = smoothed_envelope > threshold\n",
    "    #threshold = np.mean(smoothed_envelope) + 1.5 * np.std(smoothed_envelope)\n",
    "    #spindle_threshold = smoothed_envelope > threshold\n",
    "    # threshold is 75th percentile of the smoothed envelope\n",
    "    # will look at the duration later\n",
    "    \n",
    "    # 6. Detect spindles and define peaks and troughs for visualisation\n",
    "    \n",
    "    spindles = []\n",
    "    # initialize list with spindles\n",
    "    above_threshold = np.where(spindle_threshold)[0]\n",
    "    # returns indices where signal above the threshold\n",
    "    stacked_spindles = []\n",
    "    # initialize list for stacking the spindles for the visualisation\n",
    "    # contains aligned spindles at peak\n",
    "    \n",
    "    if len(above_threshold) > 0:\n",
    "        # checking it's not empty\n",
    "        start_idx = above_threshold[0]\n",
    "        # would be the start of a potential spindle\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] > above_threshold[i - 1] + 1:  \n",
    "                # if above threshold[1] > above_threshold[0] + 1\n",
    "                # because all indices should be separated by 1\n",
    "                # so here detects gaps\n",
    "                # so starting from the second index\n",
    "                # and comparing each index to the one before\n",
    "                end_idx = above_threshold[i - 1]\n",
    "                # so if above condition is true, this is the end of the spindle\n",
    "                duration = (end_idx - start_idx) / sfreq\n",
    "                if 0.5 <= duration <= 3:\n",
    "                    # only keep spindles lasting 0.5 to 3 seconds\n",
    "                    segment = channel_data[start_idx:end_idx]\n",
    "                    # extract EEG segment corresponding to detected spindle\n",
    "                    peak_idx = start_idx + np.argmax(segment) \n",
    "                    # extract the peak of the spindle\n",
    "                    # this will be useful for later\n",
    "                    spindles.append((start_idx / sfreq, end_idx / sfreq))\n",
    "                    # all the spindles are stored in spindles\n",
    "                    \n",
    "                    # Aligning spindles at peak for visualization\n",
    "                    before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "                    # still in the for loop, so this is the peak index of individual peak\n",
    "                    after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "                    # extracting 1.5 seconds before and after peak\n",
    "                    # max and min are used for out of bounds situations at the start and end of EEG data\n",
    "                    aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "                    stacked_spindles.append(aligned_segment)\n",
    "                    # the aligned segment is saved in stacked spindles\n",
    "                \n",
    "                start_idx = above_threshold[i]\n",
    "                # update the start index for the for loop\n",
    "\n",
    "        # then need to process the final spindle\n",
    "        end_idx = above_threshold[-1]\n",
    "        duration = (end_idx - start_idx) / sfreq\n",
    "        if 0.5 <= duration <= 3:\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            peak_idx = start_idx + np.argmax(segment)\n",
    "            spindles.append((start_idx / sfreq, end_idx / sfreq))\n",
    "\n",
    "            before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "            after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "            aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "            stacked_spindles.append(aligned_segment)\n",
    "    \n",
    "    return spindles\n",
    "    \n",
    "\n",
    "def detect_spindles_peaks(eeg_raw, do_filter=True, do_downsample=False, downsample_rate=100):\n",
    "    \n",
    "    # 1. Filter between 12 and 16 Hz\n",
    "    \n",
    "    data = eeg_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=12, h_freq=16)\n",
    "    \n",
    "    # 2. Downsample at 100 Hz (100 samples per second)\n",
    "    \n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "        \n",
    "    sfreq = data.info['sfreq']  \n",
    "    # update to new sampling frequency\n",
    "    # because used later in the code\n",
    "    channel_data = data.get_data()[0]\n",
    "    # extract the filtered data\n",
    "    \n",
    "    # 3: Calculate amplitude by applying Hilbert transformation\n",
    "\n",
    "    hilbert_signal = hilbert(channel_data)\n",
    "    # apply hilbert transformation to bandpassed data\n",
    "    # gives analytic signal with amplitude and phase information\n",
    "    envelope = np.abs(hilbert_signal)\n",
    "    # take the absolute part of the hilbert signal\n",
    "    # also the instantaneous power of the signal\n",
    "    # gives the envelope: amplitude modulation\n",
    "    # how strength of oscillations change over time\n",
    "    # size of sliding window\n",
    "    \n",
    "    # 4: Perform smoothing with a sliding window of 0.2 seconds\n",
    "    # this removes high-frequency noise\n",
    "    \n",
    "    sliding_window = int(0.2 * sfreq)\n",
    "    smoothed_envelope = np.convolve(envelope, np.ones(sliding_window) / sliding_window, mode='same')\n",
    "    # convolving envelope with a uniform filter over the sliding window\n",
    "    # convolution takes rolling average of 20 samples at a time\n",
    "    # smooth the signal with the average of values in the window\n",
    "    # in the smoothed envelope, can detect regions with higher amplitude \n",
    "    # which is when a spindle event occurs\n",
    "    # np.ones: creates a filter kernel\n",
    "    # have a filter where the sum of all elements equals 1\n",
    "    # this filter is replaced by the average of the 20 surrounding samples\n",
    "    # convolution between envelope and averaging filter\n",
    "    # mode = 'same': so that output of convolution has same length as original envelope\n",
    "\n",
    "    # 5. Define spindle detection threshold\n",
    "\n",
    "    threshold = np.percentile(smoothed_envelope, 75)\n",
    "    spindle_threshold = smoothed_envelope > threshold\n",
    "    # 75th percentile as criteria\n",
    "\n",
    "    #threshold = np.mean(smoothed_envelope) + 1.5 * np.std(smoothed_envelope)\n",
    "    #spindle_threshold = smoothed_envelope > threshold\n",
    "    \n",
    "    # 6. Detect spindles and define peaks and troughs for visualisation\n",
    "    \n",
    "    spindles = []\n",
    "    # initialize list with spindles\n",
    "    above_threshold = np.where(spindle_threshold)[0]\n",
    "    # returns indices where signal above the threshold\n",
    "    stacked_spindles = []\n",
    "    # initialize list for stacking the spindles for the visualisation\n",
    "    # contains aligned spindles at peak\n",
    "    \n",
    "    if len(above_threshold) > 0:\n",
    "        # checking it's not empty\n",
    "        start_idx = above_threshold[0]\n",
    "        # would be the start of a potential spindle\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] > above_threshold[i - 1] + 1:  \n",
    "                # if above threshold[1] > above_threshold[0] + 1\n",
    "                # because all indices should be separated by 1\n",
    "                # so here detects gaps\n",
    "                end_idx = above_threshold[i - 1]\n",
    "                # so if above condition is true, this is the end of the spindle\n",
    "                duration = (end_idx - start_idx) / sfreq\n",
    "                if 0.5 <= duration <= 3:\n",
    "                    # only keep spindles lasting 0.5 to 3 seconds\n",
    "                    segment = channel_data[start_idx:end_idx]\n",
    "                    # extract EEG segment corresponding to detected spindle\n",
    "                    peak_idx = start_idx + np.argmax(segment) \n",
    "                    # extract the peak of the spindle\n",
    "                    # this will be useful for later\n",
    "                    #spindles.append(f\"Spindle detected from {start_idx / sfreq:.2f}s to {end_idx / sfreq:.2f}s, peak at {peak_idx / sfreq:.2f}s\")\n",
    "                    spindles.append((peak_idx / sfreq))\n",
    "                    # all the spindles are stored in spindles\n",
    "                    \n",
    "                    # Aligning spindles at peak for visualization\n",
    "                    before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "                    # still in the for loop, so this is the peak index of individual peak\n",
    "                    after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "                    # extracting 1.5 seconds before and after peak\n",
    "                    # max and min are used for out of bounds situations at the start and end of EEG data\n",
    "                    aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "                    stacked_spindles.append(aligned_segment)\n",
    "                    # the aligned segment is saved in stacked spindles\n",
    "                \n",
    "                start_idx = above_threshold[i]\n",
    "                # update the start index for the for loop\n",
    "\n",
    "        # then need to process the final spindle\n",
    "        end_idx = above_threshold[-1]\n",
    "        duration = (end_idx - start_idx) / sfreq\n",
    "        if 0.5 <= duration <= 3:\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            peak_idx = start_idx + np.argmax(segment)\n",
    "            spindles.append((peak_idx / sfreq))\n",
    "\n",
    "            before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "            after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "            aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "            stacked_spindles.append(aligned_segment)\n",
    "\n",
    "    \n",
    "    return spindles\n",
    "\n",
    "def detect_spindles_peaks_average(eeg_raw, do_filter=True, do_downsample=False, downsample_rate=100):\n",
    "    \n",
    "    # 1. Filter between 12 and 16 Hz\n",
    "    \n",
    "    data = eeg_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=12, h_freq=16)\n",
    "    \n",
    "    # 2. Downsample at 100 Hz (100 samples per second)\n",
    "    \n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "        \n",
    "    sfreq = data.info['sfreq']  \n",
    "    # update to new sampling frequency\n",
    "    # because used later in the code\n",
    "    channel_data = data.get_data()[0]\n",
    "    # extract the filtered data\n",
    "    \n",
    "    # 3: Calculate amplitude by applying Hilbert transformation\n",
    "\n",
    "    hilbert_signal = hilbert(channel_data)\n",
    "    # apply hilbert transformation to bandpassed data\n",
    "    # gives analytic signal with amplitude and phase information\n",
    "    envelope = np.abs(hilbert_signal)\n",
    "    # take the absolute part of the hilbert signal\n",
    "    # also the instantaneous power of the signal\n",
    "    # gives the envelope: amplitude modulation\n",
    "    # how strength of oscillations change over time\n",
    "    # size of sliding window\n",
    "    \n",
    "    # 4: Perform smoothing with a sliding window of 0.2 seconds\n",
    "    # this removes high-frequency noise\n",
    "    \n",
    "    sliding_window = int(0.2 * sfreq)\n",
    "    smoothed_envelope = np.convolve(envelope, np.ones(sliding_window) / sliding_window, mode='same')\n",
    "    # convolving envelope with a uniform filter over the sliding window\n",
    "    # convolution takes rolling average of 20 samples at a time\n",
    "    # smooth the signal with the average of values in the window\n",
    "    # in the smoothed envelope, can detect regions with higher amplitude \n",
    "    # which is when a spindle event occurs\n",
    "    # np.ones: creates a filter kernel\n",
    "    # have a filter where the sum of all elements equals 1\n",
    "    # this filter is replaced by the average of the 20 surrounding samples\n",
    "    # convolution between envelope and averaging filter\n",
    "    # mode = 'same': so that output of convolution has same length as original envelope\n",
    "\n",
    "    # 5. Define spindle detection threshold\n",
    "\n",
    "    threshold = np.percentile(smoothed_envelope, 75)\n",
    "    spindle_threshold = smoothed_envelope > threshold\n",
    "    # 75th percentile as criteria\n",
    "\n",
    "    #threshold = np.mean(smoothed_envelope) + 1.5 * np.std(smoothed_envelope)\n",
    "    #spindle_threshold = smoothed_envelope > threshold\n",
    "    \n",
    "    # 6. Detect spindles and define peaks and troughs for visualisation\n",
    "    \n",
    "    spindles = []\n",
    "    # initialize list with spindles\n",
    "    above_threshold = np.where(spindle_threshold)[0]\n",
    "    # returns indices where signal above the threshold\n",
    "    stacked_spindles = []\n",
    "    # initialize list for stacking the spindles for the visualisation\n",
    "    # contains aligned spindles at peak\n",
    "    \n",
    "    if len(above_threshold) > 0:\n",
    "        # checking it's not empty\n",
    "        start_idx = above_threshold[0]\n",
    "        # would be the start of a potential spindle\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] > above_threshold[i - 1] + 1:  \n",
    "                # if above threshold[1] > above_threshold[0] + 1\n",
    "                # because all indices should be separated by 1\n",
    "                # so here detects gaps\n",
    "                end_idx = above_threshold[i - 1]\n",
    "                # so if above condition is true, this is the end of the spindle\n",
    "                duration = (end_idx - start_idx) / sfreq\n",
    "                if 0.5 <= duration <= 3:\n",
    "                    # only keep spindles lasting 0.5 to 3 seconds\n",
    "                    segment = channel_data[start_idx:end_idx]\n",
    "                    # extract EEG segment corresponding to detected spindle\n",
    "                    peak_idx = start_idx + np.argmax(segment) \n",
    "                    # extract the peak of the spindle\n",
    "                    # this will be useful for later\n",
    "                    #spindles.append(f\"Spindle detected from {start_idx / sfreq:.2f}s to {end_idx / sfreq:.2f}s, peak at {peak_idx / sfreq:.2f}s\")\n",
    "                    spindles.append((peak_idx / sfreq))\n",
    "                    # all the spindles are stored in spindles\n",
    "                    \n",
    "                    # Aligning spindles at peak for visualization\n",
    "                    before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "                    # still in the for loop, so this is the peak index of individual peak\n",
    "                    after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "                    # extracting 1.5 seconds before and after peak\n",
    "                    # max and min are used for out of bounds situations at the start and end of EEG data\n",
    "                    aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "                    stacked_spindles.append(aligned_segment)\n",
    "                    # the aligned segment is saved in stacked spindles\n",
    "                \n",
    "                start_idx = above_threshold[i]\n",
    "                # update the start index for the for loop\n",
    "\n",
    "        # then need to process the final spindle\n",
    "        end_idx = above_threshold[-1]\n",
    "        duration = (end_idx - start_idx) / sfreq\n",
    "        if 0.5 <= duration <= 3:\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            peak_idx = start_idx + np.argmax(segment)\n",
    "            spindles.append((peak_idx / sfreq))\n",
    "\n",
    "            before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "            after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "            aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "            stacked_spindles.append(aligned_segment)\n",
    "\n",
    "    \n",
    "    return spindles, stacked_spindles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56cdca1b-148a-4610-9067-4c56b632519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_spindles(stacked_spindles, plot_name):\n",
    "    max_len = max(len(seg) for seg in stacked_spindles)\n",
    "    padded_stacked_spindles = [np.pad(seg, (0, max_len - len(seg)), constant_values=np.nan) for seg in stacked_spindles]\n",
    "    avg_spindle_waveform = np.nanmean(padded_stacked_spindles, axis=0)\n",
    "    time_axis = np.linspace(-1.5, 1.5, len(avg_spindle_waveform))\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(time_axis, avg_spindle_waveform, color=\"blue\", label=\"Mean Spindle\")\n",
    "    plt.axvline(0, color=\"red\", linestyle=\"--\", label=\"Peak (0s)\")\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude (µV)')\n",
    "    plt.title(plot_name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be09852-473f-461d-b9cc-523182a9d3e8",
   "metadata": {},
   "source": [
    "## Slow oscillation detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20980f99-324d-4663-aaf8-2f864a345fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_slow_oscillations_times(combined_raw, do_filter=True, do_downsample=False, downsample_rate=100):\n",
    "\n",
    "    # according to methods from Klinzing et al.(2016)\n",
    "\n",
    "    data = combined_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=0.16, h_freq=1.25)\n",
    "\n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "        \n",
    "    sfreq = data.info['sfreq']\n",
    "    channel_data = data.get_data()[0]\n",
    "    \n",
    "    # 3. find all positive-to-negative zero-crossings\n",
    "    \n",
    "    # zero_crossings = np.where( S!= 0)[0]\n",
    "    # can also save this somewhere for further detection of spindles\n",
    "    \n",
    "    S = np.diff(np.sign(channel_data))\n",
    "    # np.sign returns an array with 1 (positive), 0 (zero), -1 (negative)\n",
    "    # np.diff calculates the difference between consecutive elements in an array\n",
    "    # positive value: transition from negative to positive\n",
    "    # negative value: transition from positive to negative\n",
    "    # when it's a zero, means that value stayed the same\n",
    "    zero_crossings = np.where(S < 0)[0]\n",
    "    # -2 is when a positive-to-negative zero-crossing occurs\n",
    "    # goes from 1 to -1 \n",
    "    # -1 - 1 = -2\n",
    "    # [0] extracts the actual array\n",
    "    # extracts the indices of interest from current_data (not S)\n",
    "    #signs = np.sign(current_data)\n",
    "    #pos_to_neg = np.where((signs[:-1] > 0) & (signs[1:] < 0))[0]\n",
    "    # detect +1 to -1\n",
    "    #neg_to_pos = np.where((signs[:-1] <  0) & (signs[1:] > 0))[0]\n",
    "    # detect -1 to +1\n",
    "\n",
    "    # 4. Detect peak potentials in each pair\n",
    "    slow_oscillations = []\n",
    "    negative_peaks = []\n",
    "    positive_peaks = []\n",
    "    peak_to_peak_amplitudes = []\n",
    "    candidate_indices = []\n",
    "\n",
    "    # for loop for each pair\n",
    "    # to collect all the negative and positive peaks\n",
    "    # to further apply criteria\n",
    "    count = 0\n",
    "    for i in range(0, len(zero_crossings)-1, 1):\n",
    "        # loop through all the zero_crossings\n",
    "        # step of 1 (with step of 2, miss some zero_crossings)\n",
    "        start_idx = zero_crossings[i] + 1\n",
    "        # assigns index of zero-crossing (representing start of potential SO)\n",
    "        # to start_idx\n",
    "        end_idx = zero_crossings[i + 1] + 1\n",
    "        # assigns index of next zero-crossing (representing end of potential SO)\n",
    "        # to end_idx\n",
    "\n",
    "        # find the negative to positive crossing in between\n",
    "        #mid_crossings = neg_to_pos[(neg_to_pos > start_idx) & (neg_to_pos < end_idx)]\n",
    "\n",
    "        #if len(mid_crossings) != 1:\n",
    "            #continue\n",
    "\n",
    "        #mid_idx = mid_crossings [0]\n",
    "\n",
    "        #duration = (end_idx - start_idx) / sfreq\n",
    "        #if not (0.8 <= duration <= 2.0):\n",
    "  \n",
    "        \n",
    "        segment_length = (end_idx - start_idx) / sfreq\n",
    "\n",
    "        # need to add +1 because of way extract segment later\n",
    "\n",
    "        # have identified index for the pair\n",
    "        \n",
    "        # extract data segment between crossings\n",
    "        \n",
    "        # find peaks\n",
    "        if 0.8 <= segment_length <= 2.0:\n",
    "            count += 1\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            positive_peak = np.max(segment)\n",
    "            negative_peak = np.min(segment)\n",
    "            peak_to_peak_amplitude = positive_peak - negative_peak\n",
    "\n",
    "        # store values\n",
    "            candidate_indices.append((start_idx, end_idx))\n",
    "            positive_peaks.append(positive_peak)\n",
    "            negative_peaks.append(negative_peak)\n",
    "            peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "\n",
    "    # calculate mean values for comparison\n",
    "    #mean_negative_peak = np.mean(negative_peaks)\n",
    "    # mean_negative_peak = np.mean(negative_peaks) if negative_peaks else 0\n",
    "    #mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes)\n",
    "    # mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes) if peak_to_peak_amplitudes else 0\n",
    "\n",
    "    negative_peak_threshold = np.percentile(negative_peaks, 25)\n",
    "    # keep lowest negative peaks (under the 25th percentile)\n",
    "    peak_to_peak_amplitude_threshold = np.percentile(peak_to_peak_amplitudes, 75)\n",
    "    # keep largest peak-to-peak amplitude (over 75th percentile)\n",
    "\n",
    "    for (start_idx, end_idx), negative_peak, peak_to_peak_amplitude in zip(candidate_indices, negative_peaks, peak_to_peak_amplitudes):\n",
    "        if peak_to_peak_amplitude >= peak_to_peak_amplitude_threshold and negative_peak <= negative_peak_threshold:\n",
    "            slow_oscillations.append((start_idx / sfreq, end_idx / sfreq))\n",
    "            \n",
    "    return slow_oscillations\n",
    "    # returns a list of tuples, in which each tuple represents the start and end times of\n",
    "    # a detected slow oscillation\n",
    "\n",
    "def detect_slow_oscillations_peaks(combined_raw, do_filter=True, do_downsample=True, downsample_rate=100):\n",
    "\n",
    "    # according to methods from Klinzing et al.(2016)\n",
    "\n",
    "    data = combined_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=0.16, h_freq=1.25)\n",
    "\n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "        \n",
    "    sfreq = data.info['sfreq']\n",
    "    channel_data = data.get_data()[0]\n",
    "    \n",
    "    # 3. find all positive-to-negative zero-crossings\n",
    "    \n",
    "    # zero_crossings = np.where( S!= 0)[0]\n",
    "    # can also save this somewhere for further detection of spindles\n",
    "    \n",
    "    S = np.diff(np.sign(channel_data))\n",
    "    # np.sign returns an array with 1 (positive), 0 (zero), -1 (negative)\n",
    "    # np.diff calculates the difference between consecutive elements in an array\n",
    "    # positive value: transition from negative to positive\n",
    "    # negative value: transition from positive to negative\n",
    "    # when it's a zero, means that value stayed the same\n",
    "    zero_crossings = np.where(S < 0)[0]\n",
    "    # -2 is when a positive-to-negative zero-crossing occurs\n",
    "    # goes from 1 to -1 \n",
    "    # -1 - 1 = -2\n",
    "    # [0] extracts the actual array\n",
    "    # extracts the indices of interest from current_data (not S)\n",
    "\n",
    "\n",
    "    # 4. Detect peak potentials in each pair\n",
    "    slow_oscillations = []\n",
    "    slow_oscillations_peaks = []\n",
    "    negative_peaks = []\n",
    "    positive_peaks = []\n",
    "    peak_to_peak_amplitudes = []\n",
    "    candidate_indices =  []\n",
    "\n",
    "    # for loop for each pair\n",
    "    # to collect all the negative and positive peaks\n",
    "    # to further apply criteria\n",
    "    count = 0\n",
    "    for i in range(0, len(zero_crossings) - 1, 1):\n",
    "        # loop through all the zero_crossings\n",
    "        # step of 1 (with step of 2, miss some zero_crossings)\n",
    "        start_idx = zero_crossings[i] + 1\n",
    "        # assigns index of zero-crossing (representing start of potential SO)\n",
    "        # to start_idx\n",
    "        end_idx = zero_crossings[i + 1] + 1\n",
    "        # assigns index of next zero-crossing (representing end of potential SO)\n",
    "        # to end_idx\n",
    "        segment_length = (end_idx - start_idx) / sfreq\n",
    "\n",
    "        # need to add +1 because of way extract segment later\n",
    "\n",
    "        # have identified index for the pair\n",
    "        \n",
    "        # extract data segment between crossings\n",
    "        \n",
    "        # find peaks\n",
    "        if 0.8 <= segment_length <= 2.0:\n",
    "            count += 1\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            positive_peak = np.max(segment)\n",
    "            negative_peak = np.min(segment)\n",
    "            peak_to_peak_amplitude = positive_peak - negative_peak\n",
    "\n",
    "        # store values\n",
    "            candidate_indices.append((start_idx, end_idx))\n",
    "            positive_peaks.append(positive_peak)\n",
    "            negative_peaks.append(negative_peak)\n",
    "            peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "\n",
    "    # calculate mean values for comparison\n",
    "    #mean_negative_peak = np.mean(negative_peaks)\n",
    "    # mean_negative_peak = np.mean(negative_peaks) if negative_peaks else 0\n",
    "    #mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes)\n",
    "    # mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes) if peak_to_peak_amplitudes else 0\n",
    "\n",
    "    negative_peak_threshold = np.percentile(negative_peaks, 25)\n",
    "    peak_to_peak_amplitude_threshold = np.percentile(peak_to_peak_amplitudes, 75)\n",
    "\n",
    "    for (start_idx, end_idx), negative_peak, peak_to_peak_amplitude in zip(candidate_indices, negative_peaks, peak_to_peak_amplitudes):\n",
    "        if peak_to_peak_amplitude >= peak_to_peak_amplitude_threshold and negative_peak <= negative_peak_threshold:\n",
    "            slow_oscillations.append((start_idx / sfreq, end_idx / sfreq))\n",
    "            slow_oscillations_peaks.append((negative_peak, positive_peak))\n",
    "\n",
    "            \n",
    "    return slow_oscillations_peaks\n",
    "    # returns a list of tuples, in which each tuple represents the start and end times of\n",
    "    # a detected slow oscillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "392d72d7-ee0e-49a6-8204-27c01fb168d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now want to visualise slow oscillations\n",
    "# find peak and trough for each of them, and then stack them all together to visualise\n",
    "\n",
    "# this function aligns detected slow oscillations at their trough\n",
    "# creates an average SO waveform\n",
    "\n",
    "def visualize_and_stack_slow_oscillations_trough(combined_raw, slow_oscillations_times, plot_name):\n",
    "\n",
    "    # Apply band-pass filter between 0.3 and 1.25 Hz\n",
    "    filtered_data = combined_raw.copy().filter(l_freq=0.16, h_freq=1.25)\n",
    "    # downsampling to 100 Hz\n",
    "    #filtered_data.resample(100)\n",
    "    filtered_channel_data = filtered_data.get_data(picks=\"Fz\")[0]\n",
    "    \n",
    "    sfreq = filtered_data.info['sfreq']\n",
    "    \n",
    "    stacked_data = []\n",
    "    # loop through each slow oscillation\n",
    "    for start_time, end_time in slow_oscillations_times:\n",
    "        # to convert start and end times to sample indices\n",
    "        start_idx = int(start_time * sfreq)\n",
    "        end_idx = int(end_time * sfreq)\n",
    "\n",
    "        # extract the slow oscillation segment\n",
    "        segment = filtered_channel_data[start_idx:end_idx]\n",
    "\n",
    "        global_trough_idx = np.argmin(filtered_channel_data[start_idx:end_idx]) + start_idx\n",
    "         # argmin finds the index of the min value\n",
    "        # min finds the min value itself\n",
    "        \n",
    "        # calculate indices for 1.5 seconds before and after trough\n",
    "        before_trough_idx = max(0, global_trough_idx - int(1.5 * sfreq))\n",
    "        # substracts 1.5 seconds from the trough index\n",
    "        # max as a safety check, to make sure that before_trough_index never negative\n",
    "        # to prevent accessing data points before the beginning of the segment\n",
    "        after_trough_idx = min(len(filtered_channel_data), global_trough_idx + int(1.5 * sfreq))\n",
    "        # adds 1.5 seconds to the trough index\n",
    "        # min is another safety check\n",
    "        \n",
    "        # extract the segment around the trough\n",
    "        aligned_segment = filtered_channel_data[before_trough_idx:after_trough_idx]\n",
    "\n",
    "        # append the aligned segment to the stacked data\n",
    "        stacked_data.append(aligned_segment)\n",
    "\n",
    "    # Find the maximum length of the segments\n",
    "    max_len = max(len(segment) for segment in stacked_data)\n",
    "\n",
    "    # Pad shorter segments with np.nan\n",
    "    padded_stacked_data = []\n",
    "    for segment in stacked_data:\n",
    "        pad_len = max_len - len(segment)\n",
    "        # how much padding is needed\n",
    "        pad_before = pad_len // 2\n",
    "        pad_after = pad_len - pad_before\n",
    "        padded_segment = np.pad(segment, (pad_before, pad_after), 'constant', constant_values=np.nan)\n",
    "        # distribute the padding before and after the segment\n",
    "        # use NaNs instead of zeros to avoid bias\n",
    "        padded_stacked_data.append(padded_segment)\n",
    "\n",
    "    # calculate the average stacked slow oscillation\n",
    "    average_padded_stacked_data = np.nanmean(padded_stacked_data, axis=0)\n",
    "    # compute average waveform by ignoring NaNs\n",
    "\n",
    "    # visualize the average stacked slow oscillation\n",
    "    time_axis = np.linspace(-1.5, 1.5, len(average_padded_stacked_data))\n",
    "    # this is to create the time axis\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(time_axis, average_padded_stacked_data, color=\"blue\", label=\"Mean SO\")\n",
    "    plt.axvline(0, color=\"red\", linestyle=\"--\", label=\"Trough (0s)\")\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude (µV)')\n",
    "    plt.title(plot_name)\n",
    "    plt.legend()\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757a47d5-6917-4bd5-bf4a-79df47ec9787",
   "metadata": {},
   "source": [
    "## SO-spindle coupling detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6771ec46-4c9b-4edd-9c58-b18915a3057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_slow_oscillations_spindles_coupling_so_times(combined_raw, do_filter=True, do_downsample=True, downsample_rate=100):\n",
    "    slow_oscillations_peaks = detect_slow_oscillations_peaks(combined_raw, do_filter=do_filter, do_downsample=do_downsample, downsample_rate=downsample_rate)\n",
    "    slow_oscillations_times = detect_slow_oscillations_times(combined_raw, do_filter=do_filter, do_downsample=do_downsample, downsample_rate=downsample_rate)\n",
    "    spindles_peaks = detect_spindles_peaks(combined_raw, do_filter=do_filter, do_downsample=do_downsample, downsample_rate=downsample_rate)\n",
    "\n",
    "    coupling_times = []\n",
    "    coupling_times_so = []\n",
    "\n",
    "    # first detect the coupling events\n",
    "    for start_time, end_time in slow_oscillations_times:\n",
    "    #for start_time, end_time (negative_peak, positive_peak) in zip(slow_oscillations_times, slow_oscillations_peaks):\n",
    "        for peak in spindles_peaks:\n",
    "            if start_time < peak < end_time:\n",
    "                # if negative_peak < peak < end_time:\n",
    "                coupling_times.append(peak)\n",
    "                # if the peak of the spindle is between the negative and positive trough\n",
    "                # add it to list of coupling times\n",
    "\n",
    "    # then calculate the slow oscillation length\n",
    "    for start_time, end_time in slow_oscillations_times:\n",
    "        current_start_time = start_time\n",
    "        current_end_time = end_time\n",
    "        for coupling_peak in coupling_times:\n",
    "            if current_start_time < coupling_peak < current_end_time:\n",
    "                coupling_times_so.append((current_start_time, current_end_time))\n",
    "\n",
    "    return coupling_times_so"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4c5cf-c198-4b1d-9bd0-f996c4e84367",
   "metadata": {},
   "source": [
    "## Density"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed73c7a-168d-4bc0-a8e4-2e7d151b1137",
   "metadata": {},
   "source": [
    "### at 500 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc6ca0a3-07c9-4dbd-865a-e595423aa0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 12 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 12.00\n",
      "- Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 551 samples (1.102 s)\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 0.16 - 1.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.16\n",
      "- Lower transition bandwidth: 0.16 Hz (-6 dB cutoff frequency: 0.08 Hz)\n",
      "- Upper passband edge: 1.25 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.25 Hz)\n",
      "- Filter length: 10313 samples (20.626 s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spindles_times = detect_spindles_times(\n",
    "    five_participants_raw,\n",
    "    do_filter=True,\n",
    "    do_downsample=False\n",
    ")\n",
    "\n",
    "slow_oscillations_times = detect_slow_oscillations_times(\n",
    "    five_participants_raw,\n",
    "    do_filter=True,\n",
    "    do_downsample=False\n",
    ")                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f437cf82-c630-415c-8cc7-6331acaf4fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 0.16 - 1.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.16\n",
      "- Lower transition bandwidth: 0.16 Hz (-6 dB cutoff frequency: 0.08 Hz)\n",
      "- Upper passband edge: 1.25 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.25 Hz)\n",
      "- Filter length: 10313 samples (20.626 s)\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 0.16 - 1.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.16\n",
      "- Lower transition bandwidth: 0.16 Hz (-6 dB cutoff frequency: 0.08 Hz)\n",
      "- Upper passband edge: 1.25 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.25 Hz)\n",
      "- Filter length: 10313 samples (20.626 s)\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 12 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 12.00\n",
      "- Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 551 samples (1.102 s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "so_spindle_coupling_times = detect_slow_oscillations_spindles_coupling_so_times(\n",
    "    five_participants_raw,\n",
    "    do_filter=True,\n",
    "    do_downsample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f400de2a-5d00-4b0f-a1f2-f6cf3e9e5060",
   "metadata": {},
   "outputs": [],
   "source": [
    "## average number of SO, spindle or coupling per min\n",
    "sfreq = five_participants_raw.info['sfreq']\n",
    "\n",
    "# count number of events\n",
    "num_spindles = len(spindles_times)\n",
    "num_slow_oscillations_times = len(slow_oscillations_times)\n",
    "num_so_spindle_coupling = len(so_spindle_coupling_times)\n",
    "\n",
    "# the duration\n",
    "duration_sec = five_participants_raw.times[-1]\n",
    "duration_min = duration_sec / 60\n",
    "\n",
    "# Averages\n",
    "avg_spindles_per_min = num_spindles / duration_min\n",
    "avg_sos_per_min = num_slow_oscillations_times / duration_min\n",
    "avg_couplings_per_min = num_so_spindle_coupling / duration_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "164ea2eb-e2cb-4ad3-9973-bf3da7ef9bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Metric      Value\n",
      "0              Spindle density  10.056914\n",
      "1                   SO density   4.394753\n",
      "2  SO-spindle coupling density   1.636009\n"
     ]
    }
   ],
   "source": [
    "def summary_to_dataframe(avg_spindles_per_min, avg_sos_per_min, avg_couplinds_per_min):\n",
    "    data = {\n",
    "        \"Metric\": [\"Spindle density\", \"SO density\", \"SO-spindle coupling density\"],\n",
    "        \"Value\": [avg_spindles_per_min, avg_sos_per_min, avg_couplings_per_min]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df_summary = summary_to_dataframe(avg_spindles_per_min, avg_sos_per_min, avg_couplings_per_min)\n",
    "print(df_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c7c252-4714-4cc5-be0d-aced80845670",
   "metadata": {},
   "source": [
    "## Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e89fea8-008a-445b-940c-34029060ba6c",
   "metadata": {},
   "source": [
    "### Spindle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dff5afed-c1cc-412c-984b-599a361c2e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 12 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 12.00\n",
      "- Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 551 samples (1.102 s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spindles_times = detect_spindles_times(five_participants_raw, do_filter=True, do_downsample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c141af38-ce65-4245-a290-87e80c8154da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(np.float64(0.046), np.float64(0.92)), (np.float64(4.94), np.float64(6.132)), (np.float64(10.002), np.float64(10.578)), (np.float64(19.398), np.float64(20.796)), (np.float64(27.22), np.float64(28.674))]\n"
     ]
    }
   ],
   "source": [
    "print(spindles_times[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e233c2-17b3-4d97-96d3-4d15b76ef1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spindles, stacked = detect_spindles_peaks_average(five_participants_raw)\n",
    "visualize_spindles(stacked, \"Average Spindle for 5 participants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a500bf2b-1040-4d62-a49e-8ee3d60ff1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spindles[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c191e2b-73b6-415a-be84-6dcfd9933eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 12 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 12.00\n",
      "- Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 551 samples (1.102 s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spindles_peaks = detect_spindles_peaks(five_participants_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bea979-5e60-4932-868d-0c4b2b1dbb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(spindles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f896fdf-b6ae-4b36-944a-29af539bac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(slow_oscillations_peaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f20c2c-c10d-462a-af0d-1a0ad83c3df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(slow_oscillations_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01a7971-c6f9-45d7-a1bc-9910c66a9e6e",
   "metadata": {},
   "source": [
    "### Slow oscillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ff22996-86f8-453f-bc37-f8ce9dbe6e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 0.16 - 1.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.16\n",
      "- Lower transition bandwidth: 0.16 Hz (-6 dB cutoff frequency: 0.08 Hz)\n",
      "- Upper passband edge: 1.25 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.25 Hz)\n",
      "- Filter length: 10313 samples (20.626 s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "slow_oscillations_times = detect_slow_oscillations_times(five_participants_raw, do_filter=True, do_downsample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f237f4-dba2-4398-a15b-0997c522a4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(slow_oscillations_times[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61958ce1-8a55-4f9b-abbd-3b31d901b260",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if do_downsample=True, need to turn on downsampling in visualisation function\n",
    "\n",
    "visualize_and_stack_slow_oscillations_trough(\n",
    "    five_participants_raw,\n",
    "    slow_oscillations_times,\n",
    "    plot_name=\"Average Slow Oscillation for 5 participants\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e035cb88-f04d-48b1-b024-bfbc3668e468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 0.16 - 1.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.16\n",
      "- Lower transition bandwidth: 0.16 Hz (-6 dB cutoff frequency: 0.08 Hz)\n",
      "- Upper passband edge: 1.25 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.25 Hz)\n",
      "- Filter length: 10313 samples (20.626 s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "slow_oscillations_peaks = detect_slow_oscillations_peaks(\n",
    "    five_participants_raw,\n",
    "    do_filter=True,\n",
    "    do_downsample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd038c9e-f436-4e86-890a-49217c2c92bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spindles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(spindles)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spindles' is not defined"
     ]
    }
   ],
   "source": [
    "print(spindles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf44272c-64c1-4099-9138-47a9ed25f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(slow_oscillations_peaks[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b16bc5e-b089-44ae-9ad1-59ddae75b18e",
   "metadata": {},
   "source": [
    "## Coupling visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba65a37-7a60-4e67-b9a5-593aef4e57be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_paired_events(slow_oscillations, spindles):\n",
    "\n",
    "    paired_events = []\n",
    "    for so_start, so_end in slow_oscillations:\n",
    "        for sp_start, sp_end in spindles:\n",
    "            # Check for overlap\n",
    "            if max(so_start, sp_start) < min(so_end, sp_end):\n",
    "                paired_events.append((so_start, so_end, sp_start, sp_end))\n",
    "    return paired_events\n",
    "\n",
    "def detect_unpaired_events(slow_oscillations, spindles):\n",
    "\n",
    "    paired_so_indices = set()\n",
    "    paired_sp_indices = set()\n",
    "\n",
    "    for i, (so_start, so_end) in enumerate(slow_oscillations):\n",
    "        for j, (sp_start, sp_end) in enumerate(spindles):\n",
    "            if max(so_start, sp_start) < min(so_end, sp_end):\n",
    "                paired_so_indices.add(i)\n",
    "                paired_sp_indices.add(j)\n",
    "\n",
    "    unpaired_so = [so for i, so in enumerate(slow_oscillations) if i not in paired_so_indices]\n",
    "    unpaired_sp = [sp for i, sp in enumerate(spindles) if i not in paired_sp_indices]\n",
    "\n",
    "    return unpaired_so, unpaired_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7725f8-9f0c-4bb0-b664-b82ad88b78ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_event(raw, so, sp, title):\n",
    "    \n",
    "    # Get the data for the Fz channel\n",
    "    data, times = raw.get_data(picks=['Fz'], return_times=True)\n",
    "    data = data[0]\n",
    "\n",
    "    # Get the start and end times for the plot\n",
    "    start_time = min(so[0], sp[0]) - 1\n",
    "    end_time = max(so[1], sp[1]) + 1\n",
    "\n",
    "    # Get the indices for the start and end times\n",
    "    start_idx = np.where(times >= start_time)[0][0]\n",
    "    end_idx = np.where(times <= end_time)[0][-1]\n",
    "\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(times[start_idx:end_idx], data[start_idx:end_idx], label='EEG')\n",
    "\n",
    "    # Highlight the slow oscillation\n",
    "    so_start_idx = np.where(times >= so[0])[0][0]\n",
    "    so_end_idx = np.where(times <= so[1])[0][-1]\n",
    "    plt.fill_between(times[so_start_idx:so_end_idx], data[so_start_idx:so_end_idx], color='blue', alpha=0.3, label='Slow Oscillation')\n",
    "\n",
    "    # Highlight the spindle\n",
    "    sp_start_idx = np.where(times >= sp[0])[0][0]\n",
    "    sp_end_idx = np.where(times <= sp[1])[0][-1]\n",
    "    plt.fill_between(times[sp_start_idx:sp_end_idx], data[sp_start_idx:sp_end_idx], color='red', alpha=0.3, label='Spindle')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude (µV)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516bdc88-0bb5-419e-a4ff-abda736912e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SO and spindle detection\n",
    "slow_oscillations = detect_slow_oscillations_times(five_participants_raw)\n",
    "spindles = detect_spindles_times(five_participants_raw)\n",
    "\n",
    "# paired and unpaired events\n",
    "paired_events = detect_paired_events(slow_oscillations, spindles)\n",
    "unpaired_so, unpaired_sp = detect_unpaired_events(slow_oscillations, spindles)\n",
    "\n",
    "# paired event visualisation\n",
    "if paired_events:\n",
    "    so_start, so_end, sp_start, sp_end = paired_events[0]\n",
    "    plot_event(five_participants_raw, (so_start, so_end), (sp_start, sp_end), 'Paired Slow Oscillation and Spindle')\n",
    "else:\n",
    "    print(\"No paired events found.\")\n",
    "\n",
    "# unpaired so visualisation\n",
    "if unpaired_so:\n",
    "    so_start, so_end = unpaired_so[0]\n",
    "    plot_event(five_participants_raw, (so_start, so_end), (0, 0), 'Unpaired Slow Oscillation')\n",
    "else:\n",
    "    print(\"No unpaired slow oscillations found.\")\n",
    "\n",
    "# unpaired spindle visualization\n",
    "if unpaired_sp:\n",
    "    sp_start, sp_end = unpaired_sp[0]\n",
    "    plot_event(five_participants_raw, (0, 0), (sp_start, sp_end), 'Unpaired Spindle')\n",
    "else:\n",
    "    print(\"No unpaired spindles found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
