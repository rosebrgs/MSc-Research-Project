{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c00b3c25-4ba0-45b7-8491-528229c2ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvista\n",
    "import ipywidgets\n",
    "import ipyevents\n",
    "import pyvistaqt\n",
    "import yasa\n",
    "import os\n",
    "import random\n",
    "\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import stft\n",
    "\n",
    "import pywt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5beb49ef-a6ff-4ab0-ade8-df708e511e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356d696b-c121-42b9-a546-bf8b754ae812",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "139ca8c6-db81-46a7-ad53-db30194f04fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:\\EEG DATA\\combined_sets\\five_participants_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 1470000 ... 40455122 =   2940.000 ... 80910.244 secs\n",
      "Ready.\n",
      "Reading 0 ... 38985122  =      0.000 ... 77970.244 secs...\n"
     ]
    }
   ],
   "source": [
    "# file paths\n",
    "five_participants_file = r\"C:\\EEG DATA\\combined_sets\\five_participants_raw.fif\"\n",
    "\n",
    "# load raw files\n",
    "five_participants_raw = mne.io.read_raw_fif(five_participants_file, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df652b2-2504-4e1d-ab39-e2962d5c3e38",
   "metadata": {},
   "source": [
    "## Spindle detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "961b5a90-7636-4679-8b98-6d968587f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_spindles_times(eeg_raw, do_filter=True, do_downsample=False, downsample_rate=100):\n",
    "    \n",
    "    # 1. Filter between 12 and 16 Hz\n",
    "    \n",
    "    data = eeg_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=12, h_freq=16)\n",
    "    \n",
    "    # 2. Downsample at 100 Hz (100 samples per second)\n",
    "\n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "    \n",
    "    sfreq = data.info['sfreq']  \n",
    "    channel_data = data.get_data()[0]\n",
    "    # extract the filtered data\n",
    "    \n",
    "    \n",
    "    # 3: Calculate amplitude by applying Hilbert transformation\n",
    "\n",
    "    hilbert_signal = hilbert(channel_data)\n",
    "    # apply hilbert transformation to bandpassed data\n",
    "    # gives analytic signal with amplitude and phase information\n",
    "    envelope = np.abs(hilbert_signal)\n",
    "    # take the absolute part of the hilbert signal\n",
    "    # also the instantaneous power of the signal\n",
    "    # gives the envelope: amplitude modulation\n",
    "    # how strength of oscillations change over time\n",
    "    # size of sliding window\n",
    "    \n",
    "    # 4: Perform smoothing with a sliding window of 0.2 seconds\n",
    "    # this removes high-frequency noise\n",
    "    \n",
    "    sliding_window = int(0.2 * sfreq)\n",
    "    smoothed_envelope = np.convolve(envelope, np.ones(sliding_window) / sliding_window, mode='same')\n",
    "    # convolving envelope with a uniform filter over the sliding window\n",
    "    # convolution takes rolling average of 20 samples at a time\n",
    "    # smooth the signal with the average of values in the window\n",
    "    # in the smoothed envelope, can detect regions with higher amplitude \n",
    "    # which is when a spindle event occurs\n",
    "    # np.ones: creates a filter kernel\n",
    "    # have a filter where the sum of all elements equals 1\n",
    "    # this filter is replaced by the average of the 20 surrounding samples\n",
    "    # convolution between envelope and averaging filter\n",
    "    # mode = 'same': so that output of convolution has same length as original envelope\n",
    "\n",
    "    # 5. Define spindle detection threshold\n",
    "\n",
    "    threshold = np.percentile(smoothed_envelope, 75)\n",
    "    spindle_threshold = smoothed_envelope > threshold\n",
    "    #threshold = np.mean(smoothed_envelope) + 1.5 * np.std(smoothed_envelope)\n",
    "    #spindle_threshold = smoothed_envelope > threshold\n",
    "    # threshold is 75th percentile of the smoothed envelope\n",
    "    # will look at the duration later\n",
    "    \n",
    "    # 6. Detect spindles and define peaks and troughs for visualisation\n",
    "    \n",
    "    spindles = []\n",
    "    # initialize list with spindles\n",
    "    above_threshold = np.where(spindle_threshold)[0]\n",
    "    # returns indices where signal above the threshold\n",
    "    stacked_spindles = []\n",
    "    # initialize list for stacking the spindles for the visualisation\n",
    "    # contains aligned spindles at peak\n",
    "    \n",
    "    if len(above_threshold) > 0:\n",
    "        # checking it's not empty\n",
    "        start_idx = above_threshold[0]\n",
    "        # would be the start of a potential spindle\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] > above_threshold[i - 1] + 1:  \n",
    "                # if above threshold[1] > above_threshold[0] + 1\n",
    "                # because all indices should be separated by 1\n",
    "                # so here detects gaps\n",
    "                # so starting from the second index\n",
    "                # and comparing each index to the one before\n",
    "                end_idx = above_threshold[i - 1]\n",
    "                # so if above condition is true, this is the end of the spindle\n",
    "                duration = (end_idx - start_idx) / sfreq\n",
    "                if 0.5 <= duration <= 3:\n",
    "                    # only keep spindles lasting 0.5 to 3 seconds\n",
    "                    segment = channel_data[start_idx:end_idx]\n",
    "                    # extract EEG segment corresponding to detected spindle\n",
    "                    peak_idx = start_idx + np.argmax(segment) \n",
    "                    # extract the peak of the spindle\n",
    "                    # this will be useful for later\n",
    "                    spindles.append((start_idx / sfreq, end_idx / sfreq))\n",
    "                    # all the spindles are stored in spindles\n",
    "                    \n",
    "                    # Aligning spindles at peak for visualization\n",
    "                    before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "                    # still in the for loop, so this is the peak index of individual peak\n",
    "                    after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "                    # extracting 1.5 seconds before and after peak\n",
    "                    # max and min are used for out of bounds situations at the start and end of EEG data\n",
    "                    aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "                    stacked_spindles.append(aligned_segment)\n",
    "                    # the aligned segment is saved in stacked spindles\n",
    "                \n",
    "                start_idx = above_threshold[i]\n",
    "                # update the start index for the for loop\n",
    "\n",
    "        # then need to process the final spindle\n",
    "        end_idx = above_threshold[-1]\n",
    "        duration = (end_idx - start_idx) / sfreq\n",
    "        if 0.5 <= duration <= 3:\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            peak_idx = start_idx + np.argmax(segment)\n",
    "            spindles.append((start_idx / sfreq, end_idx / sfreq))\n",
    "\n",
    "            before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "            after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "            aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "            stacked_spindles.append(aligned_segment)\n",
    "    \n",
    "    return spindles\n",
    "    \n",
    "\n",
    "def detect_spindles_peaks(eeg_raw, do_filter=True, do_downsample=False, downsample_rate=100):\n",
    "    \n",
    "    # 1. Filter between 12 and 16 Hz\n",
    "    \n",
    "    data = eeg_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=12, h_freq=16)\n",
    "    \n",
    "    # 2. Downsample at 100 Hz (100 samples per second)\n",
    "    \n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "        \n",
    "    sfreq = data.info['sfreq']  \n",
    "    # update to new sampling frequency\n",
    "    # because used later in the code\n",
    "    channel_data = data.get_data()[0]\n",
    "    # extract the filtered data\n",
    "    \n",
    "    # 3: Calculate amplitude by applying Hilbert transformation\n",
    "\n",
    "    hilbert_signal = hilbert(channel_data)\n",
    "    # apply hilbert transformation to bandpassed data\n",
    "    # gives analytic signal with amplitude and phase information\n",
    "    envelope = np.abs(hilbert_signal)\n",
    "    # take the absolute part of the hilbert signal\n",
    "    # also the instantaneous power of the signal\n",
    "    # gives the envelope: amplitude modulation\n",
    "    # how strength of oscillations change over time\n",
    "    # size of sliding window\n",
    "    \n",
    "    # 4: Perform smoothing with a sliding window of 0.2 seconds\n",
    "    # this removes high-frequency noise\n",
    "    \n",
    "    sliding_window = int(0.2 * sfreq)\n",
    "    smoothed_envelope = np.convolve(envelope, np.ones(sliding_window) / sliding_window, mode='same')\n",
    "    # convolving envelope with a uniform filter over the sliding window\n",
    "    # convolution takes rolling average of 20 samples at a time\n",
    "    # smooth the signal with the average of values in the window\n",
    "    # in the smoothed envelope, can detect regions with higher amplitude \n",
    "    # which is when a spindle event occurs\n",
    "    # np.ones: creates a filter kernel\n",
    "    # have a filter where the sum of all elements equals 1\n",
    "    # this filter is replaced by the average of the 20 surrounding samples\n",
    "    # convolution between envelope and averaging filter\n",
    "    # mode = 'same': so that output of convolution has same length as original envelope\n",
    "\n",
    "    # 5. Define spindle detection threshold\n",
    "\n",
    "    threshold = np.percentile(smoothed_envelope, 75)\n",
    "    spindle_threshold = smoothed_envelope > threshold\n",
    "    # 75th percentile as criteria\n",
    "\n",
    "    #threshold = np.mean(smoothed_envelope) + 1.5 * np.std(smoothed_envelope)\n",
    "    #spindle_threshold = smoothed_envelope > threshold\n",
    "    \n",
    "    # 6. Detect spindles and define peaks and troughs for visualisation\n",
    "    \n",
    "    spindles = []\n",
    "    # initialize list with spindles\n",
    "    above_threshold = np.where(spindle_threshold)[0]\n",
    "    # returns indices where signal above the threshold\n",
    "    stacked_spindles = []\n",
    "    # initialize list for stacking the spindles for the visualisation\n",
    "    # contains aligned spindles at peak\n",
    "    \n",
    "    if len(above_threshold) > 0:\n",
    "        # checking it's not empty\n",
    "        start_idx = above_threshold[0]\n",
    "        # would be the start of a potential spindle\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] > above_threshold[i - 1] + 1:  \n",
    "                # if above threshold[1] > above_threshold[0] + 1\n",
    "                # because all indices should be separated by 1\n",
    "                # so here detects gaps\n",
    "                end_idx = above_threshold[i - 1]\n",
    "                # so if above condition is true, this is the end of the spindle\n",
    "                duration = (end_idx - start_idx) / sfreq\n",
    "                if 0.5 <= duration <= 3:\n",
    "                    # only keep spindles lasting 0.5 to 3 seconds\n",
    "                    segment = channel_data[start_idx:end_idx]\n",
    "                    # extract EEG segment corresponding to detected spindle\n",
    "                    peak_idx = start_idx + np.argmax(segment) \n",
    "                    # extract the peak of the spindle\n",
    "                    # this will be useful for later\n",
    "                    #spindles.append(f\"Spindle detected from {start_idx / sfreq:.2f}s to {end_idx / sfreq:.2f}s, peak at {peak_idx / sfreq:.2f}s\")\n",
    "                    spindles.append((peak_idx / sfreq))\n",
    "                    # all the spindles are stored in spindles\n",
    "                    \n",
    "                    # Aligning spindles at peak for visualization\n",
    "                    before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "                    # still in the for loop, so this is the peak index of individual peak\n",
    "                    after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "                    # extracting 1.5 seconds before and after peak\n",
    "                    # max and min are used for out of bounds situations at the start and end of EEG data\n",
    "                    aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "                    stacked_spindles.append(aligned_segment)\n",
    "                    # the aligned segment is saved in stacked spindles\n",
    "                \n",
    "                start_idx = above_threshold[i]\n",
    "                # update the start index for the for loop\n",
    "\n",
    "        # then need to process the final spindle\n",
    "        end_idx = above_threshold[-1]\n",
    "        duration = (end_idx - start_idx) / sfreq\n",
    "        if 0.5 <= duration <= 3:\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            peak_idx = start_idx + np.argmax(segment)\n",
    "            spindles.append((peak_idx / sfreq))\n",
    "\n",
    "            before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "            after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "            aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "            stacked_spindles.append(aligned_segment)\n",
    "\n",
    "    \n",
    "    return spindles\n",
    "\n",
    "def detect_spindles_peaks_average(eeg_raw, do_filter=True, do_downsample=False, downsample_rate=100):\n",
    "    \n",
    "    # 1. Filter between 12 and 16 Hz\n",
    "    \n",
    "    data = eeg_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=12, h_freq=16)\n",
    "    \n",
    "    # 2. Downsample at 100 Hz (100 samples per second)\n",
    "    \n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "        \n",
    "    sfreq = data.info['sfreq']  \n",
    "    # update to new sampling frequency\n",
    "    # because used later in the code\n",
    "    channel_data = data.get_data()[0]\n",
    "    # extract the filtered data\n",
    "    \n",
    "    # 3: Calculate amplitude by applying Hilbert transformation\n",
    "\n",
    "    hilbert_signal = hilbert(channel_data)\n",
    "    # apply hilbert transformation to bandpassed data\n",
    "    # gives analytic signal with amplitude and phase information\n",
    "    envelope = np.abs(hilbert_signal)\n",
    "    # take the absolute part of the hilbert signal\n",
    "    # also the instantaneous power of the signal\n",
    "    # gives the envelope: amplitude modulation\n",
    "    # how strength of oscillations change over time\n",
    "    # size of sliding window\n",
    "    \n",
    "    # 4: Perform smoothing with a sliding window of 0.2 seconds\n",
    "    # this removes high-frequency noise\n",
    "    \n",
    "    sliding_window = int(0.2 * sfreq)\n",
    "    smoothed_envelope = np.convolve(envelope, np.ones(sliding_window) / sliding_window, mode='same')\n",
    "    # convolving envelope with a uniform filter over the sliding window\n",
    "    # convolution takes rolling average of 20 samples at a time\n",
    "    # smooth the signal with the average of values in the window\n",
    "    # in the smoothed envelope, can detect regions with higher amplitude \n",
    "    # which is when a spindle event occurs\n",
    "    # np.ones: creates a filter kernel\n",
    "    # have a filter where the sum of all elements equals 1\n",
    "    # this filter is replaced by the average of the 20 surrounding samples\n",
    "    # convolution between envelope and averaging filter\n",
    "    # mode = 'same': so that output of convolution has same length as original envelope\n",
    "\n",
    "    # 5. Define spindle detection threshold\n",
    "\n",
    "    threshold = np.percentile(smoothed_envelope, 75)\n",
    "    spindle_threshold = smoothed_envelope > threshold\n",
    "    # 75th percentile as criteria\n",
    "\n",
    "    #threshold = np.mean(smoothed_envelope) + 1.5 * np.std(smoothed_envelope)\n",
    "    #spindle_threshold = smoothed_envelope > threshold\n",
    "    \n",
    "    # 6. Detect spindles and define peaks and troughs for visualisation\n",
    "    \n",
    "    spindles = []\n",
    "    # initialize list with spindles\n",
    "    above_threshold = np.where(spindle_threshold)[0]\n",
    "    # returns indices where signal above the threshold\n",
    "    stacked_spindles = []\n",
    "    # initialize list for stacking the spindles for the visualisation\n",
    "    # contains aligned spindles at peak\n",
    "    \n",
    "    if len(above_threshold) > 0:\n",
    "        # checking it's not empty\n",
    "        start_idx = above_threshold[0]\n",
    "        # would be the start of a potential spindle\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] > above_threshold[i - 1] + 1:  \n",
    "                # if above threshold[1] > above_threshold[0] + 1\n",
    "                # because all indices should be separated by 1\n",
    "                # so here detects gaps\n",
    "                end_idx = above_threshold[i - 1]\n",
    "                # so if above condition is true, this is the end of the spindle\n",
    "                duration = (end_idx - start_idx) / sfreq\n",
    "                if 0.5 <= duration <= 3:\n",
    "                    # only keep spindles lasting 0.5 to 3 seconds\n",
    "                    segment = channel_data[start_idx:end_idx]\n",
    "                    # extract EEG segment corresponding to detected spindle\n",
    "                    peak_idx = start_idx + np.argmax(segment) \n",
    "                    # extract the peak of the spindle\n",
    "                    # this will be useful for later\n",
    "                    #spindles.append(f\"Spindle detected from {start_idx / sfreq:.2f}s to {end_idx / sfreq:.2f}s, peak at {peak_idx / sfreq:.2f}s\")\n",
    "                    spindles.append((peak_idx / sfreq))\n",
    "                    # all the spindles are stored in spindles\n",
    "                    \n",
    "                    # Aligning spindles at peak for visualization\n",
    "                    before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "                    # still in the for loop, so this is the peak index of individual peak\n",
    "                    after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "                    # extracting 1.5 seconds before and after peak\n",
    "                    # max and min are used for out of bounds situations at the start and end of EEG data\n",
    "                    aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "                    stacked_spindles.append(aligned_segment)\n",
    "                    # the aligned segment is saved in stacked spindles\n",
    "                \n",
    "                start_idx = above_threshold[i]\n",
    "                # update the start index for the for loop\n",
    "\n",
    "        # then need to process the final spindle\n",
    "        end_idx = above_threshold[-1]\n",
    "        duration = (end_idx - start_idx) / sfreq\n",
    "        if 0.5 <= duration <= 3:\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            peak_idx = start_idx + np.argmax(segment)\n",
    "            spindles.append((peak_idx / sfreq))\n",
    "\n",
    "            before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "            after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "            aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "            stacked_spindles.append(aligned_segment)\n",
    "\n",
    "    \n",
    "    return spindles, stacked_spindles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56cdca1b-148a-4610-9067-4c56b632519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_spindles(stacked_spindles, plot_name):\n",
    "    max_len = max(len(seg) for seg in stacked_spindles)\n",
    "    padded_stacked_spindles = [np.pad(seg, (0, max_len - len(seg)), constant_values=np.nan) for seg in stacked_spindles]\n",
    "    avg_spindle_waveform = np.nanmean(padded_stacked_spindles, axis=0)\n",
    "    time_axis = np.linspace(-1.5, 1.5, len(avg_spindle_waveform))\n",
    "    # already stacking 1.5 around each side so keep this\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(time_axis, avg_spindle_waveform, color=\"blue\", label=\"Mean Spindle\")\n",
    "    plt.axvline(0, color=\"red\", linestyle=\"--\", label=\"Peak (0s)\")\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude (µV)')\n",
    "    plt.title(plot_name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be09852-473f-461d-b9cc-523182a9d3e8",
   "metadata": {},
   "source": [
    "## Slow oscillation detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20980f99-324d-4663-aaf8-2f864a345fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_slow_oscillations_times(combined_raw, do_filter=True, do_downsample=False, downsample_rate=100):\n",
    "\n",
    "    # according to methods from Klinzing et al.(2016)\n",
    "\n",
    "    data = combined_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=0.16, h_freq=1.25)\n",
    "\n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "        \n",
    "    sfreq = data.info['sfreq']\n",
    "    channel_data = data.get_data()[0]\n",
    "    \n",
    "    # 3. find all positive-to-negative zero-crossings\n",
    "    \n",
    "    # zero_crossings = np.where( S!= 0)[0]\n",
    "    # can also save this somewhere for further detection of spindles\n",
    "    \n",
    "    S = np.diff(np.sign(channel_data))\n",
    "    # np.sign returns an array with 1 (positive), 0 (zero), -1 (negative)\n",
    "    # np.diff calculates the difference between consecutive elements in an array\n",
    "    # positive value: transition from negative to positive\n",
    "    # negative value: transition from positive to negative\n",
    "    # when it's a zero, means that value stayed the same\n",
    "    zero_crossings = np.where(S < 0)[0]\n",
    "    # -2 is when a positive-to-negative zero-crossing occurs\n",
    "    # goes from 1 to -1 \n",
    "    # -1 - 1 = -2\n",
    "    # [0] extracts the actual array\n",
    "    # extracts the indices of interest from current_data (not S)\n",
    "    #signs = np.sign(current_data)\n",
    "    #pos_to_neg = np.where((signs[:-1] > 0) & (signs[1:] < 0))[0]\n",
    "    # detect +1 to -1\n",
    "    #neg_to_pos = np.where((signs[:-1] <  0) & (signs[1:] > 0))[0]\n",
    "    # detect -1 to +1\n",
    "\n",
    "    # 4. Detect peak potentials in each pair\n",
    "    slow_oscillations = []\n",
    "    negative_peaks = []\n",
    "    positive_peaks = []\n",
    "    peak_to_peak_amplitudes = []\n",
    "    candidate_indices = []\n",
    "\n",
    "    # for loop for each pair\n",
    "    # to collect all the negative and positive peaks\n",
    "    # to further apply criteria\n",
    "    count = 0\n",
    "    for i in range(0, len(zero_crossings)-1, 1):\n",
    "        # loop through all the zero_crossings\n",
    "        # step of 1 (with step of 2, miss some zero_crossings)\n",
    "        start_idx = zero_crossings[i] + 1\n",
    "        # assigns index of zero-crossing (representing start of potential SO)\n",
    "        # to start_idx\n",
    "        end_idx = zero_crossings[i + 1] + 1\n",
    "        # assigns index of next zero-crossing (representing end of potential SO)\n",
    "        # to end_idx\n",
    "\n",
    "        # find the negative to positive crossing in between\n",
    "        #mid_crossings = neg_to_pos[(neg_to_pos > start_idx) & (neg_to_pos < end_idx)]\n",
    "\n",
    "        #if len(mid_crossings) != 1:\n",
    "            #continue\n",
    "\n",
    "        #mid_idx = mid_crossings [0]\n",
    "\n",
    "        #duration = (end_idx - start_idx) / sfreq\n",
    "        #if not (0.8 <= duration <= 2.0):\n",
    "  \n",
    "        \n",
    "        segment_length = (end_idx - start_idx) / sfreq\n",
    "\n",
    "        # need to add +1 because of way extract segment later\n",
    "\n",
    "        # have identified index for the pair\n",
    "        \n",
    "        # extract data segment between crossings\n",
    "        \n",
    "        # find peaks\n",
    "        if 0.8 <= segment_length <= 2.0:\n",
    "            count += 1\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            positive_peak = np.max(segment)\n",
    "            negative_peak = np.min(segment)\n",
    "            peak_to_peak_amplitude = positive_peak - negative_peak\n",
    "\n",
    "        # store values\n",
    "            candidate_indices.append((start_idx, end_idx))\n",
    "            positive_peaks.append(positive_peak)\n",
    "            negative_peaks.append(negative_peak)\n",
    "            peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "\n",
    "    # calculate mean values for comparison\n",
    "    #mean_negative_peak = np.mean(negative_peaks)\n",
    "    # mean_negative_peak = np.mean(negative_peaks) if negative_peaks else 0\n",
    "    #mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes)\n",
    "    # mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes) if peak_to_peak_amplitudes else 0\n",
    "\n",
    "    negative_peak_threshold = np.percentile(negative_peaks, 25)\n",
    "    # keep lowest negative peaks (under the 25th percentile)\n",
    "    peak_to_peak_amplitude_threshold = np.percentile(peak_to_peak_amplitudes, 75)\n",
    "    # keep largest peak-to-peak amplitude (over 75th percentile)\n",
    "\n",
    "    for (start_idx, end_idx), negative_peak, peak_to_peak_amplitude in zip(candidate_indices, negative_peaks, peak_to_peak_amplitudes):\n",
    "        if peak_to_peak_amplitude >= peak_to_peak_amplitude_threshold and negative_peak <= negative_peak_threshold:\n",
    "            slow_oscillations.append((start_idx / sfreq, end_idx / sfreq))\n",
    "            \n",
    "    return slow_oscillations\n",
    "    # returns a list of tuples, in which each tuple represents the start and end times of\n",
    "    # a detected slow oscillation\n",
    "\n",
    "def detect_slow_oscillations_peaks(combined_raw, do_filter=True, do_downsample=True, downsample_rate=100):\n",
    "\n",
    "    # according to methods from Klinzing et al.(2016)\n",
    "\n",
    "    data = combined_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=0.16, h_freq=1.25)\n",
    "\n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "        \n",
    "    sfreq = data.info['sfreq']\n",
    "    channel_data = data.get_data()[0]\n",
    "    \n",
    "    # 3. find all positive-to-negative zero-crossings\n",
    "    \n",
    "    # zero_crossings = np.where( S!= 0)[0]\n",
    "    # can also save this somewhere for further detection of spindles\n",
    "    \n",
    "    S = np.diff(np.sign(channel_data))\n",
    "    # np.sign returns an array with 1 (positive), 0 (zero), -1 (negative)\n",
    "    # np.diff calculates the difference between consecutive elements in an array\n",
    "    # positive value: transition from negative to positive\n",
    "    # negative value: transition from positive to negative\n",
    "    # when it's a zero, means that value stayed the same\n",
    "    zero_crossings = np.where(S < 0)[0]\n",
    "    # -2 is when a positive-to-negative zero-crossing occurs\n",
    "    # goes from 1 to -1 \n",
    "    # -1 - 1 = -2\n",
    "    # [0] extracts the actual array\n",
    "    # extracts the indices of interest from current_data (not S)\n",
    "\n",
    "\n",
    "    # 4. Detect peak potentials in each pair\n",
    "    slow_oscillations = []\n",
    "    slow_oscillations_peaks = []\n",
    "    negative_peaks = []\n",
    "    positive_peaks = []\n",
    "    peak_to_peak_amplitudes = []\n",
    "    candidate_indices =  []\n",
    "\n",
    "    # for loop for each pair\n",
    "    # to collect all the negative and positive peaks\n",
    "    # to further apply criteria\n",
    "    count = 0\n",
    "    for i in range(0, len(zero_crossings) - 1, 1):\n",
    "        # loop through all the zero_crossings\n",
    "        # step of 1 (with step of 2, miss some zero_crossings)\n",
    "        start_idx = zero_crossings[i] + 1\n",
    "        # assigns index of zero-crossing (representing start of potential SO)\n",
    "        # to start_idx\n",
    "        end_idx = zero_crossings[i + 1] + 1\n",
    "        # assigns index of next zero-crossing (representing end of potential SO)\n",
    "        # to end_idx\n",
    "        segment_length = (end_idx - start_idx) / sfreq\n",
    "\n",
    "        # need to add +1 because of way extract segment later\n",
    "\n",
    "        # have identified index for the pair\n",
    "        \n",
    "        # extract data segment between crossings\n",
    "        \n",
    "        # find peaks\n",
    "        if 0.8 <= segment_length <= 2.0:\n",
    "            count += 1\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            positive_peak = np.max(segment)\n",
    "            negative_peak = np.min(segment)\n",
    "            peak_to_peak_amplitude = positive_peak - negative_peak\n",
    "\n",
    "        # store values\n",
    "            candidate_indices.append((start_idx, end_idx))\n",
    "            positive_peaks.append(positive_peak)\n",
    "            negative_peaks.append(negative_peak)\n",
    "            peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "\n",
    "    # calculate mean values for comparison\n",
    "    #mean_negative_peak = np.mean(negative_peaks)\n",
    "    # mean_negative_peak = np.mean(negative_peaks) if negative_peaks else 0\n",
    "    #mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes)\n",
    "    # mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes) if peak_to_peak_amplitudes else 0\n",
    "\n",
    "    negative_peak_threshold = np.percentile(negative_peaks, 25)\n",
    "    peak_to_peak_amplitude_threshold = np.percentile(peak_to_peak_amplitudes, 75)\n",
    "\n",
    "    for (start_idx, end_idx), negative_peak, peak_to_peak_amplitude in zip(candidate_indices, negative_peaks, peak_to_peak_amplitudes):\n",
    "        if peak_to_peak_amplitude >= peak_to_peak_amplitude_threshold and negative_peak <= negative_peak_threshold:\n",
    "            slow_oscillations.append((start_idx / sfreq, end_idx / sfreq))\n",
    "            slow_oscillations_peaks.append((negative_peak, positive_peak))\n",
    "\n",
    "            \n",
    "    return slow_oscillations_peaks\n",
    "    # returns a list of tuples, in which each tuple represents the start and end times of\n",
    "    # a detected slow oscillation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757a47d5-6917-4bd5-bf4a-79df47ec9787",
   "metadata": {},
   "source": [
    "## SO-spindle coupling detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6771ec46-4c9b-4edd-9c58-b18915a3057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_slow_oscillations_spindles_coupling_so_times(combined_raw, do_filter=True, do_downsample=True, downsample_rate=100):\n",
    "    slow_oscillations_peaks = detect_slow_oscillations_peaks(combined_raw, do_filter=do_filter, do_downsample=do_downsample, downsample_rate=downsample_rate)\n",
    "    slow_oscillations_times = detect_slow_oscillations_times(combined_raw, do_filter=do_filter, do_downsample=do_downsample, downsample_rate=downsample_rate)\n",
    "    spindles_peaks = detect_spindles_peaks(combined_raw, do_filter=do_filter, do_downsample=do_downsample, downsample_rate=downsample_rate)\n",
    "\n",
    "    coupling_times = []\n",
    "    coupling_times_so = []\n",
    "\n",
    "    # first detect the coupling events\n",
    "    for start_time, end_time in slow_oscillations_times:\n",
    "    #for start_time, end_time (negative_peak, positive_peak) in zip(slow_oscillations_times, slow_oscillations_peaks):\n",
    "        for peak in spindles_peaks:\n",
    "            if start_time < peak < end_time:\n",
    "                # if negative_peak < peak < end_time:\n",
    "                coupling_times.append(peak)\n",
    "                # if the peak of the spindle is between the negative and positive trough\n",
    "                # add it to list of coupling times\n",
    "\n",
    "    # then calculate the slow oscillation length\n",
    "    for start_time, end_time in slow_oscillations_times:\n",
    "        current_start_time = start_time\n",
    "        current_end_time = end_time\n",
    "        for coupling_peak in coupling_times:\n",
    "            if current_start_time < coupling_peak < current_end_time:\n",
    "                coupling_times_so.append((current_start_time, current_end_time))\n",
    "\n",
    "    return coupling_times_so"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4c5cf-c198-4b1d-9bd0-f996c4e84367",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed73c7a-168d-4bc0-a8e4-2e7d151b1137",
   "metadata": {},
   "source": [
    "### at 500 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc6ca0a3-07c9-4dbd-865a-e595423aa0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 12 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 12.00\n",
      "- Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 551 samples (1.102 s)\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 0.16 - 1.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.16\n",
      "- Lower transition bandwidth: 0.16 Hz (-6 dB cutoff frequency: 0.08 Hz)\n",
      "- Upper passband edge: 1.25 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.25 Hz)\n",
      "- Filter length: 10313 samples (20.626 s)\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 0.16 - 1.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.16\n",
      "- Lower transition bandwidth: 0.16 Hz (-6 dB cutoff frequency: 0.08 Hz)\n",
      "- Upper passband edge: 1.25 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.25 Hz)\n",
      "- Filter length: 10313 samples (20.626 s)\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 0.16 - 1.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.16\n",
      "- Lower transition bandwidth: 0.16 Hz (-6 dB cutoff frequency: 0.08 Hz)\n",
      "- Upper passband edge: 1.25 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.25 Hz)\n",
      "- Filter length: 10313 samples (20.626 s)\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 12 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 12.00\n",
      "- Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 551 samples (1.102 s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spindles_times = detect_spindles_times(\n",
    "    five_participants_raw,\n",
    "    do_filter=True,\n",
    "    do_downsample=False\n",
    ")\n",
    "\n",
    "slow_oscillations_times = detect_slow_oscillations_times(\n",
    "    five_participants_raw,\n",
    "    do_filter=True,\n",
    "    do_downsample=False\n",
    ")   \n",
    "\n",
    "so_spindle_coupling_times = detect_slow_oscillations_spindles_coupling_so_times(\n",
    "    five_participants_raw,\n",
    "    do_filter=True,\n",
    "    do_downsample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598a12d4-75e4-4fb2-8658-b71bb8d1143f",
   "metadata": {},
   "source": [
    "## Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f400de2a-5d00-4b0f-a1f2-f6cf3e9e5060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.056913506644918\n",
      "4.394753465180896\n",
      "1.6360087317413035\n"
     ]
    }
   ],
   "source": [
    "# average number of SO, spindle or coupling per min\n",
    "sfreq = five_participants_raw.info['sfreq']\n",
    "\n",
    "# count number of events\n",
    "num_spindles = len(spindles_times)\n",
    "num_slow_oscillations_times = len(slow_oscillations_times)\n",
    "num_so_spindle_coupling = len(so_spindle_coupling_times)\n",
    "\n",
    "# the duration\n",
    "duration_sec = five_participants_raw.times[-1]\n",
    "duration_min = duration_sec / 60\n",
    "\n",
    "# average per min (density)\n",
    "avg_spindles_per_min = num_spindles / duration_min\n",
    "avg_sos_per_min = num_slow_oscillations_times / duration_min\n",
    "avg_couplings_per_min = num_so_spindle_coupling / duration_min\n",
    "\n",
    "# print them\n",
    "print(avg_spindles_per_min)\n",
    "print(avg_sos_per_min)\n",
    "print(avg_couplings_per_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "164ea2eb-e2cb-4ad3-9973-bf3da7ef9bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_to_dataframe(avg_spindles_per_min, avg_sos_per_min, avg_couplings_per_min):\n",
    "    data = {\n",
    "        \"Metric\": [\"Spindle density\", \"SO density\", \"SO-spindle coupling density\"],\n",
    "        \"Value\": [avg_spindles_per_min, avg_sos_per_min, avg_couplings_per_min]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"Value\"] = df[\"Value\"].map(\"{:.2f}\".format)  \n",
    "    # only 2sf\n",
    "    df.set_index(\"Metric\", inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c3a5f4c-059b-4e88-aafb-ad27c40d5b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Value\n",
      "Metric                            \n",
      "Spindle density              10.06\n",
      "SO density                    4.39\n",
      "SO-spindle coupling density   1.64\n"
     ]
    }
   ],
   "source": [
    "# with my data:\n",
    "df_summary = summary_to_dataframe(avg_spindles_per_min, avg_sos_per_min, avg_couplings_per_min)\n",
    "print(df_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c277b42-280d-4236-95f1-2928419b95b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_05ecc th {\n",
       "  font-weight: bold;\n",
       "  text-align: center;\n",
       "}\n",
       "#T_05ecc td {\n",
       "  text-align: center;\n",
       "}\n",
       "#T_05ecc_row0_col0, #T_05ecc_row2_col0 {\n",
       "  background-color: #f9f9f9;\n",
       "}\n",
       "#T_05ecc_row1_col0 {\n",
       "  background-color: #e0e0e0;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_05ecc\">\n",
       "  <caption>Summary of Densities per Minute in NREM 2/3 Sleep</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_05ecc_level0_col0\" class=\"col_heading level0 col0\" >Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Metric</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_05ecc_level0_row0\" class=\"row_heading level0 row0\" >Spindle density</th>\n",
       "      <td id=\"T_05ecc_row0_col0\" class=\"data row0 col0\" >10.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05ecc_level0_row1\" class=\"row_heading level0 row1\" >SO density</th>\n",
       "      <td id=\"T_05ecc_row1_col0\" class=\"data row1 col0\" >4.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_05ecc_level0_row2\" class=\"row_heading level0 row2\" >SO-spindle coupling density</th>\n",
       "      <td id=\"T_05ecc_row2_col0\" class=\"data row2 col0\" >1.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22590993f50>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this creates the dataframe\n",
    "df_summary = summary_to_dataframe(avg_spindles_per_min, avg_sos_per_min, avg_couplings_per_min)\n",
    "\n",
    "# to style the dataframe\n",
    "styled_df = (\n",
    "    df_summary.style\n",
    "    .set_caption(\"Summary of Densities per Minute in NREM 2/3 Sleep\")\n",
    "    .set_table_styles(\n",
    "        [\n",
    "            {\"selector\": \"th\", \"props\": [(\"font-weight\", \"bold\"), (\"text-align\", \"center\")]},\n",
    "            {\"selector\": \"td\", \"props\": [(\"text-align\", \"center\")]},\n",
    "        ]\n",
    "    )\n",
    "    .apply(lambda x: ['background-color: #f9f9f9' if i % 2 == 0 else 'background-color: #e0e0e0' \n",
    "                      for i in range(len(x))], axis=0)\n",
    ")\n",
    "\n",
    "styled_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c7c252-4714-4cc5-be0d-aced80845670",
   "metadata": {},
   "source": [
    "## Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e89fea8-008a-445b-940c-34029060ba6c",
   "metadata": {},
   "source": [
    "### Spindle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69e233c2-17b3-4d97-96d3-4d15b76ef1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 12 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 12.00\n",
      "- Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 551 samples (1.102 s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spindles, stacked = detect_spindles_peaks_average(five_participants_raw)\n",
    "visualize_spindles(stacked, \"Average Spindle for 5 participants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01a7971-c6f9-45d7-a1bc-9910c66a9e6e",
   "metadata": {},
   "source": [
    "### Slow oscillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ff22996-86f8-453f-bc37-f8ce9dbe6e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 0.16 - 1.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.16\n",
      "- Lower transition bandwidth: 0.16 Hz (-6 dB cutoff frequency: 0.08 Hz)\n",
      "- Upper passband edge: 1.25 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.25 Hz)\n",
      "- Filter length: 10313 samples (20.626 s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "slow_oscillations_times = detect_slow_oscillations_times(five_participants_raw, do_filter=True, do_downsample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61958ce1-8a55-4f9b-abbd-3b31d901b260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 0.16 - 1.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.16\n",
      "- Lower transition bandwidth: 0.16 Hz (-6 dB cutoff frequency: 0.08 Hz)\n",
      "- Upper passband edge: 1.25 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.25 Hz)\n",
      "- Filter length: 10313 samples (20.626 s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## if do_downsample=True, need to turn on downsampling in visualisation function\n",
    "\n",
    "visualize_and_stack_slow_oscillations_trough(\n",
    "    five_participants_raw,\n",
    "    slow_oscillations_times,\n",
    "    plot_name=\"Average Slow Oscillation for 5 participants\",\n",
    "    do_downsample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b16bc5e-b089-44ae-9ad1-59ddae75b18e",
   "metadata": {},
   "source": [
    "## Coupling visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bab005-9b9f-4842-bf63-3efb0799b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_so_spindle_coupling(raw, so_spindle_coupling_times, plot_name, do_downsample=False):\n",
    "\n",
    "    # slow oscillation \n",
    "    so_filtered_data = raw.copy().filter(l_freq=0.16, h_freq=1.25)\n",
    "    if do_downsample:\n",
    "        so_filtered_data.resample(100)\n",
    "    so_channel_data = so_filtered_data.get_data(picks=\"Fz\")[0]\n",
    "    sfreq = so_filtered_data.info['sfreq']\n",
    "\n",
    "    # spindle\n",
    "    spindle_filtered_data = raw.copy().filter(l_freq=12, h_freq=16)\n",
    "    if do_downsample:\n",
    "        spindle_filtered_data.resample(100)\n",
    "    spindle_channel_data = spindle_filtered_data.get_data(picks=\"Fz\")[0]\n",
    "\n",
    "\n",
    "    # align everything to the SO trough\n",
    "    aligned_so_segments = []\n",
    "    aligned_spindle_segments = []\n",
    "    for start_time, end_time in so_spindle_coupling_times:\n",
    "        # extract start and end times of SOs\n",
    "        start_idx = int(start_time * sfreq)\n",
    "        end_idx = int(end_time * sfreq)\n",
    "\n",
    "        # trough is argmin\n",
    "        so_segment = so_channel_data[start_idx:end_idx]\n",
    "        trough_idx = np.argmin(so_segment) + start_idx\n",
    "\n",
    "        # keep -1.5 and 1.5 seconds around the trough\n",
    "        before_trough_idx = max(0, trough_idx - int(1.5 * sfreq))\n",
    "        after_trough_idx = min(len(so_channel_data), trough_idx + int(1.5 * sfreq))\n",
    "        aligned_so_segment = so_channel_data[before_trough_idx:after_trough_idx]\n",
    "        aligned_so_segments.append(aligned_so_segment)\n",
    "\n",
    "        # align spindle data to the trough\n",
    "        aligned_spindle_segment = spindle_channel_data[before_trough_idx:after_trough_idx]\n",
    "        aligned_spindle_segments.append(aligned_spindle_segment)\n",
    "\n",
    "\n",
    "    # pad and average the SO (as in previous function)\n",
    "    max_len_so = max(len(seg) for seg in aligned_so_segments)\n",
    "    padded_so_segments = [np.pad(seg, (0, max_len_so - len(seg)), constant_values=np.nan) for seg in aligned_so_segments]\n",
    "    avg_so_waveform = np.nanmean(padded_so_segments, axis=0)\n",
    "    time_axis = np.linspace(-1.5, 1.5, len(avg_so_waveform))\n",
    "\n",
    "    # average spectrogram for spindle and pad\n",
    "    max_len_spindle = max(len(seg) for seg in aligned_spindle_segments)\n",
    "    padded_spindle_segments = [np.pad(seg, (0, max_len_spindle- len(seg)), constant_values=np.nan) for seg in aligned_spindle_segments]\n",
    "\n",
    "    # STFT for spindle\n",
    "    Sxx_list = []\n",
    "    for seg in padded_spindle_segments:\n",
    "        # NaNs are replaced with 0\n",
    "        if np.isnan(seg).any():\n",
    "            seg = np.nan_to_num(seg) \n",
    "        freqs, times, Sxx = signal.stft(seg, fs=sfreq, nperseg=int(sfreq/4), noverlap=int(sfreq/8))\n",
    "        Sxx_list.append(np.abs(Sxx))\n",
    "\n",
    "    # then average all the spectrograms\n",
    "    avg_Sxx = np.nanmean(Sxx_list, axis=0)\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # plot spectrogram\n",
    "    im = ax.pcolormesh(times - 1.5, freqs, avg_Sxx, shading='gouraud', cmap='viridis')\n",
    "    fig.colorbar(im, ax=ax, label='Power/Frequency (dB/Hz)', pad=0.1)\n",
    "\n",
    "    # Overlay SO waveform\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(time_axis, avg_so_waveform, color='red', linewidth=2, label='Average SO')\n",
    "    ax2.set_ylabel('Amplitude (µV)', color='red')\n",
    "    ax2.tick_params(axis='y', labelcolor='red')\n",
    "    ax2.axvline(0, color='white', linestyle='--', label=\"Trough (0s)\")\n",
    "\n",
    "\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Frequency (Hz)')\n",
    "    ax.set_ylim(0, 30)\n",
    "    ax.set_title(plot_name)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_so_no_spindle_coupling(raw, slow_oscillations_times, spindles_peaks, plot_name, do_downsample=False):\n",
    "\n",
    "    # identify non-coupled SOs\n",
    "    # as those that don't respect the definition\n",
    "    non_coupled_so_times = []\n",
    "    for start_time, end_time in slow_oscillations_times:\n",
    "        coupled = False\n",
    "        for peak in spindles_peaks:\n",
    "            if start_time < peak < end_time:\n",
    "                coupled = True\n",
    "                break\n",
    "        if not coupled:\n",
    "            non_coupled_so_times.append((start_time, end_time))\n",
    "\n",
    "    # slow oscillation\n",
    "    so_filtered_data = raw.copy().filter(l_freq=0.16, h_freq=1.25)\n",
    "    if do_downsample:\n",
    "        so_filtered_data.resample(100)\n",
    "    so_channel_data = so_filtered_data.get_data(picks=\"Fz\")[0]\n",
    "    sfreq = so_filtered_data.info['sfreq']\n",
    "\n",
    "    # spindle\n",
    "    spindle_filtered_data = raw.copy().filter(l_freq=12, h_freq=16)\n",
    "    if do_downsample:\n",
    "        spindle_filtered_data.resample(100)\n",
    "    spindle_channel_data = spindle_filtered_data.get_data(picks=\"Fz\")[0]\n",
    "\n",
    "\n",
    "    # align everything to the SO trough\n",
    "    aligned_so_segments = []\n",
    "    aligned_spindle_segments = []\n",
    "    for start_time, end_time in non_coupled_so_times:\n",
    "        start_idx = int(start_time * sfreq)\n",
    "        end_idx = int(end_time * sfreq)\n",
    "\n",
    "        # trough is argming\n",
    "        so_segment = so_channel_data[start_idx:end_idx]\n",
    "        trough_idx = np.argmin(so_segment) + start_idx\n",
    "\n",
    "        # same logic as above\n",
    "        before_trough_idx = max(0, trough_idx - int(1.5 * sfreq))\n",
    "        after_trough_idx = min(len(so_channel_data), trough_idx + int(1.5 * sfreq))\n",
    "        aligned_so_segment = so_channel_data[before_trough_idx:after_trough_idx]\n",
    "        aligned_so_segments.append(aligned_so_segment)\n",
    "\n",
    "        # spindle aligned to SO trough\n",
    "        aligned_spindle_segment = spindle_channel_data[before_trough_idx:after_trough_idx]\n",
    "        aligned_spindle_segments.append(aligned_spindle_segment)\n",
    "\n",
    "\n",
    "    # SO average\n",
    "    max_len_so = max(len(seg) for seg in aligned_so_segments)\n",
    "    padded_so_segments = [np.pad(seg, (0, max_len_so - len(seg)), constant_values=np.nan) for seg in aligned_so_segments]\n",
    "    avg_so_waveform = np.nanmean(padded_so_segments, axis=0)\n",
    "    time_axis = np.linspace(-1.5, 1.5, len(avg_so_waveform))\n",
    "\n",
    "    # spindle spectogram average and pad\n",
    "    max_len_spindle = max(len(seg) for seg in aligned_spindle_segments)\n",
    "    padded_spindle_segments = [np.pad(seg, (0, max_len_spindle- len(seg)), constant_values=np.nan) for seg in aligned_spindle_segments]\n",
    "\n",
    "    # STFT for spindles\n",
    "    Sxx_list = []\n",
    "    for seg in padded_spindle_segments:\n",
    "        # Handle potential NaNs from padding\n",
    "        if np.isnan(seg).any():\n",
    "            seg = np.nan_to_num(seg) # Replace NaNs with 0 for STFT\n",
    "        freqs, times, Sxx = signal.stft(seg, fs=sfreq, nperseg=int(sfreq/4), noverlap=int(sfreq/8))\n",
    "        Sxx_list.append(np.abs(Sxx))\n",
    "\n",
    "    # spectogram average\n",
    "    avg_Sxx = np.nanmean(Sxx_list, axis=0)\n",
    "\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # spectogram plot\n",
    "    im = ax.pcolormesh(times - 1.5, freqs, avg_Sxx, shading='gouraud', cmap='viridis')\n",
    "    fig.colorbar(im, ax=ax, label='Power/Frequency (dB/Hz)', pad=0.1)\n",
    "\n",
    "    # SO waveform\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(time_axis, avg_so_waveform, color='red', linewidth=2, label='Average SO')\n",
    "    ax2.set_ylabel('Amplitude (µV)', color='red')\n",
    "    ax2.tick_params(axis='y', labelcolor='red')\n",
    "    ax2.axvline(0, color='white', linestyle='--', label=\"Trough (0s)\")\n",
    "\n",
    "\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Frequency (Hz)')\n",
    "    ax.set_ylim(0, 30)\n",
    "    ax.set_title(plot_name)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca44de7-c562-4387-9a41-eac117c27639",
   "metadata": {},
   "outputs": [],
   "source": [
    "spindles_peaks = detect_spindles_peaks(\n",
    "    five_participants_raw,\n",
    "    do_filter=True,\n",
    "    do_downsample=False\n",
    ")\n",
    "\n",
    "visualize_so_spindle_coupling(\n",
    "    five_participants_raw,\n",
    "    so_spindle_coupling_times,\n",
    "    \"Average SO-Spindle Coupling for 5 particpants\",\n",
    "    do_downsample=False\n",
    ")\n",
    "\n",
    "visualize_so_no_spindle_coupling(\n",
    "    five_participants_raw,\n",
    "    slow_oscillations_times,\n",
    "    spindles_peaks,\n",
    "    \"Average SO with No Spindle Coupling for 5 participants\",\n",
    "    do_downsample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "85d19c05-3423-49e9-87e3-79eb66e2a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_so_spindle_coupling_9_16_Hz(raw, so_spindle_coupling_times, plot_name, do_downsample=False):\n",
    "\n",
    "    # slow oscillation \n",
    "    so_filtered_data = raw.copy().filter(l_freq=0.16, h_freq=1.25)\n",
    "    if do_downsample:\n",
    "        so_filtered_data.resample(100)\n",
    "    so_channel_data = so_filtered_data.get_data(picks=\"Fz\")[0]\n",
    "    sfreq = so_filtered_data.info['sfreq']\n",
    "\n",
    "    # spindle\n",
    "    spindle_filtered_data = raw.copy().filter(l_freq=9, h_freq=16)\n",
    "    if do_downsample:\n",
    "        spindle_filtered_data.resample(100)\n",
    "    spindle_channel_data = spindle_filtered_data.get_data(picks=\"Fz\")[0]\n",
    "\n",
    "\n",
    "    # align everything to the SO trough\n",
    "    aligned_so_segments = []\n",
    "    aligned_spindle_segments = []\n",
    "    for start_time, end_time in so_spindle_coupling_times:\n",
    "        # extract start and end times of SOs\n",
    "        start_idx = int(start_time * sfreq)\n",
    "        end_idx = int(end_time * sfreq)\n",
    "\n",
    "        # trough is argmin\n",
    "        so_segment = so_channel_data[start_idx:end_idx]\n",
    "        trough_idx = np.argmin(so_segment) + start_idx\n",
    "\n",
    "        # keep -1.5 and 1.5 seconds around the trough\n",
    "        before_trough_idx = max(0, trough_idx - int(1.5 * sfreq))\n",
    "        after_trough_idx = min(len(so_channel_data), trough_idx + int(1.5 * sfreq))\n",
    "        aligned_so_segment = so_channel_data[before_trough_idx:after_trough_idx]\n",
    "        aligned_so_segments.append(aligned_so_segment)\n",
    "\n",
    "        # align spindle data to the trough\n",
    "        aligned_spindle_segment = spindle_channel_data[before_trough_idx:after_trough_idx]\n",
    "        aligned_spindle_segments.append(aligned_spindle_segment)\n",
    "\n",
    "\n",
    "    # pad and average the SO (as in previous function)\n",
    "    max_len_so = max(len(seg) for seg in aligned_so_segments)\n",
    "    padded_so_segments = [np.pad(seg, (0, max_len_so - len(seg)), constant_values=np.nan) for seg in aligned_so_segments]\n",
    "    avg_so_waveform = np.nanmean(padded_so_segments, axis=0)\n",
    "    time_axis = np.linspace(-1.5, 1.5, len(avg_so_waveform))\n",
    "\n",
    "    # average spectrogram for spindle and pad\n",
    "    max_len_spindle = max(len(seg) for seg in aligned_spindle_segments)\n",
    "    padded_spindle_segments = [np.pad(seg, (0, max_len_spindle- len(seg)), constant_values=np.nan) for seg in aligned_spindle_segments]\n",
    "\n",
    "    # STFT for spindle\n",
    "    Sxx_list = []\n",
    "    for seg in padded_spindle_segments:\n",
    "        # NaNs are replaced with 0\n",
    "        if np.isnan(seg).any():\n",
    "            seg = np.nan_to_num(seg) \n",
    "        freqs, times, Sxx = signal.stft(seg, fs=sfreq, nperseg=int(sfreq/4), noverlap=int(sfreq/8))\n",
    "        Sxx_list.append(np.abs(Sxx))\n",
    "\n",
    "    # then average all the spectrograms\n",
    "    avg_Sxx = np.nanmean(Sxx_list, axis=0)\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # plot spectrogram\n",
    "    im = ax.pcolormesh(times - 1.5, freqs, avg_Sxx, shading='gouraud', cmap='viridis')\n",
    "    fig.colorbar(im, ax=ax, label='Power/Frequency (dB/Hz)', pad=0.1)\n",
    "\n",
    "    # Overlay SO waveform\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(time_axis, avg_so_waveform, color='red', linewidth=2, label='Average SO')\n",
    "    ax2.set_ylabel('Amplitude (µV)', color='red')\n",
    "    ax2.tick_params(axis='y', labelcolor='red')\n",
    "    ax2.axvline(0, color='white', linestyle='--', label=\"Trough (0s)\")\n",
    "\n",
    "\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Frequency (Hz)')\n",
    "    ax.set_ylim(0, 30)\n",
    "    ax.set_title(plot_name)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_so_no_spindle_coupling_9_16_Hz(raw, slow_oscillations_times, spindles_peaks, plot_name, do_downsample=False):\n",
    "\n",
    "    # identify non-coupled SOs\n",
    "    # as those that don't respect the definition\n",
    "    non_coupled_so_times = []\n",
    "    for start_time, end_time in slow_oscillations_times:\n",
    "        coupled = False\n",
    "        for peak in spindles_peaks:\n",
    "            if start_time < peak < end_time:\n",
    "                coupled = True\n",
    "                break\n",
    "        if not coupled:\n",
    "            non_coupled_so_times.append((start_time, end_time))\n",
    "\n",
    "    # slow oscillation\n",
    "    so_filtered_data = raw.copy().filter(l_freq=0.16, h_freq=1.25)\n",
    "    if do_downsample:\n",
    "        so_filtered_data.resample(100)\n",
    "    so_channel_data = so_filtered_data.get_data(picks=\"Fz\")[0]\n",
    "    sfreq = so_filtered_data.info['sfreq']\n",
    "\n",
    "    # spindle\n",
    "    spindle_filtered_data = raw.copy().filter(l_freq=9, h_freq=16)\n",
    "    if do_downsample:\n",
    "        spindle_filtered_data.resample(100)\n",
    "    spindle_channel_data = spindle_filtered_data.get_data(picks=\"Fz\")[0]\n",
    "\n",
    "\n",
    "    # align everything to the SO trough\n",
    "    aligned_so_segments = []\n",
    "    aligned_spindle_segments = []\n",
    "    for start_time, end_time in non_coupled_so_times:\n",
    "        start_idx = int(start_time * sfreq)\n",
    "        end_idx = int(end_time * sfreq)\n",
    "\n",
    "        # trough is argming\n",
    "        so_segment = so_channel_data[start_idx:end_idx]\n",
    "        trough_idx = np.argmin(so_segment) + start_idx\n",
    "\n",
    "        # same logic as above\n",
    "        before_trough_idx = max(0, trough_idx - int(1.5 * sfreq))\n",
    "        after_trough_idx = min(len(so_channel_data), trough_idx + int(1.5 * sfreq))\n",
    "        aligned_so_segment = so_channel_data[before_trough_idx:after_trough_idx]\n",
    "        aligned_so_segments.append(aligned_so_segment)\n",
    "\n",
    "        # spindle aligned to SO trough\n",
    "        aligned_spindle_segment = spindle_channel_data[before_trough_idx:after_trough_idx]\n",
    "        aligned_spindle_segments.append(aligned_spindle_segment)\n",
    "\n",
    "\n",
    "    # SO average\n",
    "    max_len_so = max(len(seg) for seg in aligned_so_segments)\n",
    "    padded_so_segments = [np.pad(seg, (0, max_len_so - len(seg)), constant_values=np.nan) for seg in aligned_so_segments]\n",
    "    avg_so_waveform = np.nanmean(padded_so_segments, axis=0)\n",
    "    time_axis = np.linspace(-1.5, 1.5, len(avg_so_waveform))\n",
    "\n",
    "    # spindle spectogram average and pad\n",
    "    max_len_spindle = max(len(seg) for seg in aligned_spindle_segments)\n",
    "    padded_spindle_segments = [np.pad(seg, (0, max_len_spindle- len(seg)), constant_values=np.nan) for seg in aligned_spindle_segments]\n",
    "\n",
    "    # STFT for spindles\n",
    "    Sxx_list = []\n",
    "    for seg in padded_spindle_segments:\n",
    "        # Handle potential NaNs from padding\n",
    "        if np.isnan(seg).any():\n",
    "            seg = np.nan_to_num(seg) # Replace NaNs with 0 for STFT\n",
    "        freqs, times, Sxx = signal.stft(seg, fs=sfreq, nperseg=int(sfreq/4), noverlap=int(sfreq/8))\n",
    "        Sxx_list.append(np.abs(Sxx))\n",
    "\n",
    "    # spectogram average\n",
    "    avg_Sxx = np.nanmean(Sxx_list, axis=0)\n",
    "\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # spectogram plot\n",
    "    im = ax.pcolormesh(times - 1.5, freqs, avg_Sxx, shading='gouraud', cmap='viridis')\n",
    "    fig.colorbar(im, ax=ax, label='Power/Frequency (dB/Hz)', pad=0.1)\n",
    "\n",
    "    # SO waveform\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(time_axis, avg_so_waveform, color='red', linewidth=2, label='Average SO')\n",
    "    ax2.set_ylabel('Amplitude (µV)', color='red')\n",
    "    ax2.tick_params(axis='y', labelcolor='red')\n",
    "    ax2.axvline(0, color='white', linestyle='--', label=\"Trough (0s)\")\n",
    "\n",
    "\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Frequency (Hz)')\n",
    "    ax.set_ylim(0, 30)\n",
    "    ax.set_title(plot_name)\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd5180a1-305f-42ff-a6ef-76a528193fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 12 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 12.00\n",
      "- Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 551 samples (1.102 s)\n",
      "\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 0.16 - 1.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.16\n",
      "- Lower transition bandwidth: 0.16 Hz (-6 dB cutoff frequency: 0.08 Hz)\n",
      "- Upper passband edge: 1.25 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.25 Hz)\n",
      "- Filter length: 10313 samples (20.626 s)\n",
      "\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 9 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 9.00\n",
      "- Lower transition bandwidth: 2.25 Hz (-6 dB cutoff frequency: 7.88 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 735 samples (1.470 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roseb\\AppData\\Local\\Temp\\ipykernel_12200\\2192724922.py:81: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  ax.legend()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 0.16 - 1.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.16\n",
      "- Lower transition bandwidth: 0.16 Hz (-6 dB cutoff frequency: 0.08 Hz)\n",
      "- Upper passband edge: 1.25 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.25 Hz)\n",
      "- Filter length: 10313 samples (20.626 s)\n",
      "\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 9 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 9.00\n",
      "- Lower transition bandwidth: 2.25 Hz (-6 dB cutoff frequency: 7.88 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 735 samples (1.470 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roseb\\AppData\\Local\\Temp\\ipykernel_12200\\2192724922.py:176: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  ax.legend()\n"
     ]
    }
   ],
   "source": [
    "spindles_peaks = detect_spindles_peaks(\n",
    "    five_participants_raw,\n",
    "    do_filter=True,\n",
    "    do_downsample=False\n",
    ")\n",
    "\n",
    "visualize_so_spindle_coupling_9_16_Hz(\n",
    "    five_participants_raw,\n",
    "    so_spindle_coupling_times,\n",
    "    \"Average SO-Spindle Coupling for 5 particpants\",\n",
    "    do_downsample=False\n",
    ")\n",
    "\n",
    "visualize_so_no_spindle_coupling_9_16_Hz(\n",
    "    five_participants_raw,\n",
    "    slow_oscillations_times,\n",
    "    spindles_peaks,\n",
    "    \"Average SO with No Spindle Coupling for 5 participants\",\n",
    "    do_downsample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f80798-3bd8-495a-9f71-6f6e414893e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
