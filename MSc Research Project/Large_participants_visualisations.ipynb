{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c00b3c25-4ba0-45b7-8491-528229c2ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvista\n",
    "import ipywidgets\n",
    "import ipyevents\n",
    "import pyvistaqt\n",
    "import yasa\n",
    "import os\n",
    "import random\n",
    "\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import stft\n",
    "from scipy.interpolate import interpn\n",
    "\n",
    "import pywt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5beb49ef-a6ff-4ab0-ade8-df708e511e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356d696b-c121-42b9-a546-bf8b754ae812",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "139ca8c6-db81-46a7-ad53-db30194f04fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:\\eeg\\combined_sets\\large_participants_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 855000 ... 406561351 =   1710.000 ... 813122.702 secs\n",
      "Ready.\n",
      "Reading 0 ... 405706351  =      0.000 ... 811412.702 secs...\n"
     ]
    }
   ],
   "source": [
    "# file paths\n",
    "large_participants_file = r\"C:\\eeg\\combined_sets\\large_participants_raw.fif\"\n",
    "\n",
    "# load raw files\n",
    "large_participants_raw = mne.io.read_raw_fif(large_participants_file, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df652b2-2504-4e1d-ab39-e2962d5c3e38",
   "metadata": {},
   "source": [
    "## Spindle detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "961b5a90-7636-4679-8b98-6d968587f718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_spindles_times(eeg_raw, do_filter=True, do_downsample=False, downsample_rate=100):\n",
    "    \n",
    "    # 1. Filter between 12 and 16 Hz\n",
    "    \n",
    "    data = eeg_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=12, h_freq=16)\n",
    "    \n",
    "    # 2. Downsample at 100 Hz (100 samples per second)\n",
    "\n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "    \n",
    "    sfreq = data.info['sfreq']  \n",
    "    channel_data = data.get_data()[0]\n",
    "    # extract the filtered data\n",
    "    \n",
    "    \n",
    "    # 3: Calculate amplitude by applying Hilbert transformation\n",
    "\n",
    "    hilbert_signal = hilbert(channel_data)\n",
    "    # apply hilbert transformation to bandpassed data\n",
    "    # gives analytic signal with amplitude and phase information\n",
    "    envelope = np.abs(hilbert_signal)\n",
    "    # take the absolute part of the hilbert signal\n",
    "    # also the instantaneous power of the signal\n",
    "    # gives the envelope: amplitude modulation\n",
    "    # how strength of oscillations change over time\n",
    "    # size of sliding window\n",
    "    \n",
    "    # 4: Perform smoothing with a sliding window of 0.2 seconds\n",
    "    # this removes high-frequency noise\n",
    "    \n",
    "    sliding_window = int(0.2 * sfreq)\n",
    "    smoothed_envelope = np.convolve(envelope, np.ones(sliding_window) / sliding_window, mode='same')\n",
    "    # convolving envelope with a uniform filter over the sliding window\n",
    "    # convolution takes rolling average of 20 samples at a time\n",
    "    # smooth the signal with the average of values in the window\n",
    "    # in the smoothed envelope, can detect regions with higher amplitude \n",
    "    # which is when a spindle event occurs\n",
    "    # np.ones: creates a filter kernel\n",
    "    # have a filter where the sum of all elements equals 1\n",
    "    # this filter is replaced by the average of the 20 surrounding samples\n",
    "    # convolution between envelope and averaging filter\n",
    "    # mode = 'same': so that output of convolution has same length as original envelope\n",
    "\n",
    "    # 5. Define spindle detection threshold\n",
    "\n",
    "    threshold = np.percentile(smoothed_envelope, 75)\n",
    "    spindle_threshold = smoothed_envelope > threshold\n",
    "    #threshold = np.mean(smoothed_envelope) + 1.5 * np.std(smoothed_envelope)\n",
    "    #spindle_threshold = smoothed_envelope > threshold\n",
    "    # threshold is 75th percentile of the smoothed envelope\n",
    "    # will look at the duration later\n",
    "    \n",
    "    # 6. Detect spindles and define peaks and troughs for visualisation\n",
    "    \n",
    "    spindles = []\n",
    "    # initialize list with spindles\n",
    "    above_threshold = np.where(spindle_threshold)[0]\n",
    "    # returns indices where signal above the threshold\n",
    "    stacked_spindles = []\n",
    "    # initialize list for stacking the spindles for the visualisation\n",
    "    # contains aligned spindles at peak\n",
    "    \n",
    "    if len(above_threshold) > 0:\n",
    "        # checking it's not empty\n",
    "        start_idx = above_threshold[0]\n",
    "        # would be the start of a potential spindle\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] > above_threshold[i - 1] + 1:  \n",
    "                # if above threshold[1] > above_threshold[0] + 1\n",
    "                # because all indices should be separated by 1\n",
    "                # so here detects gaps\n",
    "                # so starting from the second index\n",
    "                # and comparing each index to the one before\n",
    "                end_idx = above_threshold[i - 1]\n",
    "                # so if above condition is true, this is the end of the spindle\n",
    "                duration = (end_idx - start_idx) / sfreq\n",
    "                if 0.5 <= duration <= 3:\n",
    "                    # only keep spindles lasting 0.5 to 3 seconds\n",
    "                    segment = channel_data[start_idx:end_idx]\n",
    "                    # extract EEG segment corresponding to detected spindle\n",
    "                    peak_idx = start_idx + np.argmax(segment) \n",
    "                    # extract the peak of the spindle\n",
    "                    # this will be useful for later\n",
    "                    spindles.append((start_idx / sfreq, end_idx / sfreq))\n",
    "                    # all the spindles are stored in spindles\n",
    "                    \n",
    "                    # Aligning spindles at peak for visualization\n",
    "                    before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "                    # still in the for loop, so this is the peak index of individual peak\n",
    "                    after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "                    # extracting 1.5 seconds before and after peak\n",
    "                    # max and min are used for out of bounds situations at the start and end of EEG data\n",
    "                    aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "                    stacked_spindles.append(aligned_segment)\n",
    "                    # the aligned segment is saved in stacked spindles\n",
    "                \n",
    "                start_idx = above_threshold[i]\n",
    "                # update the start index for the for loop\n",
    "\n",
    "        # then need to process the final spindle\n",
    "        end_idx = above_threshold[-1]\n",
    "        duration = (end_idx - start_idx) / sfreq\n",
    "        if 0.5 <= duration <= 3:\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            peak_idx = start_idx + np.argmax(segment)\n",
    "            spindles.append((start_idx / sfreq, end_idx / sfreq))\n",
    "\n",
    "            before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "            after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "            aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "            stacked_spindles.append(aligned_segment)\n",
    "    \n",
    "    return spindles\n",
    "    \n",
    "\n",
    "def detect_spindles_peaks(eeg_raw, do_filter=True, do_downsample=False, downsample_rate=100):\n",
    "    \n",
    "    # 1. Filter between 12 and 16 Hz\n",
    "    \n",
    "    data = eeg_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=12, h_freq=16)\n",
    "    \n",
    "    # 2. Downsample at 100 Hz (100 samples per second)\n",
    "    \n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "        \n",
    "    sfreq = data.info['sfreq']  \n",
    "    # update to new sampling frequency\n",
    "    # because used later in the code\n",
    "    channel_data = data.get_data()[0]\n",
    "    # extract the filtered data\n",
    "    \n",
    "    # 3: Calculate amplitude by applying Hilbert transformation\n",
    "\n",
    "    hilbert_signal = hilbert(channel_data)\n",
    "    # apply hilbert transformation to bandpassed data\n",
    "    # gives analytic signal with amplitude and phase information\n",
    "    envelope = np.abs(hilbert_signal)\n",
    "    # take the absolute part of the hilbert signal\n",
    "    # also the instantaneous power of the signal\n",
    "    # gives the envelope: amplitude modulation\n",
    "    # how strength of oscillations change over time\n",
    "    # size of sliding window\n",
    "    \n",
    "    # 4: Perform smoothing with a sliding window of 0.2 seconds\n",
    "    # this removes high-frequency noise\n",
    "    \n",
    "    sliding_window = int(0.2 * sfreq)\n",
    "    smoothed_envelope = np.convolve(envelope, np.ones(sliding_window) / sliding_window, mode='same')\n",
    "    # convolving envelope with a uniform filter over the sliding window\n",
    "    # convolution takes rolling average of 20 samples at a time\n",
    "    # smooth the signal with the average of values in the window\n",
    "    # in the smoothed envelope, can detect regions with higher amplitude \n",
    "    # which is when a spindle event occurs\n",
    "    # np.ones: creates a filter kernel\n",
    "    # have a filter where the sum of all elements equals 1\n",
    "    # this filter is replaced by the average of the 20 surrounding samples\n",
    "    # convolution between envelope and averaging filter\n",
    "    # mode = 'same': so that output of convolution has same length as original envelope\n",
    "\n",
    "    # 5. Define spindle detection threshold\n",
    "\n",
    "    threshold = np.percentile(smoothed_envelope, 75)\n",
    "    spindle_threshold = smoothed_envelope > threshold\n",
    "    # 75th percentile as criteria\n",
    "\n",
    "    #threshold = np.mean(smoothed_envelope) + 1.5 * np.std(smoothed_envelope)\n",
    "    #spindle_threshold = smoothed_envelope > threshold\n",
    "    \n",
    "    # 6. Detect spindles and define peaks and troughs for visualisation\n",
    "    \n",
    "    spindles = []\n",
    "    # initialize list with spindles\n",
    "    above_threshold = np.where(spindle_threshold)[0]\n",
    "    # returns indices where signal above the threshold\n",
    "    stacked_spindles = []\n",
    "    # initialize list for stacking the spindles for the visualisation\n",
    "    # contains aligned spindles at peak\n",
    "    \n",
    "    if len(above_threshold) > 0:\n",
    "        # checking it's not empty\n",
    "        start_idx = above_threshold[0]\n",
    "        # would be the start of a potential spindle\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] > above_threshold[i - 1] + 1:  \n",
    "                # if above threshold[1] > above_threshold[0] + 1\n",
    "                # because all indices should be separated by 1\n",
    "                # so here detects gaps\n",
    "                end_idx = above_threshold[i - 1]\n",
    "                # so if above condition is true, this is the end of the spindle\n",
    "                duration = (end_idx - start_idx) / sfreq\n",
    "                if 0.5 <= duration <= 3:\n",
    "                    # only keep spindles lasting 0.5 to 3 seconds\n",
    "                    segment = channel_data[start_idx:end_idx]\n",
    "                    # extract EEG segment corresponding to detected spindle\n",
    "                    peak_idx = start_idx + np.argmax(segment) \n",
    "                    # extract the peak of the spindle\n",
    "                    # this will be useful for later\n",
    "                    #spindles.append(f\"Spindle detected from {start_idx / sfreq:.2f}s to {end_idx / sfreq:.2f}s, peak at {peak_idx / sfreq:.2f}s\")\n",
    "                    spindles.append((peak_idx / sfreq))\n",
    "                    # all the spindles are stored in spindles\n",
    "                    \n",
    "                    # Aligning spindles at peak for visualization\n",
    "                    before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "                    # still in the for loop, so this is the peak index of individual peak\n",
    "                    after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "                    # extracting 1.5 seconds before and after peak\n",
    "                    # max and min are used for out of bounds situations at the start and end of EEG data\n",
    "                    aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "                    stacked_spindles.append(aligned_segment)\n",
    "                    # the aligned segment is saved in stacked spindles\n",
    "                \n",
    "                start_idx = above_threshold[i]\n",
    "                # update the start index for the for loop\n",
    "\n",
    "        # then need to process the final spindle\n",
    "        end_idx = above_threshold[-1]\n",
    "        duration = (end_idx - start_idx) / sfreq\n",
    "        if 0.5 <= duration <= 3:\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            peak_idx = start_idx + np.argmax(segment)\n",
    "            spindles.append((peak_idx / sfreq))\n",
    "\n",
    "            before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "            after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "            aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "            stacked_spindles.append(aligned_segment)\n",
    "\n",
    "    \n",
    "    return spindles\n",
    "\n",
    "def detect_spindles_peaks_average(eeg_raw, do_filter=True, do_downsample=False, downsample_rate=100):\n",
    "    # same as above but returns spindles and stacked spindles\n",
    "    \n",
    "    # 1. Filter between 12 and 16 Hz\n",
    "    \n",
    "    data = eeg_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=12, h_freq=16)\n",
    "    \n",
    "    # 2. Downsample at 100 Hz (100 samples per second)\n",
    "    \n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "        \n",
    "    sfreq = data.info['sfreq']  \n",
    "    # update to new sampling frequency\n",
    "    # because used later in the code\n",
    "    channel_data = data.get_data()[0]\n",
    "    # extract the filtered data\n",
    "    \n",
    "    # 3: Calculate amplitude by applying Hilbert transformation\n",
    "\n",
    "    hilbert_signal = hilbert(channel_data)\n",
    "    # apply hilbert transformation to bandpassed data\n",
    "    # gives analytic signal with amplitude and phase information\n",
    "    envelope = np.abs(hilbert_signal)\n",
    "    # take the absolute part of the hilbert signal\n",
    "    # also the instantaneous power of the signal\n",
    "    # gives the envelope: amplitude modulation\n",
    "    # how strength of oscillations change over time\n",
    "    # size of sliding window\n",
    "    \n",
    "    # 4: Perform smoothing with a sliding window of 0.2 seconds\n",
    "    # this removes high-frequency noise\n",
    "    \n",
    "    sliding_window = int(0.2 * sfreq)\n",
    "    smoothed_envelope = np.convolve(envelope, np.ones(sliding_window) / sliding_window, mode='same')\n",
    "    # convolving envelope with a uniform filter over the sliding window\n",
    "    # convolution takes rolling average of 20 samples at a time\n",
    "    # smooth the signal with the average of values in the window\n",
    "    # in the smoothed envelope, can detect regions with higher amplitude \n",
    "    # which is when a spindle event occurs\n",
    "    # np.ones: creates a filter kernel\n",
    "    # have a filter where the sum of all elements equals 1\n",
    "    # this filter is replaced by the average of the 20 surrounding samples\n",
    "    # convolution between envelope and averaging filter\n",
    "    # mode = 'same': so that output of convolution has same length as original envelope\n",
    "\n",
    "    # 5. Define spindle detection threshold\n",
    "\n",
    "    threshold = np.percentile(smoothed_envelope, 75)\n",
    "    spindle_threshold = smoothed_envelope > threshold\n",
    "    # 75th percentile as criteria\n",
    "\n",
    "    #threshold = np.mean(smoothed_envelope) + 1.5 * np.std(smoothed_envelope)\n",
    "    #spindle_threshold = smoothed_envelope > threshold\n",
    "    \n",
    "    # 6. Detect spindles and define peaks and troughs for visualisation\n",
    "    \n",
    "    spindles = []\n",
    "    # initialize list with spindles\n",
    "    above_threshold = np.where(spindle_threshold)[0]\n",
    "    # returns indices where signal above the threshold\n",
    "    stacked_spindles = []\n",
    "    # initialize list for stacking the spindles for the visualisation\n",
    "    # contains aligned spindles at peak\n",
    "    \n",
    "    if len(above_threshold) > 0:\n",
    "        # checking it's not empty\n",
    "        start_idx = above_threshold[0]\n",
    "        # would be the start of a potential spindle\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] > above_threshold[i - 1] + 1:  \n",
    "                # if above threshold[1] > above_threshold[0] + 1\n",
    "                # because all indices should be separated by 1\n",
    "                # so here detects gaps\n",
    "                end_idx = above_threshold[i - 1]\n",
    "                # so if above condition is true, this is the end of the spindle\n",
    "                duration = (end_idx - start_idx) / sfreq\n",
    "                if 0.5 <= duration <= 3:\n",
    "                    # only keep spindles lasting 0.5 to 3 seconds\n",
    "                    segment = channel_data[start_idx:end_idx]\n",
    "                    # extract EEG segment corresponding to detected spindle\n",
    "                    peak_idx = start_idx + np.argmax(segment) \n",
    "                    # extract the peak of the spindle\n",
    "                    # this will be useful for later\n",
    "                    #spindles.append(f\"Spindle detected from {start_idx / sfreq:.2f}s to {end_idx / sfreq:.2f}s, peak at {peak_idx / sfreq:.2f}s\")\n",
    "                    spindles.append((peak_idx / sfreq))\n",
    "                    # all the spindles are stored in spindles\n",
    "                    \n",
    "                    # Aligning spindles at peak for visualization\n",
    "                    before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "                    # still in the for loop, so this is the peak index of individual peak\n",
    "                    after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "                    # extracting 1.5 seconds before and after peak\n",
    "                    # max and min are used for out of bounds situations at the start and end of EEG data\n",
    "                    aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "                    stacked_spindles.append(aligned_segment)\n",
    "                    # the aligned segment is saved in stacked spindles\n",
    "                \n",
    "                start_idx = above_threshold[i]\n",
    "                # update the start index for the for loop\n",
    "\n",
    "        # then need to process the final spindle\n",
    "        end_idx = above_threshold[-1]\n",
    "        duration = (end_idx - start_idx) / sfreq\n",
    "        if 0.5 <= duration <= 3:\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            peak_idx = start_idx + np.argmax(segment)\n",
    "            spindles.append((peak_idx / sfreq))\n",
    "\n",
    "            before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "            after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "            aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "            stacked_spindles.append(aligned_segment)\n",
    "\n",
    "    \n",
    "    return spindles, stacked_spindles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56cdca1b-148a-4610-9067-4c56b632519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_spindles(stacked_spindles, plot_name):\n",
    "    max_len = max(len(seg) for seg in stacked_spindles)\n",
    "    padded_stacked_spindles = [np.pad(seg, (0, max_len - len(seg)), constant_values=np.nan) for seg in stacked_spindles]\n",
    "    avg_spindle_waveform = np.nanmean(padded_stacked_spindles, axis=0)\n",
    "    time_axis = np.linspace(-1.5, 1.5, len(avg_spindle_waveform))\n",
    "    # already stacking 1.5 around each side so keep this\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(time_axis, avg_spindle_waveform, color=\"blue\", label=\"Mean Spindle\")\n",
    "    plt.axvline(0, color=\"red\", linestyle=\"--\", label=\"Peak (0s)\")\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude (µV)')\n",
    "    plt.title(plot_name)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be09852-473f-461d-b9cc-523182a9d3e8",
   "metadata": {},
   "source": [
    "## Slow oscillation detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20980f99-324d-4663-aaf8-2f864a345fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_slow_oscillations_times(combined_raw, do_filter=True, do_downsample=False, downsample_rate=100):\n",
    "\n",
    "    # according to methods from Klinzing et al.(2016)\n",
    "\n",
    "    data = combined_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=0.16, h_freq=1.25)\n",
    "\n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "        \n",
    "    sfreq = data.info['sfreq']\n",
    "    channel_data = data.get_data()[0]\n",
    "    \n",
    "    # 3. find all positive-to-negative zero-crossings\n",
    "    \n",
    "    # zero_crossings = np.where( S!= 0)[0]\n",
    "    # can also save this somewhere for further detection of spindles\n",
    "    \n",
    "    S = np.diff(np.sign(channel_data))\n",
    "    # np.sign returns an array with 1 (positive), 0 (zero), -1 (negative)\n",
    "    # np.diff calculates the difference between consecutive elements in an array\n",
    "    # positive value: transition from negative to positive\n",
    "    # negative value: transition from positive to negative\n",
    "    # when it's a zero, means that value stayed the same\n",
    "    zero_crossings = np.where(S < 0)[0]\n",
    "    # -2 is when a positive-to-negative zero-crossing occurs\n",
    "    # goes from 1 to -1 \n",
    "    # -1 - 1 = -2\n",
    "    # [0] extracts the actual array\n",
    "    # extracts the indices of interest from current_data (not S)\n",
    "    #signs = np.sign(current_data)\n",
    "    #pos_to_neg = np.where((signs[:-1] > 0) & (signs[1:] < 0))[0]\n",
    "    # detect +1 to -1\n",
    "    #neg_to_pos = np.where((signs[:-1] <  0) & (signs[1:] > 0))[0]\n",
    "    # detect -1 to +1\n",
    "\n",
    "    # 4. Detect peak potentials in each pair\n",
    "    slow_oscillations = []\n",
    "    negative_peaks = []\n",
    "    positive_peaks = []\n",
    "    peak_to_peak_amplitudes = []\n",
    "    candidate_indices = []\n",
    "\n",
    "    # for loop for each pair\n",
    "    # to collect all the negative and positive peaks\n",
    "    # to further apply criteria\n",
    "    count = 0\n",
    "    for i in range(0, len(zero_crossings)-1, 1):\n",
    "        # loop through all the zero_crossings\n",
    "        # step of 1 (with step of 2, miss some zero_crossings)\n",
    "        start_idx = zero_crossings[i] + 1\n",
    "        # assigns index of zero-crossing (representing start of potential SO)\n",
    "        # to start_idx\n",
    "        end_idx = zero_crossings[i + 1] + 1\n",
    "        # assigns index of next zero-crossing (representing end of potential SO)\n",
    "        # to end_idx\n",
    "\n",
    "        # find the negative to positive crossing in between\n",
    "        #mid_crossings = neg_to_pos[(neg_to_pos > start_idx) & (neg_to_pos < end_idx)]\n",
    "\n",
    "        #if len(mid_crossings) != 1:\n",
    "            #continue\n",
    "\n",
    "        #mid_idx = mid_crossings [0]\n",
    "\n",
    "        #duration = (end_idx - start_idx) / sfreq\n",
    "        #if not (0.8 <= duration <= 2.0):\n",
    "  \n",
    "        \n",
    "        segment_length = (end_idx - start_idx) / sfreq\n",
    "\n",
    "        # need to add +1 because of way extract segment later\n",
    "\n",
    "        # have identified index for the pair\n",
    "        \n",
    "        # extract data segment between crossings\n",
    "        \n",
    "        # find peaks\n",
    "        if 0.8 <= segment_length <= 2.0:\n",
    "            count += 1\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            positive_peak = np.max(segment)\n",
    "            negative_peak = np.min(segment)\n",
    "            peak_to_peak_amplitude = positive_peak - negative_peak\n",
    "\n",
    "        # store values\n",
    "            candidate_indices.append((start_idx, end_idx))\n",
    "            positive_peaks.append(positive_peak)\n",
    "            negative_peaks.append(negative_peak)\n",
    "            peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "\n",
    "    # calculate mean values for comparison\n",
    "    #mean_negative_peak = np.mean(negative_peaks)\n",
    "    # mean_negative_peak = np.mean(negative_peaks) if negative_peaks else 0\n",
    "    #mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes)\n",
    "    # mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes) if peak_to_peak_amplitudes else 0\n",
    "\n",
    "    negative_peak_threshold = np.percentile(negative_peaks, 25)\n",
    "    # keep lowest negative peaks (under the 25th percentile)\n",
    "    peak_to_peak_amplitude_threshold = np.percentile(peak_to_peak_amplitudes, 75)\n",
    "    # keep largest peak-to-peak amplitude (over 75th percentile)\n",
    "\n",
    "    for (start_idx, end_idx), negative_peak, peak_to_peak_amplitude in zip(candidate_indices, negative_peaks, peak_to_peak_amplitudes):\n",
    "        if peak_to_peak_amplitude >= peak_to_peak_amplitude_threshold and negative_peak <= negative_peak_threshold:\n",
    "            slow_oscillations.append((start_idx / sfreq, end_idx / sfreq))\n",
    "            \n",
    "    return slow_oscillations\n",
    "    # returns a list of tuples, in which each tuple represents the start and end times of\n",
    "    # a detected slow oscillation\n",
    "\n",
    "def detect_slow_oscillations_peaks(combined_raw, do_filter=True, do_downsample=True, downsample_rate=100):\n",
    "\n",
    "    # according to methods from Klinzing et al.(2016)\n",
    "\n",
    "    data = combined_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=0.16, h_freq=1.25)\n",
    "\n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "        \n",
    "    sfreq = data.info['sfreq']\n",
    "    channel_data = data.get_data()[0]\n",
    "    \n",
    "    # 3. find all positive-to-negative zero-crossings\n",
    "    \n",
    "    # zero_crossings = np.where( S!= 0)[0]\n",
    "    # can also save this somewhere for further detection of spindles\n",
    "    \n",
    "    S = np.diff(np.sign(channel_data))\n",
    "    # np.sign returns an array with 1 (positive), 0 (zero), -1 (negative)\n",
    "    # np.diff calculates the difference between consecutive elements in an array\n",
    "    # positive value: transition from negative to positive\n",
    "    # negative value: transition from positive to negative\n",
    "    # when it's a zero, means that value stayed the same\n",
    "    zero_crossings = np.where(S < 0)[0]\n",
    "    # -2 is when a positive-to-negative zero-crossing occurs\n",
    "    # goes from 1 to -1 \n",
    "    # -1 - 1 = -2\n",
    "    # [0] extracts the actual array\n",
    "    # extracts the indices of interest from current_data (not S)\n",
    "\n",
    "\n",
    "    # 4. Detect peak potentials in each pair\n",
    "    slow_oscillations = []\n",
    "    slow_oscillations_peaks = []\n",
    "    negative_peaks = []\n",
    "    positive_peaks = []\n",
    "    peak_to_peak_amplitudes = []\n",
    "    candidate_indices =  []\n",
    "\n",
    "    # for loop for each pair\n",
    "    # to collect all the negative and positive peaks\n",
    "    # to further apply criteria\n",
    "    count = 0\n",
    "    for i in range(0, len(zero_crossings) - 1, 1):\n",
    "        # loop through all the zero_crossings\n",
    "        # step of 1 (with step of 2, miss some zero_crossings)\n",
    "        start_idx = zero_crossings[i] + 1\n",
    "        # assigns index of zero-crossing (representing start of potential SO)\n",
    "        # to start_idx\n",
    "        end_idx = zero_crossings[i + 1] + 1\n",
    "        # assigns index of next zero-crossing (representing end of potential SO)\n",
    "        # to end_idx\n",
    "        segment_length = (end_idx - start_idx) / sfreq\n",
    "\n",
    "        # need to add +1 because of way extract segment later\n",
    "\n",
    "        # have identified index for the pair\n",
    "        \n",
    "        # extract data segment between crossings\n",
    "        \n",
    "        # find peaks\n",
    "        if 0.8 <= segment_length <= 2.0:\n",
    "            count += 1\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            positive_peak = np.max(segment)\n",
    "            negative_peak = np.min(segment)\n",
    "            peak_to_peak_amplitude = positive_peak - negative_peak\n",
    "\n",
    "        # store values\n",
    "            candidate_indices.append((start_idx, end_idx))\n",
    "            positive_peaks.append(positive_peak)\n",
    "            negative_peaks.append(negative_peak)\n",
    "            peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "\n",
    "    # calculate mean values for comparison\n",
    "    #mean_negative_peak = np.mean(negative_peaks)\n",
    "    # mean_negative_peak = np.mean(negative_peaks) if negative_peaks else 0\n",
    "    #mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes)\n",
    "    # mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes) if peak_to_peak_amplitudes else 0\n",
    "\n",
    "    negative_peak_threshold = np.percentile(negative_peaks, 25)\n",
    "    peak_to_peak_amplitude_threshold = np.percentile(peak_to_peak_amplitudes, 75)\n",
    "\n",
    "    for (start_idx, end_idx), negative_peak, peak_to_peak_amplitude in zip(candidate_indices, negative_peaks, peak_to_peak_amplitudes):\n",
    "        if peak_to_peak_amplitude >= peak_to_peak_amplitude_threshold and negative_peak <= negative_peak_threshold:\n",
    "            slow_oscillations.append((start_idx / sfreq, end_idx / sfreq))\n",
    "            slow_oscillations_peaks.append((negative_peak, positive_peak))\n",
    "\n",
    "            \n",
    "    return slow_oscillations_peaks\n",
    "    # returns a list of tuples, in which each tuple represents the start and end times of\n",
    "    # a detected slow oscillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a86678-6dd3-401b-8184-07bf4ef2afda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now want to visualise slow oscillations\n",
    "# find peak and trough for each of them, and then stack them all together to visualise\n",
    "\n",
    "# this function aligns detected slow oscillations at their trough\n",
    "# creates an average SO waveform\n",
    "\n",
    "def visualize_and_stack_slow_oscillations_trough(combined_raw, slow_oscillations, plot_name):\n",
    "\n",
    "    # Apply band-pass filter between 0.3 and 1.25 Hz\n",
    "    filtered_data = combined_raw.copy().filter(l_freq=0.16, h_freq=1.25)\n",
    "    # downsampling to 100 Hz\n",
    "    #filtered_data.resample(100)\n",
    "    filtered_channel_data = filtered_data.get_data(picks=\"Fz\")[0]\n",
    "    \n",
    "    sfreq = filtered_data.info['sfreq']\n",
    "    \n",
    "    stacked_data = []\n",
    "    # loop through each slow oscillation\n",
    "    for start_time, end_time in slow_oscillations:\n",
    "        # to convert start and end times to sample indices\n",
    "        start_idx = int(start_time * sfreq)\n",
    "        end_idx = int(end_time * sfreq)\n",
    "\n",
    "        # extract the slow oscillation segment\n",
    "        segment = filtered_channel_data[start_idx:end_idx]\n",
    "\n",
    "        global_trough_idx = np.argmin(filtered_channel_data[start_idx:end_idx]) + start_idx\n",
    "         # argmin finds the index of the min value\n",
    "        # min finds the min value itself\n",
    "        \n",
    "        # calculate indices for 1.5 seconds before and after trough\n",
    "        before_trough_idx = max(0, global_trough_idx - int(1.5 * sfreq))\n",
    "        # substracts 1.5 seconds from the trough index\n",
    "        # max as a safety check, to make sure that before_trough_index never negative\n",
    "        # to prevent accessing data points before the beginning of the segment\n",
    "        after_trough_idx = min(len(filtered_channel_data), global_trough_idx + int(1.5 * sfreq))\n",
    "        # adds 1.5 seconds to the trough index\n",
    "        # min is another safety check\n",
    "        \n",
    "        # extract the segment around the trough\n",
    "        aligned_segment = filtered_channel_data[before_trough_idx:after_trough_idx]\n",
    "\n",
    "        # append the aligned segment to the stacked data\n",
    "        stacked_data.append(aligned_segment)\n",
    "\n",
    "    # Find the maximum length of the segments\n",
    "    max_len = max(len(segment) for segment in stacked_data)\n",
    "\n",
    "    # Pad shorter segments with np.nan\n",
    "    padded_stacked_data = []\n",
    "    for segment in stacked_data:\n",
    "        pad_len = max_len - len(segment)\n",
    "        # how much padding is needed\n",
    "        pad_before = pad_len // 2\n",
    "        pad_after = pad_len - pad_before\n",
    "        padded_segment = np.pad(segment, (pad_before, pad_after), 'constant', constant_values=np.nan)\n",
    "        # distribute the padding before and after the segment\n",
    "        # use NaNs instead of zeros to avoid bias\n",
    "        padded_stacked_data.append(padded_segment)\n",
    "\n",
    "    # calculate the average stacked slow oscillation\n",
    "    average_padded_stacked_data = np.nanmean(padded_stacked_data, axis=0)\n",
    "    # compute average waveform by ignoring NaNs\n",
    "\n",
    "    # visualize the average stacked slow oscillation\n",
    "    time_axis = np.linspace(-1.5, 1.5, len(average_padded_stacked_data))\n",
    "    # this is to create the time axis\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(time_axis, average_padded_stacked_data, color=\"blue\", label=\"Mean SO\")\n",
    "    plt.axvline(0, color=\"red\", linestyle=\"--\", label=\"Trough (0s)\")\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude (µV)')\n",
    "    plt.title(plot_name)\n",
    "    plt.legend()\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757a47d5-6917-4bd5-bf4a-79df47ec9787",
   "metadata": {},
   "source": [
    "## SO-spindle coupling detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6771ec46-4c9b-4edd-9c58-b18915a3057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_slow_oscillations_spindles_coupling_so_times(combined_raw, do_filter=True, do_downsample=True, downsample_rate=100):\n",
    "    slow_oscillations_peaks = detect_slow_oscillations_peaks(combined_raw, do_filter=do_filter, do_downsample=do_downsample, downsample_rate=downsample_rate)\n",
    "    slow_oscillations_times = detect_slow_oscillations_times(combined_raw, do_filter=do_filter, do_downsample=do_downsample, downsample_rate=downsample_rate)\n",
    "    spindles_peaks = detect_spindles_peaks(combined_raw, do_filter=do_filter, do_downsample=do_downsample, downsample_rate=downsample_rate)\n",
    "\n",
    "    coupling_times = []\n",
    "    coupling_times_so = []\n",
    "\n",
    "    # first detect the coupling events\n",
    "    for start_time, end_time in slow_oscillations_times:\n",
    "    #for start_time, end_time (negative_peak, positive_peak) in zip(slow_oscillations_times, slow_oscillations_peaks):\n",
    "        for peak in spindles_peaks:\n",
    "            if start_time < peak < end_time:\n",
    "                # if negative_peak < peak < end_time:\n",
    "                coupling_times.append(peak)\n",
    "                # if the peak of the spindle is between the negative and positive trough\n",
    "                # add it to list of coupling times\n",
    "\n",
    "    # then calculate the slow oscillation length\n",
    "    for start_time, end_time in slow_oscillations_times:\n",
    "        current_start_time = start_time\n",
    "        current_end_time = end_time\n",
    "        for coupling_peak in coupling_times:\n",
    "            if current_start_time < coupling_peak < current_end_time:\n",
    "                coupling_times_so.append((current_start_time, current_end_time))\n",
    "\n",
    "    return coupling_times_so"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4c5cf-c198-4b1d-9bd0-f996c4e84367",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed73c7a-168d-4bc0-a8e4-2e7d151b1137",
   "metadata": {},
   "source": [
    "### at 500 Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c7c252-4714-4cc5-be0d-aced80845670",
   "metadata": {},
   "source": [
    "## Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e89fea8-008a-445b-940c-34029060ba6c",
   "metadata": {},
   "source": [
    "### Spindle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "69e233c2-17b3-4d97-96d3-4d15b76ef1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 12 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 12.00\n",
      "- Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 551 samples (1.102 s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spindles, stacked = detect_spindles_peaks_average(large_participants_raw)\n",
    "visualize_spindles(stacked, \"Average Spindle for 53 participants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01a7971-c6f9-45d7-a1bc-9910c66a9e6e",
   "metadata": {},
   "source": [
    "### Slow oscillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ff22996-86f8-453f-bc37-f8ce9dbe6e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 0.16 - 1.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.16\n",
      "- Lower transition bandwidth: 0.16 Hz (-6 dB cutoff frequency: 0.08 Hz)\n",
      "- Upper passband edge: 1.25 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.25 Hz)\n",
      "- Filter length: 10313 samples (20.626 s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "slow_oscillations_times = detect_slow_oscillations_times(large_participants_raw, do_filter=True, do_downsample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "61958ce1-8a55-4f9b-abbd-3b31d901b260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 0.16 - 1.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.16\n",
      "- Lower transition bandwidth: 0.16 Hz (-6 dB cutoff frequency: 0.08 Hz)\n",
      "- Upper passband edge: 1.25 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.25 Hz)\n",
      "- Filter length: 10313 samples (20.626 s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## if do_downsample=True, need to turn on downsampling in visualisation function\n",
    "\n",
    "visualize_and_stack_slow_oscillations_trough(\n",
    "    large_participants_raw,\n",
    "    slow_oscillations_times,\n",
    "    plot_name=\"Average Slow Oscillation for 53 participants\",\n",
    "    do_downsample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b16bc5e-b089-44ae-9ad1-59ddae75b18e",
   "metadata": {},
   "source": [
    "## Coupling visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32bab005-9b9f-4842-bf63-3efb0799b913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_so_spindle_coupling(raw, so_spindle_coupling_times, plot_name, do_downsample=False):\n",
    "    # here compute the STFT for spindles\n",
    "    # not all the data\n",
    "    # did apply per-frequency z score normalisation\n",
    "\n",
    "    # slow oscillation \n",
    "    so_filtered_data = raw.copy().filter(l_freq=0.16, h_freq=1.25)\n",
    "    if do_downsample:\n",
    "        so_filtered_data.resample(100)\n",
    "    so_channel_data = so_filtered_data.get_data(picks=\"Fz\")[0]\n",
    "    sfreq = so_filtered_data.info['sfreq']\n",
    "    # define the sampling frequency\n",
    "    # after or before downsampling\n",
    "\n",
    "    # spindle\n",
    "    spindle_filtered_data = raw.copy().filter(l_freq=12, h_freq=16)\n",
    "    if do_downsample:\n",
    "        spindle_filtered_data.resample(100)\n",
    "    spindle_channel_data = spindle_filtered_data.get_data(picks=\"Fz\")[0]\n",
    "\n",
    "    # raw\n",
    "    raw_channel_data = raw.get_data(picks=\"Fz\")[0]\n",
    "\n",
    "\n",
    "    # align everything to the SO trough\n",
    "    aligned_so_segments = []\n",
    "    aligned_spindle_segments = []\n",
    "    aligned_raw_segments = []\n",
    "    for start_time, end_time in so_spindle_coupling_times:\n",
    "        # extract start and end times of SOs\n",
    "        # do this for every coupled SO\n",
    "        start_idx = int(start_time * sfreq)\n",
    "        end_idx = int(end_time * sfreq)\n",
    "\n",
    "        # trough is argmin\n",
    "        so_segment = so_channel_data[start_idx:end_idx]\n",
    "        trough_idx = np.argmin(so_segment) + start_idx\n",
    "\n",
    "        # keep -1.5 and 1.5 seconds around the trough\n",
    "        before_trough_idx = max(0, trough_idx - int(1.5 * sfreq))\n",
    "        after_trough_idx = min(len(so_channel_data), trough_idx + int(1.5 * sfreq))\n",
    "        aligned_so_segment = so_channel_data[before_trough_idx:after_trough_idx]\n",
    "        aligned_so_segments.append(aligned_so_segment)\n",
    "\n",
    "        # extract spindle data\n",
    "        aligned_spindle_segment = spindle_channel_data[before_trough_idx:after_trough_idx]\n",
    "        # extract the data between 12 and 16 Hz that occurs during that same time window\n",
    "        aligned_spindle_segments.append(aligned_spindle_segment)\n",
    "\n",
    "\n",
    "    # pad and average the SO (as in previous function)\n",
    "    max_len_so = max(len(seg) for seg in aligned_so_segments)\n",
    "    padded_so_segments = [np.pad(seg, (0, max_len_so - len(seg)), constant_values=np.nan) for seg in aligned_so_segments]\n",
    "    avg_so_waveform = np.nanmean(padded_so_segments, axis=0)\n",
    "    time_axis = np.linspace(-1.5, 1.5, len(avg_so_waveform))\n",
    "\n",
    "    # average spectrogram for spindle and pad\n",
    "    max_len_spindle = max(len(seg) for seg in aligned_spindle_segments)\n",
    "    padded_spindle_segments = [np.pad(seg, (0, max_len_spindle- len(seg)), constant_values=np.nan) for seg in aligned_spindle_segments]\n",
    "\n",
    "    # STFT for spindle\n",
    "    baseline = np.mean(spindle_channel_data[:50])\n",
    "    # first 50 time points of data\n",
    "    Sxx_list = []\n",
    "    for seg in padded_spindle_segments:\n",
    "        # NaNs are replaced with 0\n",
    "        if np.isnan(seg).any():\n",
    "            seg = np.nan_to_num(seg) \n",
    "        # baseline correction\n",
    "        seg = seg - baseline\n",
    "        freqs, times, Sxx = signal.stft(seg, fs=sfreq, nperseg=int(sfreq/4), noverlap=int(sfreq/8))\n",
    "        # z-score normalisation\n",
    "        m = np.mean(Sxx)\n",
    "        s = np.std(Sxx)\n",
    "        Sxx = (Sxx - m) / s\n",
    "        Sxx_list.append(np.abs(Sxx))\n",
    "\n",
    "    # then average all the spectrograms\n",
    "    avg_Sxx = np.nanmean(Sxx_list, axis=0)\n",
    "\n",
    "    # interpolation (cubic)\n",
    "    #tim_interp = np.linspace(times.min(), times.max(), 5120)\n",
    "    #freq_interp = np.linspace(freqs.min(), freqs.max(), 1024)\n",
    "    #interp_tf = RegularGridInterpolator(times, freqs, avg_Sxx, kind='cubic')\n",
    "    #pow_interp_tf = interp_tf(tim_interp, freq_interp)\n",
    "\n",
    "    # interpolation (cubic)\n",
    "    tim_interp = np.linspace(times.min(), times.max(), 5120) \n",
    "    freq_interp = np.linspace(freqs.min(), freqs.max(), 1024)\n",
    "    grid = (freqs, times) \n",
    "    points = np.array(np.meshgrid(freq_interp, tim_interp, indexing='ij')).reshape(2, -1).T\n",
    "    pow_interp_tf = interpn(grid, avg_Sxx, points, method='cubic')\n",
    "    pow_interp_tf = pow_interp_tf.reshape(len(freq_interp), len(tim_interp))\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # plot spectrogram\n",
    "    #im = ax.pcolormesh(times - 1.5, freqs, avg_Sxx, shading='gouraud', cmap='viridis')\n",
    "    im = ax.imshow(pow_interp_tf, aspect='auto', extent=[times.min()-1.5, times.max()-1.5, freqs.min(), freqs.max()], origin='lower', cmap='viridis', vmin=0, vmax=8)\n",
    "    fig.colorbar(im, ax=ax, label='Power/Frequency (dB/Hz)', pad=0.1)\n",
    "    #cbar = fig.colorbar(im, ax=ax, label='Power/Frequency (dB/Hz)', pad=0.1)\n",
    "    #cbar.set_label('Z-scored Power', rotation=270, labelpad=15)\n",
    "    \n",
    "\n",
    "    # Overlay SO waveform\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(time_axis, avg_so_waveform, color='red', linewidth=2, label='Average SO')\n",
    "    ax2.set_ylabel('Amplitude (µV)', color='red')\n",
    "    ax2.tick_params(axis='y', labelcolor='red')\n",
    "    ax2.axvline(0, color='white', linestyle='--', label=\"Trough (0s)\")\n",
    "\n",
    "\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Frequency (Hz)')\n",
    "    ax.set_ylim(0, 30)\n",
    "    ax.set_title(plot_name)\n",
    "    ax.legend()\n",
    "    #ax.legend(loc='upper left')\n",
    "    #ax2.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_so_no_spindle_coupling(raw, slow_oscillations_times, spindles_peaks, plot_name, do_downsample=False):\n",
    "\n",
    "    # identify non-coupled SOs\n",
    "    # as those that don't respect the definition\n",
    "    non_coupled_so_times = []\n",
    "    for start_time, end_time in slow_oscillations_times:\n",
    "        coupled = False\n",
    "        for peak in spindles_peaks:\n",
    "            if start_time < peak < end_time:\n",
    "                coupled = True\n",
    "                break\n",
    "        if not coupled:\n",
    "            non_coupled_so_times.append((start_time, end_time))\n",
    "\n",
    "    # slow oscillation\n",
    "    so_filtered_data = raw.copy().filter(l_freq=0.16, h_freq=1.25)\n",
    "    if do_downsample:\n",
    "        so_filtered_data.resample(100)\n",
    "    so_channel_data = so_filtered_data.get_data(picks=\"Fz\")[0]\n",
    "    sfreq = so_filtered_data.info['sfreq']\n",
    "\n",
    "    # spindle\n",
    "    spindle_filtered_data = raw.copy().filter(l_freq=12, h_freq=16)\n",
    "    if do_downsample:\n",
    "        spindle_filtered_data.resample(100)\n",
    "    spindle_channel_data = spindle_filtered_data.get_data(picks=\"Fz\")[0]\n",
    "\n",
    "    # raw\n",
    "    raw_channel_data = raw.get_data(picks=\"Fz\")[0]\n",
    "\n",
    "    # align everything to the SO trough\n",
    "    aligned_so_segments = []\n",
    "    aligned_spindle_segments = []\n",
    "    for start_time, end_time in non_coupled_so_times:\n",
    "        start_idx = int(start_time * sfreq)\n",
    "        end_idx = int(end_time * sfreq)\n",
    "\n",
    "        # trough is argming\n",
    "        so_segment = so_channel_data[start_idx:end_idx]\n",
    "        trough_idx = np.argmin(so_segment) + start_idx\n",
    "\n",
    "        # same logic as above\n",
    "        before_trough_idx = max(0, trough_idx - int(1.5 * sfreq))\n",
    "        after_trough_idx = min(len(so_channel_data), trough_idx + int(1.5 * sfreq))\n",
    "        aligned_so_segment = so_channel_data[before_trough_idx:after_trough_idx]\n",
    "        aligned_so_segments.append(aligned_so_segment)\n",
    "\n",
    "        # spindle aligned to SO trough\n",
    "        aligned_spindle_segment = spindle_channel_data[before_trough_idx:after_trough_idx]\n",
    "        aligned_spindle_segments.append(aligned_spindle_segment)\n",
    "\n",
    "\n",
    "    # SO average\n",
    "    max_len_so = max(len(seg) for seg in aligned_so_segments)\n",
    "    padded_so_segments = [np.pad(seg, (0, max_len_so - len(seg)), constant_values=np.nan) for seg in aligned_so_segments]\n",
    "    avg_so_waveform = np.nanmean(padded_so_segments, axis=0)\n",
    "    time_axis = np.linspace(-1.5, 1.5, len(avg_so_waveform))\n",
    "\n",
    "    # spindle spectogram average and pad\n",
    "    max_len_spindle = max(len(seg) for seg in aligned_spindle_segments)\n",
    "    padded_spindle_segments = [np.pad(seg, (0, max_len_spindle- len(seg)), constant_values=np.nan) for seg in aligned_spindle_segments]\n",
    "\n",
    "    # STFT for spindles\n",
    "    Sxx_list = []\n",
    "    baseline = np.mean(spindle_channel_data[:50])\n",
    "    for seg in padded_spindle_segments:\n",
    "        # Handle potential NaNs from padding\n",
    "        if np.isnan(seg).any():\n",
    "            seg = np.nan_to_num(seg) # Replace NaNs with 0 for STFT\n",
    "        seg = seg - baseline\n",
    "        freqs, times, Sxx = signal.stft(seg, fs=sfreq, nperseg=int(sfreq/4), noverlap=int(sfreq/8))\n",
    "        # z-score normalisation\n",
    "        m = np.mean(Sxx)\n",
    "        s = np.std(Sxx)\n",
    "        Sxx = (Sxx - m) / s\n",
    "        Sxx_list.append(np.abs(Sxx))\n",
    "\n",
    "    # spectrogram average\n",
    "    avg_Sxx = np.nanmean(Sxx_list, axis=0)\n",
    "\n",
    "    # interpolation (cubic)\n",
    "    tim_interp = np.linspace(times.min(), times.max(), 5120) \n",
    "    freq_interp = np.linspace(freqs.min(), freqs.max(), 1024)\n",
    "    grid = (freqs, times) \n",
    "    points = np.array(np.meshgrid(freq_interp, tim_interp, indexing='ij')).reshape(2, -1).T\n",
    "    pow_interp_tf = interpn(grid, avg_Sxx, points, method='cubic')\n",
    "    pow_interp_tf = pow_interp_tf.reshape(len(freq_interp), len(tim_interp))\n",
    "\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # spectogram plot\n",
    "    #im = ax.pcolormesh(times - 1.5, freqs, avg_Sxx, shading='gouraud', cmap='viridis')\n",
    "    im = ax.imshow(pow_interp_tf, aspect='auto', extent=[times.min()-1.5, times.max()-1.5, freqs.min(), freqs.max()], origin='lower', cmap='viridis', vmin=0, vmax=8)\n",
    "    fig.colorbar(im, ax=ax, label='Power/Frequency (dB/Hz)', pad=0.1)\n",
    "    #cbar = fig.colorbar(im, ax=ax, label='Power/Frequency (dB/Hz)', pad=0.1)\n",
    "    #cbar.set_label('Z-scored Power', rotation=270, labelpad=15)\n",
    "\n",
    "    # SO waveform\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(time_axis, avg_so_waveform, color='red', linewidth=2, label='Average SO')\n",
    "    ax2.set_ylabel('Amplitude (µV)', color='red')\n",
    "    ax2.tick_params(axis='y', labelcolor='red')\n",
    "    ax2.axvline(0, color='white', linestyle='--', label=\"Trough (0s)\")\n",
    "\n",
    "\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Frequency (Hz)')\n",
    "    ax.set_ylim(0, 30)\n",
    "    ax.set_title(plot_name)\n",
    "    ax.legend()\n",
    "    #ax.legend(loc='upper left')\n",
    "    #ax2.legend(loc='upper right')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ca44de7-c562-4387-9a41-eac117c27639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 12 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 12.00\n",
      "- Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 551 samples (1.102 s)\n",
      "\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 0.16 - 1.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.16\n",
      "- Lower transition bandwidth: 0.16 Hz (-6 dB cutoff frequency: 0.08 Hz)\n",
      "- Upper passband edge: 1.25 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.25 Hz)\n",
      "- Filter length: 10313 samples (20.626 s)\n",
      "\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 12 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 12.00\n",
      "- Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 551 samples (1.102 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roseb\\AppData\\Local\\Temp\\ipykernel_4504\\2204924612.py:118: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  ax.legend()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 0.16 - 1.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.16\n",
      "- Lower transition bandwidth: 0.16 Hz (-6 dB cutoff frequency: 0.08 Hz)\n",
      "- Upper passband edge: 1.25 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.25 Hz)\n",
      "- Filter length: 10313 samples (20.626 s)\n",
      "\n",
      "Filtering raw data in 123 contiguous segments\n",
      "Setting up band-pass filter from 12 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 12.00\n",
      "- Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 551 samples (1.102 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roseb\\AppData\\Local\\Temp\\ipykernel_4504\\2204924612.py:234: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  ax.legend()\n"
     ]
    }
   ],
   "source": [
    "spindles_peaks = detect_spindles_peaks(\n",
    "    large_participants_raw,\n",
    "    do_filter=True,\n",
    "    do_downsample=False\n",
    ")\n",
    "\n",
    "visualize_so_spindle_coupling(\n",
    "    large_participants_raw,\n",
    "    so_spindle_coupling_times,\n",
    "    \"Average Coupled SO waveform overlaid on Spindle STFT representation for 53 participants\",\n",
    "    do_downsample=False\n",
    ")\n",
    "\n",
    "visualize_so_no_spindle_coupling(\n",
    "    large_participants_raw,\n",
    "    slow_oscillations_times,\n",
    "    spindles_peaks,\n",
    "    \"Average Coupled SO waveform overlaid on Spindle STFT representation for 53 participants\",\n",
    "    do_downsample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f80798-3bd8-495a-9f71-6f6e414893e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
