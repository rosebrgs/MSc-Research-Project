{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14c6dee9-6515-44d9-9c4b-851a8972b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvista\n",
    "import ipywidgets\n",
    "import ipyevents\n",
    "import pyvistaqt\n",
    "import os\n",
    "\n",
    "import mne\n",
    "from mne import concatenate_raws\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_curve, auc\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import hilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390f089e-be6c-45d9-9c50-9dd6e322a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21c552f-1f81-45b6-a7fd-752ab124235a",
   "metadata": {},
   "source": [
    "### Load the participant data from NREM 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e951cc-590c-4f42-9ad9-5e9b4a41a293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:\\EEG DATA\\020\\concatenated\\020_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 1470000 ... 7845026 =   2940.000 ... 15690.052 secs\n",
      "Ready.\n",
      "Reading 0 ... 6375026  =      0.000 ... 12750.052 secs...\n",
      "Opening raw data file C:\\EEG DATA\\033\\concatenated\\033_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 90000 ... 7560030 =    180.000 ... 15120.060 secs\n",
      "Ready.\n",
      "Reading 0 ... 7470030  =      0.000 ... 14940.060 secs...\n",
      "Opening raw data file C:\\EEG DATA\\046\\concatenated\\046_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 300000 ... 8280014 =    600.000 ... 16560.028 secs\n",
      "Ready.\n",
      "Reading 0 ... 7980014  =      0.000 ... 15960.028 secs...\n",
      "Opening raw data file C:\\EEG DATA\\067\\concatenated\\067_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 825000 ... 9180031 =   1650.000 ... 18360.062 secs\n",
      "Ready.\n",
      "Reading 0 ... 8355031  =      0.000 ... 16710.062 secs...\n",
      "Opening raw data file C:\\EEG DATA\\081\\concatenated\\081_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 165000 ... 8970017 =    330.000 ... 17940.034 secs\n",
      "Ready.\n",
      "Reading 0 ... 8805017  =      0.000 ... 17610.034 secs...\n"
     ]
    }
   ],
   "source": [
    "participant_ids = [\"020\", \"033\", \"046\", \"067\", \"081\"]\n",
    "\n",
    "combined_raw_data = {}\n",
    "# will store the raw objects in a dictionary\n",
    "base_path = r\"C:\\EEG DATA\"\n",
    "\n",
    "# for loop through the participants to load the data\n",
    "for pid in participant_ids:\n",
    "    file_path = fr\"{base_path}\\{pid}\\concatenated\\{pid}_concatenated_raw.fif\"\n",
    "    combined_raw_data[pid] = mne.io.read_raw_fif(file_path, preload=True)\n",
    "\n",
    "# if want to access participant 067\n",
    "# raw_067 = combined_raw_data[\"067\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f3111d-5b47-4ecf-bfbd-782e1642aba1",
   "metadata": {},
   "source": [
    "### Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3fbbdc-f1ad-4329-a2c4-7507c3d24ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63030.182\n",
      "14940.06\n"
     ]
    }
   ],
   "source": [
    "train_2_ids = [\"020\", \"046\", \"067\", \"081\"]\n",
    "test_2_ids = [\"033\"]\n",
    "\n",
    "# concatenation\n",
    "train_2_raw = mne.concatenate_raws([combined_raw_data[pid] for pid in train_2_ids])\n",
    "test_2_raw = combined_raw_data[test_2_ids[0]]\n",
    "\n",
    "print(train_2_raw.times[-1])\n",
    "print(test_2_raw.times[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f2121d-d002-46af-b076-ddb0060c6852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n",
      "Writing C:\\EEG DATA\\combined_sets\\train_2_raw.fif\n",
      "Closing C:\\EEG DATA\\combined_sets\\train_2_raw.fif\n",
      "[done]\n",
      "Train set saved to C:\\EEG DATA\\combined_sets\\train_2_raw.fif\n",
      "Overwriting existing file.\n",
      "Writing C:\\EEG DATA\\combined_sets\\test_2_raw.fif\n",
      "Closing C:\\EEG DATA\\combined_sets\\test_2_raw.fif\n",
      "[done]\n",
      "Test set saved to C:\\EEG DATA\\combined_sets\\test_2_raw.fif\n"
     ]
    }
   ],
   "source": [
    "# directory for saving\n",
    "save_dir = os.path.join(base_path, \"combined_sets\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Train set\n",
    "train_2_save_path = os.path.join(save_dir, \"train_2_raw.fif\")\n",
    "train_2_raw.save(train_2_save_path, overwrite=True)\n",
    "print(f\"Train set saved to {train_2_save_path}\")\n",
    "\n",
    "# Test set\n",
    "test_2_save_path = os.path.join(save_dir, \"test_2_raw.fif\")\n",
    "test_2_raw.save(test_2_save_path, overwrite=True)\n",
    "print(f\"Test set saved to {test_2_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
