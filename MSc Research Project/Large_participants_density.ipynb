{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14c6dee9-6515-44d9-9c4b-851a8972b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyvista\n",
    "import ipywidgets\n",
    "import ipyevents\n",
    "import pyvistaqt\n",
    "import os\n",
    "\n",
    "import mne\n",
    "from mne import concatenate_raws\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_curve, auc\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "import scipy.signal as signal\n",
    "from scipy.signal import hilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390f089e-be6c-45d9-9c50-9dd6e322a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21c552f-1f81-45b6-a7fd-752ab124235a",
   "metadata": {},
   "source": [
    "### Load the participant data from NREM 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e951cc-590c-4f42-9ad9-5e9b4a41a293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:\\eeg\\013\\concatenated\\013_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 855000 ... 6750021 =   1710.000 ... 13500.042 secs\n",
      "Ready.\n",
      "Reading 0 ... 5895021  =      0.000 ... 11790.042 secs...\n",
      "Opening raw data file C:\\eeg\\014\\concatenated\\014_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 330000 ... 6540021 =    660.000 ... 13080.042 secs\n",
      "Ready.\n",
      "Reading 0 ... 6210021  =      0.000 ... 12420.042 secs...\n",
      "Opening raw data file C:\\eeg\\018\\concatenated\\018_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 435000 ... 8295022 =    870.000 ... 16590.044 secs\n",
      "Ready.\n",
      "Reading 0 ... 7860022  =      0.000 ... 15720.044 secs...\n",
      "Opening raw data file C:\\eeg\\019\\concatenated\\019_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 675000 ... 6795017 =   1350.000 ... 13590.034 secs\n",
      "Ready.\n",
      "Reading 0 ... 6120017  =      0.000 ... 12240.034 secs...\n",
      "Opening raw data file C:\\eeg\\020\\concatenated\\020_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 1470000 ... 7845026 =   2940.000 ... 15690.052 secs\n",
      "Ready.\n",
      "Reading 0 ... 6375026  =      0.000 ... 12750.052 secs...\n",
      "Opening raw data file C:\\eeg\\022\\concatenated\\022_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 135000 ... 8055025 =    270.000 ... 16110.050 secs\n",
      "Ready.\n",
      "Reading 0 ... 7920025  =      0.000 ... 15840.050 secs...\n",
      "Opening raw data file C:\\eeg\\023\\concatenated\\023_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 960000 ... 7770018 =   1920.000 ... 15540.036 secs\n",
      "Ready.\n",
      "Reading 0 ... 6810018  =      0.000 ... 13620.036 secs...\n",
      "Opening raw data file C:\\eeg\\024\\concatenated\\024_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 255000 ... 7275034 =    510.000 ... 14550.068 secs\n",
      "Ready.\n",
      "Reading 0 ... 7020034  =      0.000 ... 14040.068 secs...\n",
      "Opening raw data file C:\\eeg\\025\\concatenated\\025_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 330000 ... 7050012 =    660.000 ... 14100.024 secs\n",
      "Ready.\n",
      "Reading 0 ... 6720012  =      0.000 ... 13440.024 secs...\n",
      "Opening raw data file C:\\eeg\\027\\concatenated\\027_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 270000 ... 9945039 =    540.000 ... 19890.078 secs\n",
      "Ready.\n",
      "Reading 0 ... 9675039  =      0.000 ... 19350.078 secs...\n",
      "Opening raw data file C:\\eeg\\028\\concatenated\\028_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 495000 ... 8160026 =    990.000 ... 16320.052 secs\n",
      "Ready.\n",
      "Reading 0 ... 7665026  =      0.000 ... 15330.052 secs...\n",
      "Opening raw data file C:\\eeg\\029\\concatenated\\029_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 405000 ... 6555013 =    810.000 ... 13110.026 secs\n",
      "Ready.\n",
      "Reading 0 ... 6150013  =      0.000 ... 12300.026 secs...\n",
      "Opening raw data file C:\\eeg\\030\\concatenated\\030_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 285000 ... 8760019 =    570.000 ... 17520.038 secs\n",
      "Ready.\n",
      "Reading 0 ... 8475019  =      0.000 ... 16950.038 secs...\n",
      "Opening raw data file C:\\eeg\\031\\concatenated\\031_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 195000 ... 7530015 =    390.000 ... 15060.030 secs\n",
      "Ready.\n",
      "Reading 0 ... 7335015  =      0.000 ... 14670.030 secs...\n",
      "Opening raw data file C:\\eeg\\032\\concatenated\\032_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 135000 ... 9390026 =    270.000 ... 18780.052 secs\n",
      "Ready.\n",
      "Reading 0 ... 9255026  =      0.000 ... 18510.052 secs...\n",
      "Opening raw data file C:\\eeg\\033\\concatenated\\033_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 90000 ... 7560030 =    180.000 ... 15120.060 secs\n",
      "Ready.\n",
      "Reading 0 ... 7470030  =      0.000 ... 14940.060 secs...\n",
      "Opening raw data file C:\\eeg\\034\\concatenated\\034_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 585000 ... 8070025 =   1170.000 ... 16140.050 secs\n",
      "Ready.\n",
      "Reading 0 ... 7485025  =      0.000 ... 14970.050 secs...\n",
      "Opening raw data file C:\\eeg\\035\\concatenated\\035_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 330000 ... 8280032 =    660.000 ... 16560.064 secs\n",
      "Ready.\n",
      "Reading 0 ... 7950032  =      0.000 ... 15900.064 secs...\n",
      "Opening raw data file C:\\eeg\\036\\concatenated\\036_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 285000 ... 7305039 =    570.000 ... 14610.078 secs\n",
      "Ready.\n",
      "Reading 0 ... 7020039  =      0.000 ... 14040.078 secs...\n",
      "Opening raw data file C:\\eeg\\037\\concatenated\\037_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 60000 ... 8805025 =    120.000 ... 17610.050 secs\n",
      "Ready.\n",
      "Reading 0 ... 8745025  =      0.000 ... 17490.050 secs...\n",
      "Opening raw data file C:\\eeg\\042\\concatenated\\042_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 120000 ... 6855022 =    240.000 ... 13710.044 secs\n",
      "Ready.\n",
      "Reading 0 ... 6735022  =      0.000 ... 13470.044 secs...\n",
      "Opening raw data file C:\\eeg\\044\\concatenated\\044_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 315000 ... 9840037 =    630.000 ... 19680.074 secs\n",
      "Ready.\n",
      "Reading 0 ... 9525037  =      0.000 ... 19050.074 secs...\n",
      "Opening raw data file C:\\eeg\\046\\concatenated\\046_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 300000 ... 8280014 =    600.000 ... 16560.028 secs\n",
      "Ready.\n",
      "Reading 0 ... 7980014  =      0.000 ... 15960.028 secs...\n",
      "Opening raw data file C:\\eeg\\047\\concatenated\\047_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 420000 ... 7890019 =    840.000 ... 15780.038 secs\n",
      "Ready.\n",
      "Reading 0 ... 7470019  =      0.000 ... 14940.038 secs...\n",
      "Opening raw data file C:\\eeg\\048\\concatenated\\048_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 195000 ... 7530021 =    390.000 ... 15060.042 secs\n",
      "Ready.\n",
      "Reading 0 ... 7335021  =      0.000 ... 14670.042 secs...\n",
      "Opening raw data file C:\\eeg\\049\\concatenated\\049_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 375000 ... 6645019 =    750.000 ... 13290.038 secs\n",
      "Ready.\n",
      "Reading 0 ... 6270019  =      0.000 ... 12540.038 secs...\n",
      "Opening raw data file C:\\eeg\\050\\concatenated\\050_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 540000 ... 10170025 =   1080.000 ... 20340.050 secs\n",
      "Ready.\n",
      "Reading 0 ... 9630025  =      0.000 ... 19260.050 secs...\n",
      "Opening raw data file C:\\eeg\\051\\concatenated\\051_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 510000 ... 8235019 =   1020.000 ... 16470.038 secs\n",
      "Ready.\n",
      "Reading 0 ... 7725019  =      0.000 ... 15450.038 secs...\n",
      "Opening raw data file C:\\eeg\\052\\concatenated\\052_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 1260000 ... 9240026 =   2520.000 ... 18480.052 secs\n",
      "Ready.\n",
      "Reading 0 ... 7980026  =      0.000 ... 15960.052 secs...\n",
      "Opening raw data file C:\\eeg\\053\\concatenated\\053_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 465000 ... 9315021 =    930.000 ... 18630.042 secs\n",
      "Ready.\n",
      "Reading 0 ... 8850021  =      0.000 ... 17700.042 secs...\n",
      "Opening raw data file C:\\eeg\\054\\concatenated\\054_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 135000 ... 9255024 =    270.000 ... 18510.048 secs\n",
      "Ready.\n",
      "Reading 0 ... 9120024  =      0.000 ... 18240.048 secs...\n",
      "Opening raw data file C:\\eeg\\055\\concatenated\\055_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 735000 ... 7875021 =   1470.000 ... 15750.042 secs\n",
      "Ready.\n",
      "Reading 0 ... 7140021  =      0.000 ... 14280.042 secs...\n",
      "Opening raw data file C:\\eeg\\056\\concatenated\\056_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 420000 ... 7800023 =    840.000 ... 15600.046 secs\n",
      "Ready.\n",
      "Reading 0 ... 7380023  =      0.000 ... 14760.046 secs...\n",
      "Opening raw data file C:\\eeg\\057\\concatenated\\057_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 195000 ... 8865028 =    390.000 ... 17730.056 secs\n",
      "Ready.\n",
      "Reading 0 ... 8670028  =      0.000 ... 17340.056 secs...\n",
      "Opening raw data file C:\\eeg\\058\\concatenated\\058_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 465000 ... 8010015 =    930.000 ... 16020.030 secs\n",
      "Ready.\n",
      "Reading 0 ... 7545015  =      0.000 ... 15090.030 secs...\n",
      "Opening raw data file C:\\eeg\\059\\concatenated\\059_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 4035000 ... 9870021 =   8070.000 ... 19740.042 secs\n",
      "Ready.\n",
      "Reading 0 ... 5835021  =      0.000 ... 11670.042 secs...\n",
      "Opening raw data file C:\\eeg\\060\\concatenated\\060_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 420000 ... 8595022 =    840.000 ... 17190.044 secs\n",
      "Ready.\n",
      "Reading 0 ... 8175022  =      0.000 ... 16350.044 secs...\n",
      "Opening raw data file C:\\eeg\\061\\concatenated\\061_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 270000 ... 7155024 =    540.000 ... 14310.048 secs\n",
      "Ready.\n",
      "Reading 0 ... 6885024  =      0.000 ... 13770.048 secs...\n",
      "Opening raw data file C:\\eeg\\064\\concatenated\\064_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 1035000 ... 8160015 =   2070.000 ... 16320.030 secs\n",
      "Ready.\n",
      "Reading 0 ... 7125015  =      0.000 ... 14250.030 secs...\n",
      "Opening raw data file C:\\eeg\\066\\concatenated\\066_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 450000 ... 6885017 =    900.000 ... 13770.034 secs\n",
      "Ready.\n",
      "Reading 0 ... 6435017  =      0.000 ... 12870.034 secs...\n",
      "Opening raw data file C:\\eeg\\067\\concatenated\\067_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 825000 ... 9180031 =   1650.000 ... 18360.062 secs\n",
      "Ready.\n",
      "Reading 0 ... 8355031  =      0.000 ... 16710.062 secs...\n",
      "Opening raw data file C:\\eeg\\068\\concatenated\\068_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 285000 ... 8625040 =    570.000 ... 17250.080 secs\n",
      "Ready.\n",
      "Reading 0 ... 8340040  =      0.000 ... 16680.080 secs...\n",
      "Opening raw data file C:\\eeg\\070\\concatenated\\070_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 645000 ... 9390029 =   1290.000 ... 18780.058 secs\n",
      "Ready.\n",
      "Reading 0 ... 8745029  =      0.000 ... 17490.058 secs...\n",
      "Opening raw data file C:\\eeg\\071\\concatenated\\071_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 195000 ... 9870028 =    390.000 ... 19740.056 secs\n",
      "Ready.\n",
      "Reading 0 ... 9675028  =      0.000 ... 19350.056 secs...\n",
      "Opening raw data file C:\\eeg\\072\\concatenated\\072_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 345000 ... 8520023 =    690.000 ... 17040.046 secs\n",
      "Ready.\n",
      "Reading 0 ... 8175023  =      0.000 ... 16350.046 secs...\n",
      "Opening raw data file C:\\eeg\\074\\concatenated\\074_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 165000 ... 6405032 =    330.000 ... 12810.064 secs\n",
      "Ready.\n",
      "Reading 0 ... 6240032  =      0.000 ... 12480.064 secs...\n",
      "Opening raw data file C:\\eeg\\075\\concatenated\\075_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 7950047 =      0.000 ... 15900.094 secs\n",
      "Ready.\n",
      "Reading 0 ... 7950047  =      0.000 ... 15900.094 secs...\n",
      "Opening raw data file C:\\eeg\\076\\concatenated\\076_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 150000 ... 8415039 =    300.000 ... 16830.078 secs\n",
      "Ready.\n",
      "Reading 0 ... 8265039  =      0.000 ... 16530.078 secs...\n",
      "Opening raw data file C:\\eeg\\077\\concatenated\\077_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 255000 ... 5610021 =    510.000 ... 11220.042 secs\n",
      "Ready.\n",
      "Reading 0 ... 5355021  =      0.000 ... 10710.042 secs...\n",
      "Opening raw data file C:\\eeg\\078\\concatenated\\078_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 450000 ... 8550026 =    900.000 ... 17100.052 secs\n",
      "Ready.\n",
      "Reading 0 ... 8100026  =      0.000 ... 16200.052 secs...\n",
      "Opening raw data file C:\\eeg\\080\\concatenated\\080_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 375000 ... 8280024 =    750.000 ... 16560.048 secs\n",
      "Ready.\n",
      "Reading 0 ... 7905024  =      0.000 ... 15810.048 secs...\n",
      "Opening raw data file C:\\eeg\\081\\concatenated\\081_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 165000 ... 8970017 =    330.000 ... 17940.034 secs\n",
      "Ready.\n",
      "Reading 0 ... 8805017  =      0.000 ... 17610.034 secs...\n",
      "Opening raw data file C:\\eeg\\082\\concatenated\\082_concatenated_raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 300000 ... 8130024 =    600.000 ... 16260.048 secs\n",
      "Ready.\n",
      "Reading 0 ... 7830024  =      0.000 ... 15660.048 secs...\n"
     ]
    }
   ],
   "source": [
    "participant_ids = ['013', '014', '018', '019', '020', '022', '023', '024', '025','027', '028', '029', '030', '031', '032', '033', '034',\n",
    "                   '035', '036', '037',  '042',  '044','046', '047', '048', '049', '050', '051', '052', '053', '054','055', '056', '057', \n",
    "                   '058', '059', '060', '061', '064','066', '067', '068', '070', '071', '072', '074', '075', '076', '077', '078', '080', '081', '082']\n",
    "\n",
    "combined_raw_data = {}\n",
    "# will store the raw objects in a dictionary\n",
    "base_path = r\"C:\\eeg\"\n",
    "\n",
    "# for loop through the participants to load the data\n",
    "for pid in participant_ids:\n",
    "    file_path = fr\"{base_path}\\{pid}\\concatenated\\{pid}_concatenated_raw.fif\"\n",
    "    combined_raw_data[pid] = mne.io.read_raw_fif(file_path, preload=True)\n",
    "\n",
    "# if want to access participant 067\n",
    "# raw_067 = combined_raw_data[\"067\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62e84254-1864-4b4d-83fc-4dbd2245d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_spindles_times(eeg_raw, do_filter=True, do_downsample=False, downsample_rate=100):\n",
    "    \n",
    "    # 1. Filter between 12 and 16 Hz\n",
    "    \n",
    "    data = eeg_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=12, h_freq=16)\n",
    "    \n",
    "    # 2. Downsample at 100 Hz (100 samples per second)\n",
    "\n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "    \n",
    "    sfreq = data.info['sfreq']  \n",
    "    channel_data = data.get_data()[0]\n",
    "    # extract the filtered data\n",
    "    \n",
    "    \n",
    "    # 3: Calculate amplitude by applying Hilbert transformation\n",
    "\n",
    "    hilbert_signal = hilbert(channel_data)\n",
    "    # apply hilbert transformation to bandpassed data\n",
    "    # gives analytic signal with amplitude and phase information\n",
    "    envelope = np.abs(hilbert_signal)\n",
    "    # take the absolute part of the hilbert signal\n",
    "    # also the instantaneous power of the signal\n",
    "    # gives the envelope: amplitude modulation\n",
    "    # how strength of oscillations change over time\n",
    "    # size of sliding window\n",
    "    \n",
    "    # 4: Perform smoothing with a sliding window of 0.2 seconds\n",
    "    # this removes high-frequency noise\n",
    "    \n",
    "    sliding_window = int(0.2 * sfreq)\n",
    "    smoothed_envelope = np.convolve(envelope, np.ones(sliding_window) / sliding_window, mode='same')\n",
    "    # convolving envelope with a uniform filter over the sliding window\n",
    "    # convolution takes rolling average of 20 samples at a time\n",
    "    # smooth the signal with the average of values in the window\n",
    "    # in the smoothed envelope, can detect regions with higher amplitude \n",
    "    # which is when a spindle event occurs\n",
    "    # np.ones: creates a filter kernel\n",
    "    # have a filter where the sum of all elements equals 1\n",
    "    # this filter is replaced by the average of the 20 surrounding samples\n",
    "    # convolution between envelope and averaging filter\n",
    "    # mode = 'same': so that output of convolution has same length as original envelope\n",
    "\n",
    "    # 5. Define spindle detection threshold\n",
    "\n",
    "    threshold = np.percentile(smoothed_envelope, 75)\n",
    "    spindle_threshold = smoothed_envelope > threshold\n",
    "    #threshold = np.mean(smoothed_envelope) + 1.5 * np.std(smoothed_envelope)\n",
    "    #spindle_threshold = smoothed_envelope > threshold\n",
    "    # threshold is 75th percentile of the smoothed envelope\n",
    "    # will look at the duration later\n",
    "    \n",
    "    # 6. Detect spindles and define peaks and troughs for visualisation\n",
    "    \n",
    "    spindles = []\n",
    "    # initialize list with spindles\n",
    "    above_threshold = np.where(spindle_threshold)[0]\n",
    "    # returns indices where signal above the threshold\n",
    "    stacked_spindles = []\n",
    "    # initialize list for stacking the spindles for the visualisation\n",
    "    # contains aligned spindles at peak\n",
    "    \n",
    "    if len(above_threshold) > 0:\n",
    "        # checking it's not empty\n",
    "        start_idx = above_threshold[0]\n",
    "        # would be the start of a potential spindle\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] > above_threshold[i - 1] + 1:  \n",
    "                # if above threshold[1] > above_threshold[0] + 1\n",
    "                # because all indices should be separated by 1\n",
    "                # so here detects gaps\n",
    "                # so starting from the second index\n",
    "                # and comparing each index to the one before\n",
    "                end_idx = above_threshold[i - 1]\n",
    "                # so if above condition is true, this is the end of the spindle\n",
    "                duration = (end_idx - start_idx) / sfreq\n",
    "                if 0.5 <= duration <= 3:\n",
    "                    # only keep spindles lasting 0.5 to 3 seconds\n",
    "                    segment = channel_data[start_idx:end_idx]\n",
    "                    # extract EEG segment corresponding to detected spindle\n",
    "                    peak_idx = start_idx + np.argmax(segment) \n",
    "                    # extract the peak of the spindle\n",
    "                    # this will be useful for later\n",
    "                    spindles.append((start_idx / sfreq, end_idx / sfreq))\n",
    "                    # all the spindles are stored in spindles\n",
    "                    \n",
    "                    # Aligning spindles at peak for visualization\n",
    "                    before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "                    # still in the for loop, so this is the peak index of individual peak\n",
    "                    after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "                    # extracting 1.5 seconds before and after peak\n",
    "                    # max and min are used for out of bounds situations at the start and end of EEG data\n",
    "                    aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "                    stacked_spindles.append(aligned_segment)\n",
    "                    # the aligned segment is saved in stacked spindles\n",
    "                \n",
    "                start_idx = above_threshold[i]\n",
    "                # update the start index for the for loop\n",
    "\n",
    "        # then need to process the final spindle\n",
    "        end_idx = above_threshold[-1]\n",
    "        duration = (end_idx - start_idx) / sfreq\n",
    "        if 0.5 <= duration <= 3:\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            peak_idx = start_idx + np.argmax(segment)\n",
    "            spindles.append((start_idx / sfreq, end_idx / sfreq))\n",
    "\n",
    "            before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "            after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "            aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "            stacked_spindles.append(aligned_segment)\n",
    "    \n",
    "    return spindles\n",
    "    \n",
    "\n",
    "def detect_spindles_peaks(eeg_raw, do_filter=True, do_downsample=False, downsample_rate=100):\n",
    "    \n",
    "    # 1. Filter between 12 and 16 Hz\n",
    "    \n",
    "    data = eeg_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=12, h_freq=16)\n",
    "    \n",
    "    # 2. Downsample at 100 Hz (100 samples per second)\n",
    "    \n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "        \n",
    "    sfreq = data.info['sfreq']  \n",
    "    # update to new sampling frequency\n",
    "    # because used later in the code\n",
    "    channel_data = data.get_data()[0]\n",
    "    # extract the filtered data\n",
    "    \n",
    "    # 3: Calculate amplitude by applying Hilbert transformation\n",
    "\n",
    "    hilbert_signal = hilbert(channel_data)\n",
    "    # apply hilbert transformation to bandpassed data\n",
    "    # gives analytic signal with amplitude and phase information\n",
    "    envelope = np.abs(hilbert_signal)\n",
    "    # take the absolute part of the hilbert signal\n",
    "    # also the instantaneous power of the signal\n",
    "    # gives the envelope: amplitude modulation\n",
    "    # how strength of oscillations change over time\n",
    "    # size of sliding window\n",
    "    \n",
    "    # 4: Perform smoothing with a sliding window of 0.2 seconds\n",
    "    # this removes high-frequency noise\n",
    "    \n",
    "    sliding_window = int(0.2 * sfreq)\n",
    "    smoothed_envelope = np.convolve(envelope, np.ones(sliding_window) / sliding_window, mode='same')\n",
    "    # convolving envelope with a uniform filter over the sliding window\n",
    "    # convolution takes rolling average of 20 samples at a time\n",
    "    # smooth the signal with the average of values in the window\n",
    "    # in the smoothed envelope, can detect regions with higher amplitude \n",
    "    # which is when a spindle event occurs\n",
    "    # np.ones: creates a filter kernel\n",
    "    # have a filter where the sum of all elements equals 1\n",
    "    # this filter is replaced by the average of the 20 surrounding samples\n",
    "    # convolution between envelope and averaging filter\n",
    "    # mode = 'same': so that output of convolution has same length as original envelope\n",
    "\n",
    "    # 5. Define spindle detection threshold\n",
    "\n",
    "    threshold = np.percentile(smoothed_envelope, 75)\n",
    "    spindle_threshold = smoothed_envelope > threshold\n",
    "    # 75th percentile as criteria\n",
    "\n",
    "    #threshold = np.mean(smoothed_envelope) + 1.5 * np.std(smoothed_envelope)\n",
    "    #spindle_threshold = smoothed_envelope > threshold\n",
    "    \n",
    "    # 6. Detect spindles and define peaks and troughs for visualisation\n",
    "    \n",
    "    spindles = []\n",
    "    # initialize list with spindles\n",
    "    above_threshold = np.where(spindle_threshold)[0]\n",
    "    # returns indices where signal above the threshold\n",
    "    stacked_spindles = []\n",
    "    # initialize list for stacking the spindles for the visualisation\n",
    "    # contains aligned spindles at peak\n",
    "    \n",
    "    if len(above_threshold) > 0:\n",
    "        # checking it's not empty\n",
    "        start_idx = above_threshold[0]\n",
    "        # would be the start of a potential spindle\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] > above_threshold[i - 1] + 1:  \n",
    "                # if above threshold[1] > above_threshold[0] + 1\n",
    "                # because all indices should be separated by 1\n",
    "                # so here detects gaps\n",
    "                end_idx = above_threshold[i - 1]\n",
    "                # so if above condition is true, this is the end of the spindle\n",
    "                duration = (end_idx - start_idx) / sfreq\n",
    "                if 0.5 <= duration <= 3:\n",
    "                    # only keep spindles lasting 0.5 to 3 seconds\n",
    "                    segment = channel_data[start_idx:end_idx]\n",
    "                    # extract EEG segment corresponding to detected spindle\n",
    "                    peak_idx = start_idx + np.argmax(segment) \n",
    "                    # extract the peak of the spindle\n",
    "                    # this will be useful for later\n",
    "                    #spindles.append(f\"Spindle detected from {start_idx / sfreq:.2f}s to {end_idx / sfreq:.2f}s, peak at {peak_idx / sfreq:.2f}s\")\n",
    "                    spindles.append((peak_idx / sfreq))\n",
    "                    # all the spindles are stored in spindles\n",
    "                    \n",
    "                    # Aligning spindles at peak for visualization\n",
    "                    before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "                    # still in the for loop, so this is the peak index of individual peak\n",
    "                    after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "                    # extracting 1.5 seconds before and after peak\n",
    "                    # max and min are used for out of bounds situations at the start and end of EEG data\n",
    "                    aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "                    stacked_spindles.append(aligned_segment)\n",
    "                    # the aligned segment is saved in stacked spindles\n",
    "                \n",
    "                start_idx = above_threshold[i]\n",
    "                # update the start index for the for loop\n",
    "\n",
    "        # then need to process the final spindle\n",
    "        end_idx = above_threshold[-1]\n",
    "        duration = (end_idx - start_idx) / sfreq\n",
    "        if 0.5 <= duration <= 3:\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            peak_idx = start_idx + np.argmax(segment)\n",
    "            spindles.append((peak_idx / sfreq))\n",
    "\n",
    "            before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "            after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "            aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "            stacked_spindles.append(aligned_segment)\n",
    "\n",
    "    \n",
    "    return spindles\n",
    "\n",
    "def detect_spindles_peaks_average(eeg_raw, do_filter=True, do_downsample=False, downsample_rate=100):\n",
    "    \n",
    "    # 1. Filter between 12 and 16 Hz\n",
    "    \n",
    "    data = eeg_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=12, h_freq=16)\n",
    "    \n",
    "    # 2. Downsample at 100 Hz (100 samples per second)\n",
    "    \n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "        \n",
    "    sfreq = data.info['sfreq']  \n",
    "    # update to new sampling frequency\n",
    "    # because used later in the code\n",
    "    channel_data = data.get_data()[0]\n",
    "    # extract the filtered data\n",
    "    \n",
    "    # 3: Calculate amplitude by applying Hilbert transformation\n",
    "\n",
    "    hilbert_signal = hilbert(channel_data)\n",
    "    # apply hilbert transformation to bandpassed data\n",
    "    # gives analytic signal with amplitude and phase information\n",
    "    envelope = np.abs(hilbert_signal)\n",
    "    # take the absolute part of the hilbert signal\n",
    "    # also the instantaneous power of the signal\n",
    "    # gives the envelope: amplitude modulation\n",
    "    # how strength of oscillations change over time\n",
    "    # size of sliding window\n",
    "    \n",
    "    # 4: Perform smoothing with a sliding window of 0.2 seconds\n",
    "    # this removes high-frequency noise\n",
    "    \n",
    "    sliding_window = int(0.2 * sfreq)\n",
    "    smoothed_envelope = np.convolve(envelope, np.ones(sliding_window) / sliding_window, mode='same')\n",
    "    # convolving envelope with a uniform filter over the sliding window\n",
    "    # convolution takes rolling average of 20 samples at a time\n",
    "    # smooth the signal with the average of values in the window\n",
    "    # in the smoothed envelope, can detect regions with higher amplitude \n",
    "    # which is when a spindle event occurs\n",
    "    # np.ones: creates a filter kernel\n",
    "    # have a filter where the sum of all elements equals 1\n",
    "    # this filter is replaced by the average of the 20 surrounding samples\n",
    "    # convolution between envelope and averaging filter\n",
    "    # mode = 'same': so that output of convolution has same length as original envelope\n",
    "\n",
    "    # 5. Define spindle detection threshold\n",
    "\n",
    "    threshold = np.percentile(smoothed_envelope, 75)\n",
    "    spindle_threshold = smoothed_envelope > threshold\n",
    "    # 75th percentile as criteria\n",
    "\n",
    "    #threshold = np.mean(smoothed_envelope) + 1.5 * np.std(smoothed_envelope)\n",
    "    #spindle_threshold = smoothed_envelope > threshold\n",
    "    \n",
    "    # 6. Detect spindles and define peaks and troughs for visualisation\n",
    "    \n",
    "    spindles = []\n",
    "    # initialize list with spindles\n",
    "    above_threshold = np.where(spindle_threshold)[0]\n",
    "    # returns indices where signal above the threshold\n",
    "    stacked_spindles = []\n",
    "    # initialize list for stacking the spindles for the visualisation\n",
    "    # contains aligned spindles at peak\n",
    "    \n",
    "    if len(above_threshold) > 0:\n",
    "        # checking it's not empty\n",
    "        start_idx = above_threshold[0]\n",
    "        # would be the start of a potential spindle\n",
    "        for i in range(1, len(above_threshold)):\n",
    "            if above_threshold[i] > above_threshold[i - 1] + 1:  \n",
    "                # if above threshold[1] > above_threshold[0] + 1\n",
    "                # because all indices should be separated by 1\n",
    "                # so here detects gaps\n",
    "                end_idx = above_threshold[i - 1]\n",
    "                # so if above condition is true, this is the end of the spindle\n",
    "                duration = (end_idx - start_idx) / sfreq\n",
    "                if 0.5 <= duration <= 3:\n",
    "                    # only keep spindles lasting 0.5 to 3 seconds\n",
    "                    segment = channel_data[start_idx:end_idx]\n",
    "                    # extract EEG segment corresponding to detected spindle\n",
    "                    peak_idx = start_idx + np.argmax(segment) \n",
    "                    # extract the peak of the spindle\n",
    "                    # this will be useful for later\n",
    "                    #spindles.append(f\"Spindle detected from {start_idx / sfreq:.2f}s to {end_idx / sfreq:.2f}s, peak at {peak_idx / sfreq:.2f}s\")\n",
    "                    spindles.append((peak_idx / sfreq))\n",
    "                    # all the spindles are stored in spindles\n",
    "                    \n",
    "                    # Aligning spindles at peak for visualization\n",
    "                    before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "                    # still in the for loop, so this is the peak index of individual peak\n",
    "                    after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "                    # extracting 1.5 seconds before and after peak\n",
    "                    # max and min are used for out of bounds situations at the start and end of EEG data\n",
    "                    aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "                    stacked_spindles.append(aligned_segment)\n",
    "                    # the aligned segment is saved in stacked spindles\n",
    "                \n",
    "                start_idx = above_threshold[i]\n",
    "                # update the start index for the for loop\n",
    "\n",
    "        # then need to process the final spindle\n",
    "        end_idx = above_threshold[-1]\n",
    "        duration = (end_idx - start_idx) / sfreq\n",
    "        if 0.5 <= duration <= 3:\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            peak_idx = start_idx + np.argmax(segment)\n",
    "            spindles.append((peak_idx / sfreq))\n",
    "\n",
    "            before_peak_idx = max(0, peak_idx - int(1.5 * sfreq))\n",
    "            after_peak_idx = min(len(channel_data), peak_idx + int(1.5 * sfreq))\n",
    "            aligned_segment = channel_data[before_peak_idx:after_peak_idx]\n",
    "            stacked_spindles.append(aligned_segment)\n",
    "\n",
    "    \n",
    "    return spindles, stacked_spindles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e44050e2-05c0-454f-8a2c-314ea13fc1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_slow_oscillations_times(combined_raw, do_filter=True, do_downsample=False, downsample_rate=100):\n",
    "\n",
    "    # according to methods from Klinzing et al.(2016)\n",
    "\n",
    "    data = combined_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=0.16, h_freq=1.25)\n",
    "\n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "        \n",
    "    sfreq = data.info['sfreq']\n",
    "    channel_data = data.get_data()[0]\n",
    "    \n",
    "    # 3. find all positive-to-negative zero-crossings\n",
    "    \n",
    "    # zero_crossings = np.where( S!= 0)[0]\n",
    "    # can also save this somewhere for further detection of spindles\n",
    "    \n",
    "    S = np.diff(np.sign(channel_data))\n",
    "    # np.sign returns an array with 1 (positive), 0 (zero), -1 (negative)\n",
    "    # np.diff calculates the difference between consecutive elements in an array\n",
    "    # positive value: transition from negative to positive\n",
    "    # negative value: transition from positive to negative\n",
    "    # when it's a zero, means that value stayed the same\n",
    "    zero_crossings = np.where(S < 0)[0]\n",
    "    # -2 is when a positive-to-negative zero-crossing occurs\n",
    "    # goes from 1 to -1 \n",
    "    # -1 - 1 = -2\n",
    "    # [0] extracts the actual array\n",
    "    # extracts the indices of interest from current_data (not S)\n",
    "    #signs = np.sign(current_data)\n",
    "    #pos_to_neg = np.where((signs[:-1] > 0) & (signs[1:] < 0))[0]\n",
    "    # detect +1 to -1\n",
    "    #neg_to_pos = np.where((signs[:-1] <  0) & (signs[1:] > 0))[0]\n",
    "    # detect -1 to +1\n",
    "\n",
    "    # 4. Detect peak potentials in each pair\n",
    "    slow_oscillations = []\n",
    "    negative_peaks = []\n",
    "    positive_peaks = []\n",
    "    peak_to_peak_amplitudes = []\n",
    "    candidate_indices = []\n",
    "\n",
    "    # for loop for each pair\n",
    "    # to collect all the negative and positive peaks\n",
    "    # to further apply criteria\n",
    "    count = 0\n",
    "    for i in range(0, len(zero_crossings)-1, 1):\n",
    "        # loop through all the zero_crossings\n",
    "        # step of 1 (with step of 2, miss some zero_crossings)\n",
    "        start_idx = zero_crossings[i] + 1\n",
    "        # assigns index of zero-crossing (representing start of potential SO)\n",
    "        # to start_idx\n",
    "        end_idx = zero_crossings[i + 1] + 1\n",
    "        # assigns index of next zero-crossing (representing end of potential SO)\n",
    "        # to end_idx\n",
    "\n",
    "        # find the negative to positive crossing in between\n",
    "        #mid_crossings = neg_to_pos[(neg_to_pos > start_idx) & (neg_to_pos < end_idx)]\n",
    "\n",
    "        #if len(mid_crossings) != 1:\n",
    "            #continue\n",
    "\n",
    "        #mid_idx = mid_crossings [0]\n",
    "\n",
    "        #duration = (end_idx - start_idx) / sfreq\n",
    "        #if not (0.8 <= duration <= 2.0):\n",
    "  \n",
    "        \n",
    "        segment_length = (end_idx - start_idx) / sfreq\n",
    "\n",
    "        # need to add +1 because of way extract segment later\n",
    "\n",
    "        # have identified index for the pair\n",
    "        \n",
    "        # extract data segment between crossings\n",
    "        \n",
    "        # find peaks\n",
    "        if 0.8 <= segment_length <= 2.0:\n",
    "            count += 1\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            positive_peak = np.max(segment)\n",
    "            negative_peak = np.min(segment)\n",
    "            peak_to_peak_amplitude = positive_peak - negative_peak\n",
    "\n",
    "        # store values\n",
    "            candidate_indices.append((start_idx, end_idx))\n",
    "            positive_peaks.append(positive_peak)\n",
    "            negative_peaks.append(negative_peak)\n",
    "            peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "\n",
    "    # calculate mean values for comparison\n",
    "    #mean_negative_peak = np.mean(negative_peaks)\n",
    "    # mean_negative_peak = np.mean(negative_peaks) if negative_peaks else 0\n",
    "    #mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes)\n",
    "    # mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes) if peak_to_peak_amplitudes else 0\n",
    "\n",
    "    negative_peak_threshold = np.percentile(negative_peaks, 25)\n",
    "    # keep lowest negative peaks (under the 25th percentile)\n",
    "    peak_to_peak_amplitude_threshold = np.percentile(peak_to_peak_amplitudes, 75)\n",
    "    # keep largest peak-to-peak amplitude (over 75th percentile)\n",
    "\n",
    "    for (start_idx, end_idx), negative_peak, peak_to_peak_amplitude in zip(candidate_indices, negative_peaks, peak_to_peak_amplitudes):\n",
    "        if peak_to_peak_amplitude >= peak_to_peak_amplitude_threshold and negative_peak <= negative_peak_threshold:\n",
    "            slow_oscillations.append((start_idx / sfreq, end_idx / sfreq))\n",
    "            \n",
    "    return slow_oscillations\n",
    "    # returns a list of tuples, in which each tuple represents the start and end times of\n",
    "    # a detected slow oscillation\n",
    "\n",
    "def detect_slow_oscillations_peaks(combined_raw, do_filter=True, do_downsample=True, downsample_rate=100):\n",
    "\n",
    "    # according to methods from Klinzing et al.(2016)\n",
    "\n",
    "    data = combined_raw.copy().pick_channels(['Fz'])\n",
    "\n",
    "    if do_filter:\n",
    "        data.filter(l_freq=0.16, h_freq=1.25)\n",
    "\n",
    "    if do_downsample:\n",
    "        data.resample(downsample_rate)\n",
    "        \n",
    "    sfreq = data.info['sfreq']\n",
    "    channel_data = data.get_data()[0]\n",
    "    \n",
    "    # 3. find all positive-to-negative zero-crossings\n",
    "    \n",
    "    # zero_crossings = np.where( S!= 0)[0]\n",
    "    # can also save this somewhere for further detection of spindles\n",
    "    \n",
    "    S = np.diff(np.sign(channel_data))\n",
    "    # np.sign returns an array with 1 (positive), 0 (zero), -1 (negative)\n",
    "    # np.diff calculates the difference between consecutive elements in an array\n",
    "    # positive value: transition from negative to positive\n",
    "    # negative value: transition from positive to negative\n",
    "    # when it's a zero, means that value stayed the same\n",
    "    zero_crossings = np.where(S < 0)[0]\n",
    "    # -2 is when a positive-to-negative zero-crossing occurs\n",
    "    # goes from 1 to -1 \n",
    "    # -1 - 1 = -2\n",
    "    # [0] extracts the actual array\n",
    "    # extracts the indices of interest from current_data (not S)\n",
    "\n",
    "\n",
    "    # 4. Detect peak potentials in each pair\n",
    "    slow_oscillations = []\n",
    "    slow_oscillations_peaks = []\n",
    "    negative_peaks = []\n",
    "    positive_peaks = []\n",
    "    peak_to_peak_amplitudes = []\n",
    "    candidate_indices =  []\n",
    "\n",
    "    # for loop for each pair\n",
    "    # to collect all the negative and positive peaks\n",
    "    # to further apply criteria\n",
    "    count = 0\n",
    "    for i in range(0, len(zero_crossings) - 1, 1):\n",
    "        # loop through all the zero_crossings\n",
    "        # step of 1 (with step of 2, miss some zero_crossings)\n",
    "        start_idx = zero_crossings[i] + 1\n",
    "        # assigns index of zero-crossing (representing start of potential SO)\n",
    "        # to start_idx\n",
    "        end_idx = zero_crossings[i + 1] + 1\n",
    "        # assigns index of next zero-crossing (representing end of potential SO)\n",
    "        # to end_idx\n",
    "        segment_length = (end_idx - start_idx) / sfreq\n",
    "\n",
    "        # need to add +1 because of way extract segment later\n",
    "\n",
    "        # have identified index for the pair\n",
    "        \n",
    "        # extract data segment between crossings\n",
    "        \n",
    "        # find peaks\n",
    "        if 0.8 <= segment_length <= 2.0:\n",
    "            count += 1\n",
    "            segment = channel_data[start_idx:end_idx]\n",
    "            positive_peak = np.max(segment)\n",
    "            negative_peak = np.min(segment)\n",
    "            peak_to_peak_amplitude = positive_peak - negative_peak\n",
    "\n",
    "        # store values\n",
    "            candidate_indices.append((start_idx, end_idx))\n",
    "            positive_peaks.append(positive_peak)\n",
    "            negative_peaks.append(negative_peak)\n",
    "            peak_to_peak_amplitudes.append(peak_to_peak_amplitude)\n",
    "\n",
    "    # calculate mean values for comparison\n",
    "    #mean_negative_peak = np.mean(negative_peaks)\n",
    "    # mean_negative_peak = np.mean(negative_peaks) if negative_peaks else 0\n",
    "    #mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes)\n",
    "    # mean_peak_to_peak_amplitude = np.mean(peak_to_peak_amplitudes) if peak_to_peak_amplitudes else 0\n",
    "\n",
    "    negative_peak_threshold = np.percentile(negative_peaks, 25)\n",
    "    peak_to_peak_amplitude_threshold = np.percentile(peak_to_peak_amplitudes, 75)\n",
    "\n",
    "    for (start_idx, end_idx), negative_peak, peak_to_peak_amplitude in zip(candidate_indices, negative_peaks, peak_to_peak_amplitudes):\n",
    "        if peak_to_peak_amplitude >= peak_to_peak_amplitude_threshold and negative_peak <= negative_peak_threshold:\n",
    "            slow_oscillations.append((start_idx / sfreq, end_idx / sfreq))\n",
    "            slow_oscillations_peaks.append((negative_peak, positive_peak))\n",
    "\n",
    "            \n",
    "    return slow_oscillations_peaks\n",
    "    # returns a list of tuples, in which each tuple represents the start and end times of\n",
    "    # a detected slow oscillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e956e8f-79aa-498d-a92c-c9e0e651caf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_slow_oscillations_spindles_coupling_so_times(combined_raw, do_filter=True, do_downsample=False, downsample_rate=100):\n",
    "    slow_oscillations_peaks = detect_slow_oscillations_peaks(combined_raw, do_filter=do_filter, do_downsample=do_downsample, downsample_rate=downsample_rate)\n",
    "    slow_oscillations_times = detect_slow_oscillations_times(combined_raw, do_filter=do_filter, do_downsample=do_downsample, downsample_rate=downsample_rate)\n",
    "    spindles_peaks = detect_spindles_peaks(combined_raw, do_filter=do_filter, do_downsample=do_downsample, downsample_rate=downsample_rate)\n",
    "\n",
    "    coupling_times = []\n",
    "    coupling_times_so = []\n",
    "\n",
    "    # first detect the coupling events\n",
    "    for start_time, end_time in slow_oscillations_times:\n",
    "    #for start_time, end_time (negative_peak, positive_peak) in zip(slow_oscillations_times, slow_oscillations_peaks):\n",
    "        for peak in spindles_peaks:\n",
    "            if start_time < peak < end_time:\n",
    "                # if negative_peak < peak < end_time:\n",
    "                coupling_times.append(peak)\n",
    "                # if the peak of the spindle is between the negative and positive trough\n",
    "                # add it to list of coupling times\n",
    "\n",
    "    # then calculate the slow oscillation length\n",
    "    for start_time, end_time in slow_oscillations_times:\n",
    "        current_start_time = start_time\n",
    "        current_end_time = end_time\n",
    "        for coupling_peak in coupling_times:\n",
    "            if current_start_time < coupling_peak < current_end_time:\n",
    "                coupling_times_so.append((current_start_time, current_end_time))\n",
    "\n",
    "    return coupling_times_so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd55c699-07b8-4d69-9960-b3870be4c17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 22 contiguous segments\n",
      "Setting up band-pass filter from 12 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 12.00\n",
      "- Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 551 samples (1.102 s)\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 22 contiguous segments\n",
      "Setting up band-pass filter from 0.16 - 1.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.16\n",
      "- Lower transition bandwidth: 0.16 Hz (-6 dB cutoff frequency: 0.08 Hz)\n",
      "- Upper passband edge: 1.25 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.25 Hz)\n",
      "- Filter length: 10313 samples (20.626 s)\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 22 contiguous segments\n",
      "Setting up band-pass filter from 0.16 - 1.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.16\n",
      "- Lower transition bandwidth: 0.16 Hz (-6 dB cutoff frequency: 0.08 Hz)\n",
      "- Upper passband edge: 1.25 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.25 Hz)\n",
      "- Filter length: 10313 samples (20.626 s)\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 22 contiguous segments\n",
      "Setting up band-pass filter from 0.16 - 1.2 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.16\n",
      "- Lower transition bandwidth: 0.16 Hz (-6 dB cutoff frequency: 0.08 Hz)\n",
      "- Upper passband edge: 1.25 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.25 Hz)\n",
      "- Filter length: 10313 samples (20.626 s)\n",
      "\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 22 contiguous segments\n",
      "Setting up band-pass filter from 12 - 16 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 12.00\n",
      "- Lower transition bandwidth: 3.00 Hz (-6 dB cutoff frequency: 10.50 Hz)\n",
      "- Upper passband edge: 16.00 Hz\n",
      "- Upper transition bandwidth: 4.00 Hz (-6 dB cutoff frequency: 18.00 Hz)\n",
      "- Filter length: 551 samples (1.102 s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "participant_ids = ['013', '014', '018', '019', '020', '022', '023', '024', '025','027', '028', '029', '030', '031', '032', '033', '034',\n",
    "                   '035', '036', '037',  '042',  '044','046', '047', '048', '049', '050', '051', '052', '053', '054','055', '056', '057', \n",
    "                   '058', '059', '060', '061', '064','066', '067', '068', '070', '071', '072', '074', '075', '076', '077', '078', '080', '081', '082']\n",
    "results = []\n",
    "\n",
    "for pid in participant_ids:\n",
    "    raw = combined_raw_data[pid]\n",
    "    \n",
    "    # Detect events\n",
    "    spindles_times = detect_spindles_peaks(raw)\n",
    "    slow_oscillations_times = detect_slow_oscillations_times(raw)\n",
    "    so_spindle_coupling_times = detect_slow_oscillations_spindles_coupling_so_times(raw)\n",
    "\n",
    "    # Count number of events\n",
    "    num_spindles = len(spindles_times)\n",
    "    num_slow_oscillations = len(slow_oscillations_times)\n",
    "    num_so_spindle_coupling = len(so_spindle_coupling_times)\n",
    "\n",
    "    # The duration\n",
    "    duration_sec = raw.times[-1]\n",
    "    duration_min = duration_sec / 60\n",
    "\n",
    "    # Average per min (density)\n",
    "    avg_spindles_per_min = num_spindles / duration_min\n",
    "    avg_sos_per_min = num_slow_oscillations / duration_min\n",
    "    avg_couplings_per_min = num_so_spindle_coupling / duration_min\n",
    "    \n",
    "    results.append({\n",
    "        'Participant': pid,\n",
    "        'Spindle Density': avg_spindles_per_min,\n",
    "        'SO Density': avg_sos_per_min,\n",
    "        'Coupling Density': avg_couplings_per_min\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "# Calculate and display the average and standard deviation\n",
    "summary_df = results_df.describe().loc[['mean', 'std']]\n",
    "\n",
    "# Now format both dataframes for display\n",
    "results_df_display = results_df.copy()\n",
    "results_df_display[['Spindle Density', 'SO Density', 'Coupling Density']] = results_df_display[['Spindle Density', 'SO Density', 'Coupling Density']].applymap('{:.2f}'.format)\n",
    "display(results_df_display)\n",
    "\n",
    "summary_df_display = summary_df.applymap('{:.2f}'.format)\n",
    "display(summary_df_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d98ee-b1a0-4f14-86c8-0d5582f6cd44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
